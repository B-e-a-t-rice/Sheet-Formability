{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f53f67cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-11 17:58:08.644934: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-11 17:58:08.651970: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-11 17:58:08.660111: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-11 17:58:08.662432: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-11 17:58:08.669246: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-11 17:58:09.056564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import cv2\n",
    "from PIL import Image \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170e2d52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a347398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733965093.547278  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.569980  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.572196  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.575352  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.577061  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.578567  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.672559  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.673815  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1733965093.674906  583271 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-11 17:58:13.676007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13429 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4080 SUPER, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "gpuid = 0 #int(args.gpu_id)                                                                                                                           \n",
    "if gpus:\n",
    "  # Restrict TensorFlow to only allocate X GB of memory on the first GPU                                                                              \n",
    "  try:\n",
    "    tf.config.set_visible_devices(gpus[gpuid], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpus[gpuid], True)\n",
    "    '''\n",
    "    tf.config.set_logical_device_configuration(\n",
    "        gpus[gpuid],\n",
    "        [tf.config.LogicalDeviceConfiguration(memory_limit=12000)])\n",
    "    '''\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Virtual devices must be set before GPUs have been initialized                                                                                   \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b47bd50-699a-4df2-a734-b7d0ce6b4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "    inputs = np.load(\"all_inputs_height.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf4234ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "    targets = np.load(\"all_targets_height.npy\")\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5376c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3467, 512, 512, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fc10fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.65385175],\n",
       "         [0.6585279 ],\n",
       "         [0.67108393],\n",
       "         ...,\n",
       "         [0.63729916],\n",
       "         [0.64624695],\n",
       "         [0.6634144 ]],\n",
       "\n",
       "        [[0.66166691],\n",
       "         [0.65849554],\n",
       "         [0.66752423],\n",
       "         ...,\n",
       "         [0.64640875],\n",
       "         [0.64741194],\n",
       "         [0.64440238]],\n",
       "\n",
       "        [[0.70396259],\n",
       "         [0.69482064],\n",
       "         [0.69257156],\n",
       "         ...,\n",
       "         [0.64896526],\n",
       "         [0.63597236],\n",
       "         [0.62385321]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.42276265],\n",
       "         [0.42912156],\n",
       "         [0.43277834],\n",
       "         ...,\n",
       "         [0.5774477 ],\n",
       "         [0.56987525],\n",
       "         [0.57178454]],\n",
       "\n",
       "        [[0.41865282],\n",
       "         [0.42881414],\n",
       "         [0.43651603],\n",
       "         ...,\n",
       "         [0.57898484],\n",
       "         [0.57625034],\n",
       "         [0.57021504]],\n",
       "\n",
       "        [[0.41687297],\n",
       "         [0.42844199],\n",
       "         [0.436872  ],\n",
       "         ...,\n",
       "         [0.57023122],\n",
       "         [0.58531139],\n",
       "         [0.58031164]]],\n",
       "\n",
       "\n",
       "       [[[0.44314455],\n",
       "         [0.44454773],\n",
       "         [0.46070195],\n",
       "         ...,\n",
       "         [0.70932945],\n",
       "         [0.71408275],\n",
       "         [0.71852034]],\n",
       "\n",
       "        [[0.4444425 ],\n",
       "         [0.45093224],\n",
       "         [0.47278691],\n",
       "         ...,\n",
       "         [0.70759301],\n",
       "         [0.71878344],\n",
       "         [0.72615018]],\n",
       "\n",
       "        [[0.47206777],\n",
       "         [0.47183976],\n",
       "         [0.47615456],\n",
       "         ...,\n",
       "         [0.70941715],\n",
       "         [0.71395997],\n",
       "         [0.72716749]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.4734885 ],\n",
       "         [0.47224317],\n",
       "         [0.46698121],\n",
       "         ...,\n",
       "         [0.56269623],\n",
       "         [0.57374634],\n",
       "         [0.5833231 ]],\n",
       "\n",
       "        [[0.47429534],\n",
       "         [0.47127848],\n",
       "         [0.46756003],\n",
       "         ...,\n",
       "         [0.55804816],\n",
       "         [0.57692105],\n",
       "         [0.59191763]],\n",
       "\n",
       "        [[0.4708049 ],\n",
       "         [0.46733201],\n",
       "         [0.46419238],\n",
       "         ...,\n",
       "         [0.56231035],\n",
       "         [0.57965727],\n",
       "         [0.59342606]]],\n",
       "\n",
       "\n",
       "       [[[0.83683067],\n",
       "         [0.84242532],\n",
       "         [0.82486297],\n",
       "         ...,\n",
       "         [0.60871469],\n",
       "         [0.61403367],\n",
       "         [0.61500665]],\n",
       "\n",
       "        [[0.83412253],\n",
       "         [0.83856582],\n",
       "         [0.82418188],\n",
       "         ...,\n",
       "         [0.56940616],\n",
       "         [0.597947  ],\n",
       "         [0.61349852]],\n",
       "\n",
       "        [[0.83216035],\n",
       "         [0.83193332],\n",
       "         [0.81540882],\n",
       "         ...,\n",
       "         [0.55617358],\n",
       "         [0.57723867],\n",
       "         [0.59622807]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.53060033],\n",
       "         [0.51632991],\n",
       "         [0.50481627],\n",
       "         ...,\n",
       "         [0.55453572],\n",
       "         [0.55377355],\n",
       "         [0.56739532]],\n",
       "\n",
       "        [[0.53444362],\n",
       "         [0.51806506],\n",
       "         [0.50278922],\n",
       "         ...,\n",
       "         [0.55164921],\n",
       "         [0.55583304],\n",
       "         [0.56961697]],\n",
       "\n",
       "        [[0.54011935],\n",
       "         [0.52520027],\n",
       "         [0.50290273],\n",
       "         ...,\n",
       "         [0.56309798],\n",
       "         [0.57866572],\n",
       "         [0.59099017]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.69824439],\n",
       "         [0.69238706],\n",
       "         [0.68908537],\n",
       "         ...,\n",
       "         [0.60624147],\n",
       "         [0.61374964],\n",
       "         [0.59903489]],\n",
       "\n",
       "        [[0.67841836],\n",
       "         [0.67049748],\n",
       "         [0.6710848 ],\n",
       "         ...,\n",
       "         [0.60098733],\n",
       "         [0.63575034],\n",
       "         [0.64519509]],\n",
       "\n",
       "        [[0.68706943],\n",
       "         [0.6994349 ],\n",
       "         [0.71041938],\n",
       "         ...,\n",
       "         [0.57400235],\n",
       "         [0.61590844],\n",
       "         [0.65324296]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.56228769],\n",
       "         [0.55182704],\n",
       "         [0.5417791 ],\n",
       "         ...,\n",
       "         [0.56712912],\n",
       "         [0.54216007],\n",
       "         [0.53485825]],\n",
       "\n",
       "        [[0.55479539],\n",
       "         [0.55263659],\n",
       "         [0.53731865],\n",
       "         ...,\n",
       "         [0.57638338],\n",
       "         [0.57185942],\n",
       "         [0.55270009]],\n",
       "\n",
       "        [[0.54625544],\n",
       "         [0.54455697],\n",
       "         [0.53284231],\n",
       "         ...,\n",
       "         [0.56290676],\n",
       "         [0.57855805],\n",
       "         [0.5930347 ]]],\n",
       "\n",
       "\n",
       "       [[[0.70448534],\n",
       "         [0.7240061 ],\n",
       "         [0.73532081],\n",
       "         ...,\n",
       "         [0.38740322],\n",
       "         [0.39199861],\n",
       "         [0.38842656]],\n",
       "\n",
       "        [[0.71587728],\n",
       "         [0.73375683],\n",
       "         [0.74410612],\n",
       "         ...,\n",
       "         [0.39730841],\n",
       "         [0.39777181],\n",
       "         [0.39165106]],\n",
       "\n",
       "        [[0.71888938],\n",
       "         [0.73833291],\n",
       "         [0.75040065],\n",
       "         ...,\n",
       "         [0.39873723],\n",
       "         [0.40987816],\n",
       "         [0.40024329]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.53426271],\n",
       "         [0.53157885],\n",
       "         [0.5319457 ],\n",
       "         ...,\n",
       "         [0.7157035 ],\n",
       "         [0.7249136 ],\n",
       "         [0.72010581]],\n",
       "\n",
       "        [[0.52750478],\n",
       "         [0.52234944],\n",
       "         [0.52816126],\n",
       "         ...,\n",
       "         [0.71574212],\n",
       "         [0.7256087 ],\n",
       "         [0.72103261]],\n",
       "\n",
       "        [[0.52300593],\n",
       "         [0.52231083],\n",
       "         [0.53503504],\n",
       "         ...,\n",
       "         [0.71545249],\n",
       "         [0.72703752],\n",
       "         [0.72464328]]],\n",
       "\n",
       "\n",
       "       [[[0.54967211],\n",
       "         [0.5784255 ],\n",
       "         [0.61569141],\n",
       "         ...,\n",
       "         [0.49279589],\n",
       "         [0.48975345],\n",
       "         [0.49612208]],\n",
       "\n",
       "        [[0.56083297],\n",
       "         [0.57076423],\n",
       "         [0.55574122],\n",
       "         ...,\n",
       "         [0.48508733],\n",
       "         [0.49166089],\n",
       "         [0.49746201]],\n",
       "\n",
       "        [[0.57986002],\n",
       "         [0.58573996],\n",
       "         [0.57555647],\n",
       "         ...,\n",
       "         [0.49832902],\n",
       "         [0.50740904],\n",
       "         [0.51497572]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.68661328],\n",
       "         [0.68453244],\n",
       "         [0.69082225],\n",
       "         ...,\n",
       "         [0.37653698],\n",
       "         [0.3992055 ],\n",
       "         [0.40021439]],\n",
       "\n",
       "        [[0.69004981],\n",
       "         [0.6905385 ],\n",
       "         [0.70032789],\n",
       "         ...,\n",
       "         [0.34551359],\n",
       "         [0.37596948],\n",
       "         [0.41876852]],\n",
       "\n",
       "        [[0.69555142],\n",
       "         [0.69764802],\n",
       "         [0.69785295],\n",
       "         ...,\n",
       "         [0.37117725],\n",
       "         [0.34609685],\n",
       "         [0.34770477]]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4422cdc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0][0].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc333f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9ce12a0",
   "metadata": {},
   "source": [
    "Don't run any of the three below cells when using the alternate gridsearch method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71309228",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "\n",
    "with tf.device(\"/CPU:0\") :\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "with tf.device(\"/GPU:0\") :\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=200).batch(batchsize)\n",
    "    val_dataset = val_dataset.shuffle(buffer_size=200).batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52658a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 32\n",
    "\n",
    "with tf.device('/job:localhost/replica:0/task:0/device:CPU:0'):\n",
    "    targets = np.load(\"all_targets_with_height.npy\")\n",
    "    # train test split\n",
    "    X_trainval, X_test, y_trainval, y_test = train_test_split(inputs, targets, test_size=0.2)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2)\n",
    "\n",
    "with tf.device(\"/CPU:0\") :\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "with tf.device(\"/GPU:0\") :\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=200).batch(batchsize)\n",
    "    val_dataset = val_dataset.shuffle(buffer_size=200).batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69054bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated batch processing\n",
    "#X_trainval, X_test, y_trainval, y_test = train_test_split(inputs, targets, test_size=0.2)\n",
    "with tf.device(\"/CPU:0\") :\n",
    "    X_train, X_val, y_train, y_val = train_test_split(inputs, targets, test_size=0.2)\n",
    "    \n",
    "\n",
    "# Batch processing\\\n",
    "with tf.device(\"/CPU:0\") :\n",
    "    batchsize = 32\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(200).batch(batchsize)\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "146986f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3470,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40414180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   3    5    7    9   16   23   24   28   31   37   41   43   45   48\n",
      "   54   57   60   61   71   86   89   90   92   94  111  115  120  121\n",
      "  123  124  127  131  139  140  141  146  152  163  175  178  179  180\n",
      "  181  188  192  197  201  204  205  218  234  235  236  240  241  245\n",
      "  249  260  261  277  279  282  284  289  291  300  302  324  328  334\n",
      "  338  349  354  356  359  363  371  392  403  407  408  417  418  421\n",
      "  426  429  434  436  439  446  450  453  456  458  467  489  499  506\n",
      "  510  512  517  524  529  530  539  541  542  545  554  558  562  565\n",
      "  574  587  590  591  592  598  599  622  625  626  627  628  632  638\n",
      "  641  646  651  658  662  663  666  668  669  684  698  703  706  707\n",
      "  713  715  724  728  729  730  736  738  750  751  754  755  757  759\n",
      "  760  763  767  782  784  787  788  794  797  799  801  802  804  807\n",
      "  812  813  815  816  818  823  824  825  830  837  839  843  851  853\n",
      "  854  856  859  862  863  865  876  877  879  898  906  907  911  912\n",
      "  913  917  920  924  929  944  953  961  974  980  983  989  991  994\n",
      "  996  997 1004 1005 1019 1028 1029 1031 1039 1043 1051 1056 1068 1069\n",
      " 1072 1078 1082 1083 1089 1099 1105 1111 1113 1120 1123 1135 1141 1146\n",
      " 1153 1172 1176 1181 1186 1192 1195 1203 1205 1206 1209 1221 1223 1233\n",
      " 1237 1244 1245 1250 1256 1257 1265 1268 1278 1280 1281 1284 1285 1300\n",
      " 1307 1313 1317 1318 1321 1325 1330 1339 1341 1351 1358 1362 1365 1367\n",
      " 1368 1371 1373 1375 1382 1384 1385 1399 1434 1442 1456 1464 1465 1467\n",
      " 1469 1471 1481 1482 1487 1489 1495 1502 1504 1505 1517 1518 1525 1531\n",
      " 1532 1533 1537 1539 1550 1559 1560 1564 1574 1578 1583 1593 1598 1600\n",
      " 1601 1608 1617 1618 1619 1623 1624 1632 1638 1640 1645 1649 1650 1654\n",
      " 1670 1677 1678 1687 1690 1691 1692 1694 1697 1707 1714 1716 1719 1725\n",
      " 1726 1727 1728 1732 1733 1734 1739 1742 1743 1744 1746 1754 1770 1773\n",
      " 1776 1777 1782 1791 1794 1804 1823 1824 1827 1833 1846 1847 1850 1854\n",
      " 1855 1856 1861 1863 1867 1868 1872 1881 1887 1893 1899 1901 1903 1908\n",
      " 1917 1928 1930 1932 1936 1937 1945 1947 1948 1951 1952 1955 1956 1960\n",
      " 1963 1973 1982 1984 1989 1993 1995 1997 2000 2006 2010 2017 2020 2022\n",
      " 2026 2028 2029 2030 2031 2048 2050 2055 2058 2067 2069 2072 2073 2075\n",
      " 2077 2079 2081 2082 2089 2090 2091 2096 2097 2114 2115 2123 2128 2132\n",
      " 2141 2143 2157 2161 2170 2175 2182 2188 2190 2192 2193 2197 2198 2211\n",
      " 2220 2222 2225 2230 2233 2235 2240 2251 2254 2260 2267 2281 2290 2292\n",
      " 2293 2311 2312 2314 2318 2320 2323 2324 2343 2344 2348 2349 2354 2365\n",
      " 2371 2372 2374 2375 2379 2380 2386 2390 2394 2400 2403 2405 2409 2410\n",
      " 2419 2421 2429 2430 2432 2434 2435 2436 2438 2440 2452 2453 2458 2470\n",
      " 2473 2474 2476 2487 2492 2496 2500 2512 2516 2521 2525 2533 2539 2548\n",
      " 2550 2554 2555 2556 2559 2560 2562 2572 2576 2577 2581 2582 2596 2611\n",
      " 2619 2626 2628 2640 2650 2654 2656 2661 2669 2674 2678 2685 2687 2701\n",
      " 2710 2723 2728 2729 2731 2733 2743 2746 2750 2755 2762 2778 2779 2784\n",
      " 2785 2791 2803 2809 2810 2813 2815 2816 2827 2838 2844 2869 2876 2886\n",
      " 2899 2901 2911 2923 2928 2930 2931 2937 2945 2948 2950 2955 2957 2964\n",
      " 2965 2975 2995 3013 3022 3028 3033 3036 3042 3049 3051 3063 3064 3069\n",
      " 3079 3081 3084 3094 3095 3096 3104 3108 3114 3118 3121 3125 3128 3129\n",
      " 3133 3135 3140 3144 3145 3147 3153 3164 3167 3180 3189 3191 3195 3197\n",
      " 3199 3204 3210 3211 3213 3225 3230 3244 3246 3247 3256 3260 3262 3266\n",
      " 3268 3269 3270 3273 3276 3279 3280 3281 3286 3298 3302 3306 3308 3312\n",
      " 3314 3315 3322 3333 3344 3346 3360 3377 3379 3380 3397 3401 3414 3419\n",
      " 3428 3432 3433 3436 3443 3450 3452 3454]\n",
      "[   1    4   14   18   21   29   30   34   35   36   46   47   55   62\n",
      "   64   66   68   69   77   93   97   99  100  102  107  110  114  116\n",
      "  128  135  137  138  145  150  153  155  156  158  160  161  165  170\n",
      "  171  173  182  193  195  198  202  206  207  213  215  216  223  224\n",
      "  228  231  244  256  257  268  281  283  296  298  304  308  309  312\n",
      "  315  321  337  340  341  361  367  373  374  375  377  378  387  391\n",
      "  393  395  398  399  402  406  410  411  430  432  435  437  440  443\n",
      "  444  448  455  459  461  466  472  474  476  479  482  483  491  495\n",
      "  496  501  503  504  505  509  513  514  518  519  522  526  527  536\n",
      "  544  546  549  551  556  561  564  566  568  572  575  588  602  603\n",
      "  604  610  611  612  620  633  637  643  644  653  654  655  660  661\n",
      "  664  667  678  683  685  686  690  691  692  704  705  710  720  723\n",
      "  726  727  734  748  752  753  756  769  774  776  777  790  791  806\n",
      "  820  822  826  828  836  838  850  868  869  880  885  894  899  915\n",
      "  925  931  932  935  940  945  952  965  968  977  979  981  986  987\n",
      " 1003 1010 1011 1012 1014 1016 1018 1021 1025 1037 1038 1045 1048 1057\n",
      " 1067 1070 1071 1077 1091 1096 1098 1100 1103 1110 1112 1124 1127 1134\n",
      " 1136 1138 1139 1140 1158 1161 1162 1166 1167 1179 1180 1198 1208 1215\n",
      " 1218 1219 1220 1227 1229 1236 1240 1242 1255 1258 1262 1264 1271 1282\n",
      " 1288 1309 1314 1319 1329 1336 1337 1342 1346 1348 1352 1356 1361 1370\n",
      " 1379 1392 1405 1406 1420 1422 1426 1428 1433 1436 1443 1446 1452 1458\n",
      " 1459 1470 1472 1473 1474 1480 1485 1486 1493 1499 1507 1511 1520 1528\n",
      " 1534 1535 1546 1554 1556 1562 1567 1571 1580 1582 1591 1592 1596 1602\n",
      " 1610 1616 1621 1629 1641 1653 1656 1658 1659 1660 1662 1672 1682 1685\n",
      " 1686 1688 1699 1701 1710 1713 1718 1731 1735 1737 1740 1747 1749 1751\n",
      " 1752 1757 1760 1762 1765 1767 1775 1788 1793 1796 1798 1799 1800 1807\n",
      " 1815 1817 1821 1828 1829 1832 1839 1840 1843 1849 1852 1853 1858 1864\n",
      " 1865 1869 1877 1897 1907 1914 1922 1929 1943 1950 1957 1969 1976 1978\n",
      " 1979 1987 1991 1994 1996 2001 2003 2004 2012 2027 2036 2039 2040 2041\n",
      " 2046 2053 2056 2057 2059 2063 2064 2080 2084 2087 2092 2094 2100 2104\n",
      " 2107 2108 2112 2116 2117 2122 2124 2136 2140 2146 2148 2149 2159 2166\n",
      " 2180 2191 2203 2205 2206 2209 2210 2213 2219 2226 2232 2244 2248 2252\n",
      " 2256 2258 2259 2261 2263 2264 2273 2275 2277 2282 2284 2287 2289 2297\n",
      " 2298 2306 2316 2319 2326 2328 2331 2335 2337 2342 2361 2362 2367 2377\n",
      " 2381 2387 2391 2393 2395 2396 2397 2402 2404 2407 2417 2427 2439 2445\n",
      " 2447 2448 2449 2451 2457 2462 2464 2468 2478 2482 2493 2497 2504 2511\n",
      " 2514 2515 2527 2529 2530 2540 2547 2557 2558 2566 2567 2568 2569 2570\n",
      " 2571 2574 2575 2583 2587 2588 2590 2593 2601 2625 2629 2636 2637 2642\n",
      " 2645 2647 2652 2660 2662 2664 2665 2670 2673 2680 2682 2689 2691 2692\n",
      " 2693 2699 2703 2704 2705 2708 2713 2717 2744 2745 2758 2764 2766 2773\n",
      " 2775 2783 2788 2792 2794 2795 2800 2804 2807 2821 2822 2824 2826 2832\n",
      " 2835 2839 2847 2848 2850 2852 2855 2858 2859 2863 2865 2874 2875 2880\n",
      " 2883 2896 2913 2916 2921 2927 2932 2934 2939 2940 2946 2958 2961 2962\n",
      " 2976 2978 2982 2985 2996 3001 3004 3006 3009 3025 3037 3040 3047 3050\n",
      " 3056 3057 3070 3073 3078 3087 3092 3103 3105 3115 3136 3148 3151 3159\n",
      " 3162 3171 3176 3177 3182 3185 3188 3198 3206 3207 3212 3214 3216 3234\n",
      " 3236 3245 3254 3261 3264 3277 3283 3284 3289 3294 3304 3309 3316 3318\n",
      " 3319 3321 3323 3325 3329 3332 3334 3336 3340 3342 3345 3350 3351 3356\n",
      " 3361 3384 3403 3405 3407 3411 3412 3421 3422 3427 3429 3430 3435 3437\n",
      " 3439 3441 3444 3447 3455 3461 3463 3464]\n",
      "[   8   12   17   26   33   38   39   40   44   49   52   58   59   65\n",
      "   70   73   78   82   83   84   87  104  105  106  109  117  130  132\n",
      "  143  147  162  168  169  183  184  189  191  203  209  214  217  221\n",
      "  227  232  233  237  239  246  251  252  258  259  263  264  270  271\n",
      "  285  290  292  297  311  314  316  319  326  327  329  342  344  347\n",
      "  352  353  357  369  370  372  384  388  390  396  416  420  422  454\n",
      "  463  473  488  490  498  507  508  515  521  523  540  548  552  553\n",
      "  567  569  570  573  579  585  594  597  601  606  609  616  619  629\n",
      "  636  649  659  665  672  673  674  676  680  687  688  694  695  699\n",
      "  702  712  717  725  733  737  742  743  744  745  746  762  766  771\n",
      "  778  780  785  786  789  792  798  800  803  811  814  827  829  833\n",
      "  847  848  849  855  858  866  870  871  878  882  886  887  888  889\n",
      "  890  900  901  903  908  909  928  930  936  937  941  946  948  950\n",
      "  951  955  963  966  967  971  995  998 1001 1007 1009 1022 1023 1027\n",
      " 1030 1033 1042 1044 1046 1049 1050 1052 1055 1058 1059 1062 1064 1065\n",
      " 1066 1079 1084 1088 1090 1092 1093 1095 1097 1106 1109 1115 1118 1119\n",
      " 1121 1129 1131 1142 1150 1157 1159 1165 1171 1173 1175 1177 1182 1183\n",
      " 1184 1185 1189 1190 1201 1211 1212 1217 1222 1224 1225 1228 1230 1235\n",
      " 1239 1241 1247 1272 1279 1286 1291 1293 1299 1303 1305 1306 1332 1334\n",
      " 1343 1347 1353 1355 1363 1366 1374 1381 1383 1386 1388 1395 1400 1401\n",
      " 1417 1418 1421 1430 1438 1439 1440 1444 1445 1447 1451 1454 1455 1457\n",
      " 1462 1463 1477 1488 1490 1492 1494 1501 1506 1508 1519 1527 1530 1538\n",
      " 1540 1544 1548 1552 1557 1558 1568 1572 1575 1588 1599 1607 1611 1625\n",
      " 1628 1630 1633 1634 1643 1644 1646 1661 1665 1671 1674 1679 1681 1683\n",
      " 1695 1696 1705 1708 1712 1722 1736 1756 1759 1761 1771 1779 1783 1784\n",
      " 1786 1789 1790 1792 1801 1802 1813 1819 1826 1830 1831 1834 1837 1838\n",
      " 1841 1842 1851 1860 1866 1875 1878 1880 1886 1894 1896 1898 1900 1906\n",
      " 1913 1920 1923 1925 1927 1931 1935 1940 1949 1954 1965 1977 1980 1983\n",
      " 2002 2009 2015 2018 2021 2032 2035 2037 2044 2047 2051 2060 2061 2065\n",
      " 2066 2068 2070 2085 2086 2095 2105 2109 2111 2119 2120 2126 2129 2130\n",
      " 2131 2142 2151 2156 2158 2168 2173 2174 2178 2184 2186 2187 2189 2196\n",
      " 2199 2200 2201 2212 2236 2239 2245 2257 2268 2270 2272 2276 2278 2291\n",
      " 2295 2296 2300 2301 2302 2308 2309 2317 2327 2332 2333 2334 2341 2345\n",
      " 2347 2350 2352 2355 2356 2357 2359 2369 2373 2376 2382 2383 2385 2388\n",
      " 2406 2408 2415 2418 2420 2423 2425 2433 2437 2443 2455 2461 2467 2469\n",
      " 2472 2477 2483 2484 2485 2488 2489 2495 2498 2499 2503 2506 2507 2508\n",
      " 2518 2531 2532 2534 2535 2542 2543 2544 2546 2551 2564 2578 2579 2580\n",
      " 2584 2586 2594 2595 2604 2605 2606 2608 2610 2613 2615 2616 2631 2638\n",
      " 2646 2655 2657 2667 2668 2672 2676 2677 2679 2681 2684 2688 2690 2695\n",
      " 2696 2707 2712 2718 2719 2727 2734 2742 2751 2757 2760 2770 2771 2772\n",
      " 2787 2790 2814 2825 2831 2840 2845 2846 2849 2854 2867 2868 2870 2877\n",
      " 2879 2885 2888 2900 2905 2925 2926 2929 2949 2951 2953 2963 2966 2967\n",
      " 2968 2969 2971 2979 2980 2983 2984 2987 2991 2993 2997 3005 3007 3011\n",
      " 3014 3016 3021 3023 3041 3044 3046 3060 3080 3082 3085 3088 3106 3112\n",
      " 3116 3120 3130 3132 3142 3143 3149 3152 3155 3156 3157 3168 3173 3187\n",
      " 3190 3192 3194 3200 3201 3202 3203 3208 3223 3226 3228 3229 3231 3232\n",
      " 3235 3240 3258 3259 3271 3282 3287 3292 3293 3297 3299 3303 3317 3324\n",
      " 3326 3327 3339 3343 3349 3355 3357 3364 3365 3366 3370 3378 3386 3390\n",
      " 3391 3392 3395 3396 3398 3399 3404 3413 3415 3417 3418 3420 3423 3425\n",
      " 3438 3440 3442 3448 3451 3458 3466]\n",
      "[   0    6   15   19   20   25   32   42   56   63   75   79   81   88\n",
      "  101  108  118  119  125  129  134  148  151  159  167  176  185  186\n",
      "  187  190  194  196  200  210  211  225  226  230  238  243  253  255\n",
      "  262  265  266  273  274  278  286  294  295  299  301  306  310  313\n",
      "  318  322  325  336  343  350  351  355  362  376  380  382  389  394\n",
      "  400  401  404  413  425  428  431  433  442  447  449  452  460  462\n",
      "  468  471  477  478  480  484  487  492  493  494  500  502  520  531\n",
      "  532  533  535  537  543  547  550  557  560  563  571  583  584  586\n",
      "  589  593  595  607  608  613  617  621  623  624  630  631  635  640\n",
      "  642  647  648  652  671  675  689  693  697  708  711  716  718  721\n",
      "  731  732  739  747  758  761  765  770  772  773  775  781  783  795\n",
      "  796  805  808  809  810  819  821  834  841  861  867  872  873  875\n",
      "  881  892  893  896  897  902  904  905  910  918  919  923  926  927\n",
      "  933  934  947  957  958  962  964  969  970  972  973  978  982  988\n",
      "  990  999 1002 1006 1020 1026 1035 1040 1047 1053 1060 1073 1075 1080\n",
      " 1087 1102 1107 1114 1122 1126 1128 1132 1144 1147 1148 1149 1152 1154\n",
      " 1163 1164 1168 1170 1174 1188 1193 1196 1199 1200 1204 1207 1210 1213\n",
      " 1214 1216 1231 1232 1234 1238 1248 1251 1252 1263 1266 1267 1269 1274\n",
      " 1276 1287 1295 1296 1301 1302 1310 1311 1316 1323 1326 1328 1350 1359\n",
      " 1360 1364 1372 1378 1393 1394 1397 1404 1410 1412 1419 1423 1424 1425\n",
      " 1427 1429 1435 1437 1441 1449 1450 1453 1460 1461 1466 1468 1475 1476\n",
      " 1478 1483 1484 1491 1496 1503 1510 1513 1514 1516 1542 1545 1549 1551\n",
      " 1555 1563 1565 1566 1576 1581 1584 1585 1586 1590 1595 1597 1604 1613\n",
      " 1614 1622 1627 1636 1637 1648 1651 1657 1663 1667 1669 1675 1680 1700\n",
      " 1703 1704 1706 1720 1721 1723 1724 1730 1738 1741 1750 1758 1768 1769\n",
      " 1772 1774 1780 1805 1808 1811 1812 1816 1822 1825 1835 1836 1844 1871\n",
      " 1874 1888 1889 1890 1902 1905 1912 1915 1916 1938 1942 1961 1966 1967\n",
      " 1971 1975 1985 1988 1992 2008 2013 2016 2024 2042 2043 2045 2049 2052\n",
      " 2054 2071 2074 2083 2088 2093 2102 2113 2118 2121 2125 2127 2135 2137\n",
      " 2138 2139 2145 2147 2155 2160 2164 2172 2194 2195 2207 2208 2214 2216\n",
      " 2221 2223 2224 2228 2229 2231 2237 2242 2247 2249 2250 2255 2266 2269\n",
      " 2271 2274 2286 2288 2299 2303 2304 2305 2307 2310 2313 2315 2321 2329\n",
      " 2330 2338 2339 2346 2351 2353 2358 2360 2363 2368 2384 2389 2398 2401\n",
      " 2414 2416 2422 2424 2441 2442 2444 2446 2454 2460 2466 2471 2475 2479\n",
      " 2491 2509 2510 2513 2517 2519 2520 2523 2524 2526 2528 2536 2545 2549\n",
      " 2552 2563 2573 2585 2589 2599 2602 2607 2614 2618 2620 2623 2624 2630\n",
      " 2632 2633 2634 2635 2639 2641 2644 2648 2649 2653 2658 2659 2666 2671\n",
      " 2683 2694 2697 2700 2702 2711 2714 2720 2722 2724 2725 2726 2730 2732\n",
      " 2736 2739 2748 2749 2752 2754 2756 2761 2763 2765 2767 2777 2780 2782\n",
      " 2789 2793 2797 2805 2806 2818 2820 2823 2829 2833 2836 2837 2842 2851\n",
      " 2853 2861 2862 2871 2872 2878 2889 2891 2892 2895 2897 2903 2908 2909\n",
      " 2910 2914 2918 2920 2935 2938 2952 2954 2956 2959 2960 2973 2989 2990\n",
      " 2992 2998 3002 3008 3012 3015 3017 3019 3029 3030 3031 3032 3034 3035\n",
      " 3038 3043 3048 3052 3053 3055 3058 3059 3061 3062 3065 3066 3072 3075\n",
      " 3086 3091 3093 3097 3099 3100 3101 3107 3110 3117 3119 3123 3124 3126\n",
      " 3131 3150 3160 3161 3163 3165 3169 3174 3175 3184 3193 3196 3205 3215\n",
      " 3218 3220 3233 3238 3239 3250 3251 3253 3255 3257 3263 3272 3274 3288\n",
      " 3290 3300 3301 3305 3311 3313 3320 3330 3331 3335 3352 3367 3368 3372\n",
      " 3374 3375 3383 3385 3389 3394 3400 3406 3408 3424 3431 3434 3445 3446\n",
      " 3449 3453 3456 3459 3460 3462 3465]\n",
      "[   2   10   11   13   22   27   50   51   53   67   72   74   76   80\n",
      "   85   91   95   96   98  103  112  113  122  126  133  136  142  144\n",
      "  149  154  157  164  166  172  174  177  199  208  212  219  220  222\n",
      "  229  242  247  248  250  254  267  269  272  275  276  280  287  288\n",
      "  293  303  305  307  317  320  323  330  331  332  333  335  339  345\n",
      "  346  348  358  360  364  365  366  368  379  381  383  385  386  397\n",
      "  405  409  412  414  415  419  423  424  427  438  441  445  451  457\n",
      "  464  465  469  470  475  481  485  486  497  511  516  525  528  534\n",
      "  538  555  559  576  577  578  580  581  582  596  600  605  614  615\n",
      "  618  634  639  645  650  656  657  670  677  679  681  682  696  700\n",
      "  701  709  714  719  722  735  740  741  749  764  768  779  793  817\n",
      "  831  832  835  840  842  844  845  846  852  857  860  864  874  883\n",
      "  884  891  895  914  916  921  922  938  939  942  943  949  954  956\n",
      "  959  960  975  976  984  985  992  993 1000 1008 1013 1015 1017 1024\n",
      " 1032 1034 1036 1041 1054 1061 1063 1074 1076 1081 1085 1086 1094 1101\n",
      " 1104 1108 1116 1117 1125 1130 1133 1137 1143 1145 1151 1155 1156 1160\n",
      " 1169 1178 1187 1191 1194 1197 1202 1226 1243 1246 1249 1253 1254 1259\n",
      " 1260 1261 1270 1273 1275 1277 1283 1289 1290 1292 1294 1297 1298 1304\n",
      " 1308 1312 1315 1320 1322 1324 1327 1331 1333 1335 1338 1340 1344 1345\n",
      " 1349 1354 1357 1369 1376 1377 1380 1387 1389 1390 1391 1396 1398 1402\n",
      " 1403 1407 1408 1409 1411 1413 1414 1415 1416 1431 1432 1448 1479 1497\n",
      " 1498 1500 1509 1512 1515 1521 1522 1523 1524 1526 1529 1536 1541 1543\n",
      " 1547 1553 1561 1569 1570 1573 1577 1579 1587 1589 1594 1603 1605 1606\n",
      " 1609 1612 1615 1620 1626 1631 1635 1639 1642 1647 1652 1655 1664 1666\n",
      " 1668 1673 1676 1684 1689 1693 1698 1702 1709 1711 1715 1717 1729 1745\n",
      " 1748 1753 1755 1763 1764 1766 1778 1781 1785 1787 1795 1797 1803 1806\n",
      " 1809 1810 1814 1818 1820 1845 1848 1857 1859 1862 1870 1873 1876 1879\n",
      " 1882 1883 1884 1885 1891 1892 1895 1904 1909 1910 1911 1918 1919 1921\n",
      " 1924 1926 1933 1934 1939 1941 1944 1946 1953 1958 1959 1962 1964 1968\n",
      " 1970 1972 1974 1981 1986 1990 1998 1999 2005 2007 2011 2014 2019 2023\n",
      " 2025 2033 2034 2038 2062 2076 2078 2098 2099 2101 2103 2106 2110 2133\n",
      " 2134 2144 2150 2152 2153 2154 2162 2163 2165 2167 2169 2171 2176 2177\n",
      " 2179 2181 2183 2185 2202 2204 2215 2217 2218 2227 2234 2238 2241 2243\n",
      " 2246 2253 2262 2265 2279 2280 2283 2285 2294 2322 2325 2336 2340 2364\n",
      " 2366 2370 2378 2392 2399 2411 2412 2413 2426 2428 2431 2450 2456 2459\n",
      " 2463 2465 2480 2481 2486 2490 2494 2501 2502 2505 2522 2537 2538 2541\n",
      " 2553 2561 2565 2591 2592 2597 2598 2600 2603 2609 2612 2617 2621 2622\n",
      " 2627 2643 2651 2663 2675 2686 2698 2706 2709 2715 2716 2721 2735 2737\n",
      " 2738 2740 2741 2747 2753 2759 2768 2769 2774 2776 2781 2786 2796 2798\n",
      " 2799 2801 2802 2808 2811 2812 2817 2819 2828 2830 2834 2841 2843 2856\n",
      " 2857 2860 2864 2866 2873 2881 2882 2884 2887 2890 2893 2894 2898 2902\n",
      " 2904 2906 2907 2912 2915 2917 2919 2922 2924 2933 2936 2941 2942 2943\n",
      " 2944 2947 2970 2972 2974 2977 2981 2986 2988 2994 2999 3000 3003 3010\n",
      " 3018 3020 3024 3026 3027 3039 3045 3054 3067 3068 3071 3074 3076 3077\n",
      " 3083 3089 3090 3098 3102 3109 3111 3113 3122 3127 3134 3137 3138 3139\n",
      " 3141 3146 3154 3158 3166 3170 3172 3178 3179 3181 3183 3186 3209 3217\n",
      " 3219 3221 3222 3224 3227 3237 3241 3242 3243 3248 3249 3252 3265 3267\n",
      " 3275 3278 3285 3291 3295 3296 3307 3310 3328 3337 3338 3341 3347 3348\n",
      " 3353 3354 3358 3359 3362 3363 3369 3371 3373 3376 3381 3382 3387 3388\n",
      " 3393 3402 3409 3410 3416 3426 3457]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(inputs, targets):\n",
    "    print(test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3f6976",
   "metadata": {},
   "source": [
    "### Other gridsearch methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2990db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing model 1 out of 12\n",
      "testing params: max, 3, 9, 32,0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733965115.074833  583425 service.cc:146] XLA service 0x770cf8004710 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733965115.074857  583425 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4080 SUPER, Compute Capability 8.9\n",
      "2024-12-11 17:58:35.114828: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-11 17:58:35.242046: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 3/70\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.5035 - loss: 2.3983"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733965121.420866  583425 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 114ms/step - accuracy: 0.5253 - loss: 1.0484 - val_accuracy: 0.5099 - val_loss: 0.6877\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5527 - loss: 0.6742 - val_accuracy: 0.5207 - val_loss: 0.6918\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5768 - loss: 0.6610 - val_accuracy: 0.5225 - val_loss: 0.6861\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5964 - loss: 0.6577 - val_accuracy: 0.4757 - val_loss: 0.6946\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5762 - loss: 0.6591 - val_accuracy: 0.4793 - val_loss: 0.6943\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5888 - loss: 0.6489 - val_accuracy: 0.4703 - val_loss: 0.6960\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6290 - loss: 0.6426 - val_accuracy: 0.5315 - val_loss: 0.7851\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6424 - loss: 0.6281 - val_accuracy: 0.5225 - val_loss: 1.1780\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6383 - loss: 0.6298 - val_accuracy: 0.5189 - val_loss: 1.0365\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6608 - loss: 0.6062 - val_accuracy: 0.5225 - val_loss: 1.2041\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6661 - loss: 0.5984 - val_accuracy: 0.4667 - val_loss: 0.7107\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6837 - loss: 0.5873 - val_accuracy: 0.5658 - val_loss: 0.7411\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6838 - loss: 0.5746 - val_accuracy: 0.4793 - val_loss: 0.7058\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6767 - loss: 0.5755 - val_accuracy: 0.5207 - val_loss: 2.4472\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7235 - loss: 0.5411 - val_accuracy: 0.4793 - val_loss: 0.7102\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7136 - loss: 0.5553 - val_accuracy: 0.4937 - val_loss: 0.7056\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6549 - loss: 0.5872 - val_accuracy: 0.4739 - val_loss: 0.7197\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7428 - loss: 0.5198 - val_accuracy: 0.4721 - val_loss: 0.7238\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7331 - loss: 0.5305 - val_accuracy: 0.4703 - val_loss: 0.7309\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7776 - loss: 0.4820 - val_accuracy: 0.5315 - val_loss: 4.9379\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7363 - loss: 0.5170 - val_accuracy: 0.5207 - val_loss: 5.8639\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7936 - loss: 0.4556 - val_accuracy: 0.4775 - val_loss: 0.7828\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.6570 - loss: 0.8584\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.5106 - loss: 1.0366 - val_accuracy: 0.5802 - val_loss: 0.6772\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5630 - loss: 0.6830 - val_accuracy: 0.5604 - val_loss: 0.6802\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5676 - loss: 0.6742 - val_accuracy: 0.5297 - val_loss: 0.6935\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.6021 - loss: 0.6627 - val_accuracy: 0.5153 - val_loss: 0.6901\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6049 - loss: 0.6491 - val_accuracy: 0.5477 - val_loss: 0.6747\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6305 - loss: 0.6229 - val_accuracy: 0.5766 - val_loss: 0.7083\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6533 - loss: 0.6144 - val_accuracy: 0.5441 - val_loss: 0.6882\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6462 - loss: 0.6124 - val_accuracy: 0.5712 - val_loss: 0.7370\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6784 - loss: 0.5772 - val_accuracy: 0.5568 - val_loss: 0.7385\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7242 - loss: 0.5490 - val_accuracy: 0.4811 - val_loss: 2.6561\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7107 - loss: 0.5507 - val_accuracy: 0.5838 - val_loss: 0.7925\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7349 - loss: 0.5197 - val_accuracy: 0.5387 - val_loss: 0.7855\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7248 - loss: 0.5142 - val_accuracy: 0.4829 - val_loss: 2.5295\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7642 - loss: 0.4731 - val_accuracy: 0.6180 - val_loss: 0.6868\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7993 - loss: 0.4416 - val_accuracy: 0.4811 - val_loss: 3.8850\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8127 - loss: 0.3892 - val_accuracy: 0.5225 - val_loss: 2.3413\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8489 - loss: 0.3636 - val_accuracy: 0.5514 - val_loss: 1.3402\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8175 - loss: 0.3888 - val_accuracy: 0.5189 - val_loss: 2.2679\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8736 - loss: 0.3137 - val_accuracy: 0.5514 - val_loss: 1.8573\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8713 - loss: 0.2942 - val_accuracy: 0.6396 - val_loss: 0.9520\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9062 - loss: 0.2490 - val_accuracy: 0.4937 - val_loss: 4.3108\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9372 - loss: 0.1903 - val_accuracy: 0.6450 - val_loss: 0.9325\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9424 - loss: 0.1873 - val_accuracy: 0.4829 - val_loss: 11.4169\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9456 - loss: 0.1702 - val_accuracy: 0.5207 - val_loss: 4.0800\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9476 - loss: 0.1633 - val_accuracy: 0.6541 - val_loss: 0.9595\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9740 - loss: 0.1101 - val_accuracy: 0.5946 - val_loss: 1.3036\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9568 - loss: 0.1379 - val_accuracy: 0.4955 - val_loss: 5.3581\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9721 - loss: 0.1020 - val_accuracy: 0.4811 - val_loss: 19.8223\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9773 - loss: 0.0845 - val_accuracy: 0.5351 - val_loss: 3.5748\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9743 - loss: 0.0853 - val_accuracy: 0.5225 - val_loss: 5.1880\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9875 - loss: 0.0636 - val_accuracy: 0.5369 - val_loss: 3.2401\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9905 - loss: 0.0475 - val_accuracy: 0.4829 - val_loss: 17.9520\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9949 - loss: 0.0415 - val_accuracy: 0.4811 - val_loss: 13.5100\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9927 - loss: 0.0434 - val_accuracy: 0.4811 - val_loss: 24.5793\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9835 - loss: 0.0687 - val_accuracy: 0.5207 - val_loss: 6.9551\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5224 - loss: 1.3426\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 101ms/step - accuracy: 0.4935 - loss: 1.1942 - val_accuracy: 0.5189 - val_loss: 0.6928\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5431 - loss: 0.6922 - val_accuracy: 0.5189 - val_loss: 0.6926\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5489 - loss: 0.6910 - val_accuracy: 0.5189 - val_loss: 0.6924\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5670 - loss: 0.6891 - val_accuracy: 0.5189 - val_loss: 0.6924\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5504 - loss: 0.6897 - val_accuracy: 0.5189 - val_loss: 0.6925\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5361 - loss: 0.6907 - val_accuracy: 0.5189 - val_loss: 0.6926\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5549 - loss: 0.6884 - val_accuracy: 0.5189 - val_loss: 0.6928\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.5304 - loss: 0.6913 - val_accuracy: 0.5189 - val_loss: 0.6929\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5336 - loss: 0.6909 - val_accuracy: 0.5189 - val_loss: 0.6930\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5377 - loss: 0.6903 - val_accuracy: 0.5189 - val_loss: 0.6932\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5183 - loss: 0.6933 - val_accuracy: 0.5189 - val_loss: 0.6933\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.2161 - loss: 0.6985 \n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.5301 - loss: 1.0575 - val_accuracy: 0.5514 - val_loss: 0.7006\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5456 - loss: 0.8118 - val_accuracy: 0.5207 - val_loss: 0.7028\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6091 - loss: 0.6958 - val_accuracy: 0.5279 - val_loss: 0.6966\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6044 - loss: 0.7036 - val_accuracy: 0.5297 - val_loss: 0.7302\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6159 - loss: 0.6609 - val_accuracy: 0.6018 - val_loss: 0.6702\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6140 - loss: 0.6629 - val_accuracy: 0.5459 - val_loss: 0.6942\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6764 - loss: 0.5959 - val_accuracy: 0.4811 - val_loss: 7.3187\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6871 - loss: 0.5828 - val_accuracy: 0.5351 - val_loss: 1.0071\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6992 - loss: 0.5789 - val_accuracy: 0.5189 - val_loss: 1.6073\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7215 - loss: 0.5527 - val_accuracy: 0.5189 - val_loss: 1.4540\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7848 - loss: 0.4782 - val_accuracy: 0.5189 - val_loss: 1.8415\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7400 - loss: 0.5017 - val_accuracy: 0.6288 - val_loss: 0.6752\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7643 - loss: 0.4481 - val_accuracy: 0.4811 - val_loss: 11.1025\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8055 - loss: 0.3975 - val_accuracy: 0.4721 - val_loss: 10.9156\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8432 - loss: 0.3623 - val_accuracy: 0.4793 - val_loss: 24.8472\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8237 - loss: 0.3942 - val_accuracy: 0.5189 - val_loss: 3.5389\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8557 - loss: 0.3305 - val_accuracy: 0.4685 - val_loss: 20.2766\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8894 - loss: 0.2908 - val_accuracy: 0.4667 - val_loss: 13.3687\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9026 - loss: 0.2342 - val_accuracy: 0.5189 - val_loss: 7.4452\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9068 - loss: 0.2327 - val_accuracy: 0.5333 - val_loss: 4.9513\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9218 - loss: 0.2050 - val_accuracy: 0.5189 - val_loss: 5.8847\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9314 - loss: 0.1854 - val_accuracy: 0.5333 - val_loss: 5.5111\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7200 - loss: 0.5493\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.5110 - loss: 1.0140 - val_accuracy: 0.5189 - val_loss: 0.6930\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5522 - loss: 0.6924 - val_accuracy: 0.5171 - val_loss: 0.6927\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5730 - loss: 0.6900 - val_accuracy: 0.5189 - val_loss: 0.6925\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5580 - loss: 0.6859 - val_accuracy: 0.5387 - val_loss: 0.6910\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5694 - loss: 0.6822 - val_accuracy: 0.5171 - val_loss: 0.6926\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5751 - loss: 0.6822 - val_accuracy: 0.5225 - val_loss: 0.6888\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5920 - loss: 0.6788 - val_accuracy: 0.5459 - val_loss: 0.6863\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5842 - loss: 0.6702 - val_accuracy: 0.5351 - val_loss: 0.6911\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6024 - loss: 0.6658 - val_accuracy: 0.5297 - val_loss: 0.6924\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5926 - loss: 0.6697 - val_accuracy: 0.5297 - val_loss: 0.6940\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6200 - loss: 0.6612 - val_accuracy: 0.5748 - val_loss: 0.7056\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6336 - loss: 0.6457 - val_accuracy: 0.5441 - val_loss: 0.6970\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6259 - loss: 0.6513 - val_accuracy: 0.5405 - val_loss: 0.6903\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6266 - loss: 0.6476 - val_accuracy: 0.5459 - val_loss: 0.6973\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6294 - loss: 0.6406 - val_accuracy: 0.5297 - val_loss: 0.6943\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6588 - loss: 0.6353 - val_accuracy: 0.5441 - val_loss: 0.6936\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6433 - loss: 0.6333 - val_accuracy: 0.5189 - val_loss: 0.7030\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6370 - loss: 0.6375 - val_accuracy: 0.5423 - val_loss: 1.3689\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6511 - loss: 0.6235 - val_accuracy: 0.5622 - val_loss: 0.7171\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6581 - loss: 0.6127 - val_accuracy: 0.5676 - val_loss: 0.7082\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6716 - loss: 0.6045 - val_accuracy: 0.5063 - val_loss: 1.3211\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4657 - loss: 0.6710\n",
      "testing model 2 out of 12\n",
      "testing params: max, 5, 9, 32,0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 0.5159 - loss: 0.8281 - val_accuracy: 0.5315 - val_loss: 0.6951\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6296 - loss: 0.6418 - val_accuracy: 0.5207 - val_loss: 0.7043\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6445 - loss: 0.6176 - val_accuracy: 0.5207 - val_loss: 0.7147\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6886 - loss: 0.5859 - val_accuracy: 0.4757 - val_loss: 1.0564\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7181 - loss: 0.5568 - val_accuracy: 0.5207 - val_loss: 1.5251\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7556 - loss: 0.5145 - val_accuracy: 0.4793 - val_loss: 2.0151\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7780 - loss: 0.4864 - val_accuracy: 0.5243 - val_loss: 0.9175\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7779 - loss: 0.4780 - val_accuracy: 0.4649 - val_loss: 1.8266\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8250 - loss: 0.3990 - val_accuracy: 0.5207 - val_loss: 6.8637\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8571 - loss: 0.3569 - val_accuracy: 0.5315 - val_loss: 1.3570\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8680 - loss: 0.3195 - val_accuracy: 0.4793 - val_loss: 6.4246\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.2727 - loss: 0.7940\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.5318 - loss: 0.7673 - val_accuracy: 0.5423 - val_loss: 0.6851\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6116 - loss: 0.6548 - val_accuracy: 0.5586 - val_loss: 0.6881\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6573 - loss: 0.6194 - val_accuracy: 0.5874 - val_loss: 0.6801\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6479 - loss: 0.6063 - val_accuracy: 0.4793 - val_loss: 0.7796\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7199 - loss: 0.5389 - val_accuracy: 0.5604 - val_loss: 0.6775\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7532 - loss: 0.5090 - val_accuracy: 0.5225 - val_loss: 1.4031\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7821 - loss: 0.4823 - val_accuracy: 0.4829 - val_loss: 1.5639\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7934 - loss: 0.4522 - val_accuracy: 0.5207 - val_loss: 2.4133\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7764 - loss: 0.4615 - val_accuracy: 0.5189 - val_loss: 0.9102\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8861 - loss: 0.3305 - val_accuracy: 0.6396 - val_loss: 0.6814\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8801 - loss: 0.3164 - val_accuracy: 0.5207 - val_loss: 3.6054\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9155 - loss: 0.2721 - val_accuracy: 0.4811 - val_loss: 7.8528\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9348 - loss: 0.2156 - val_accuracy: 0.4811 - val_loss: 8.9024\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9302 - loss: 0.2076 - val_accuracy: 0.4847 - val_loss: 3.4200\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9479 - loss: 0.1525 - val_accuracy: 0.4811 - val_loss: 7.8272\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9796 - loss: 0.0991 - val_accuracy: 0.5189 - val_loss: 4.4377\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9792 - loss: 0.0824 - val_accuracy: 0.4811 - val_loss: 7.0785\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9932 - loss: 0.0562 - val_accuracy: 0.4883 - val_loss: 6.2421\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9947 - loss: 0.0447 - val_accuracy: 0.5261 - val_loss: 3.9885\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9962 - loss: 0.0425 - val_accuracy: 0.5459 - val_loss: 2.1052\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7176 - loss: 0.5602\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.5546 - loss: 0.7154 - val_accuracy: 0.5189 - val_loss: 0.8654\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6633 - loss: 0.6047 - val_accuracy: 0.5189 - val_loss: 0.7173\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7081 - loss: 0.5690 - val_accuracy: 0.5910 - val_loss: 0.6831\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7454 - loss: 0.5349 - val_accuracy: 0.6685 - val_loss: 0.6448\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7402 - loss: 0.5239 - val_accuracy: 0.5189 - val_loss: 0.7550\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7824 - loss: 0.4684 - val_accuracy: 0.5225 - val_loss: 1.7805\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8051 - loss: 0.4414 - val_accuracy: 0.5207 - val_loss: 1.2458\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8454 - loss: 0.3594 - val_accuracy: 0.5225 - val_loss: 1.4907\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8704 - loss: 0.3271 - val_accuracy: 0.5207 - val_loss: 2.6600\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9077 - loss: 0.2584 - val_accuracy: 0.6234 - val_loss: 0.7685\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9232 - loss: 0.2173 - val_accuracy: 0.5928 - val_loss: 1.0148\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9428 - loss: 0.1948 - val_accuracy: 0.5874 - val_loss: 1.1552\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9482 - loss: 0.1651 - val_accuracy: 0.4811 - val_loss: 11.9009\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9817 - loss: 0.0904 - val_accuracy: 0.4811 - val_loss: 14.8985\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7096 - loss: 0.6226\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.5261 - loss: 0.8339 - val_accuracy: 0.5189 - val_loss: 0.6889\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6164 - loss: 0.6439 - val_accuracy: 0.5189 - val_loss: 0.6962\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6090 - loss: 0.6410 - val_accuracy: 0.5189 - val_loss: 0.7492\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6610 - loss: 0.5992 - val_accuracy: 0.5532 - val_loss: 0.7594\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6968 - loss: 0.5710 - val_accuracy: 0.5189 - val_loss: 0.8449\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7419 - loss: 0.5354 - val_accuracy: 0.5712 - val_loss: 0.6957\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7522 - loss: 0.5006 - val_accuracy: 0.4811 - val_loss: 3.7359\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7764 - loss: 0.4662 - val_accuracy: 0.5189 - val_loss: 1.6407\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7725 - loss: 0.4655 - val_accuracy: 0.6054 - val_loss: 0.8171\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8523 - loss: 0.3712 - val_accuracy: 0.5189 - val_loss: 3.7093\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8674 - loss: 0.3329 - val_accuracy: 0.5189 - val_loss: 7.7104\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8908 - loss: 0.2870 - val_accuracy: 0.5351 - val_loss: 2.5448\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9210 - loss: 0.2326 - val_accuracy: 0.5261 - val_loss: 5.1444\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9211 - loss: 0.2185 - val_accuracy: 0.4829 - val_loss: 5.0646\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9587 - loss: 0.1465 - val_accuracy: 0.4793 - val_loss: 7.0534\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9643 - loss: 0.1166 - val_accuracy: 0.4811 - val_loss: 5.4950\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9928 - loss: 0.0751 - val_accuracy: 0.5189 - val_loss: 30.5691\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9556 - loss: 0.1264 - val_accuracy: 0.5225 - val_loss: 7.2020\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9858 - loss: 0.0564 - val_accuracy: 0.5351 - val_loss: 3.4155\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7372 - loss: 0.5813\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.5570 - loss: 0.7292 - val_accuracy: 0.5189 - val_loss: 0.7547\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6100 - loss: 0.6521 - val_accuracy: 0.4811 - val_loss: 0.7283\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6686 - loss: 0.6152 - val_accuracy: 0.5622 - val_loss: 0.6813\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6765 - loss: 0.5952 - val_accuracy: 0.4793 - val_loss: 0.7628\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6941 - loss: 0.5745 - val_accuracy: 0.4811 - val_loss: 1.3976\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7230 - loss: 0.5423 - val_accuracy: 0.4811 - val_loss: 1.6827\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7078 - loss: 0.5469 - val_accuracy: 0.5189 - val_loss: 1.1654\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7687 - loss: 0.4698 - val_accuracy: 0.4793 - val_loss: 2.9404\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8006 - loss: 0.4282 - val_accuracy: 0.5874 - val_loss: 0.6695\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8216 - loss: 0.4021 - val_accuracy: 0.4793 - val_loss: 3.3047\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8453 - loss: 0.3679 - val_accuracy: 0.5207 - val_loss: 3.3636\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8685 - loss: 0.3272 - val_accuracy: 0.5405 - val_loss: 1.6343\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8862 - loss: 0.2833 - val_accuracy: 0.5207 - val_loss: 1.5791\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9450 - loss: 0.1814 - val_accuracy: 0.5207 - val_loss: 2.9050\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9450 - loss: 0.1717 - val_accuracy: 0.4811 - val_loss: 6.3933\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9580 - loss: 0.1409 - val_accuracy: 0.5207 - val_loss: 10.4731\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9828 - loss: 0.0878 - val_accuracy: 0.5207 - val_loss: 5.1005\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9849 - loss: 0.0694 - val_accuracy: 0.5207 - val_loss: 3.7146\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9909 - loss: 0.0513 - val_accuracy: 0.5189 - val_loss: 12.2166\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7918 - loss: 0.5428\n",
      "testing model 3 out of 12\n",
      "testing params: average, 3, 9, 32,0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 74ms/step - accuracy: 0.5345 - loss: 0.7592 - val_accuracy: 0.5135 - val_loss: 0.6886\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5696 - loss: 0.6618 - val_accuracy: 0.5459 - val_loss: 0.6947\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5868 - loss: 0.6451 - val_accuracy: 0.5261 - val_loss: 0.6887\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5936 - loss: 0.6497 - val_accuracy: 0.4919 - val_loss: 0.6889\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6035 - loss: 0.6476 - val_accuracy: 0.5369 - val_loss: 0.6858\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6381 - loss: 0.6224 - val_accuracy: 0.4847 - val_loss: 1.3107\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6288 - loss: 0.6028 - val_accuracy: 0.5495 - val_loss: 0.8616\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6297 - loss: 0.5790 - val_accuracy: 0.5405 - val_loss: 1.1528\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6716 - loss: 0.5616 - val_accuracy: 0.5784 - val_loss: 0.8264\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6719 - loss: 0.5509 - val_accuracy: 0.5441 - val_loss: 1.2779\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6813 - loss: 0.5383 - val_accuracy: 0.5802 - val_loss: 0.7837\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7131 - loss: 0.5075 - val_accuracy: 0.5532 - val_loss: 1.3363\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7144 - loss: 0.5046 - val_accuracy: 0.5171 - val_loss: 1.4986\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7310 - loss: 0.4683 - val_accuracy: 0.5874 - val_loss: 0.7495\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7640 - loss: 0.4532 - val_accuracy: 0.5495 - val_loss: 1.1177\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7764 - loss: 0.4214 - val_accuracy: 0.5081 - val_loss: 2.5001\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7805 - loss: 0.4339 - val_accuracy: 0.5622 - val_loss: 1.0307\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8212 - loss: 0.3672 - val_accuracy: 0.5315 - val_loss: 1.5828\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8230 - loss: 0.3797 - val_accuracy: 0.5333 - val_loss: 2.8127\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8321 - loss: 0.3437 - val_accuracy: 0.5333 - val_loss: 2.8160\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8726 - loss: 0.3040 - val_accuracy: 0.6180 - val_loss: 0.9750\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8517 - loss: 0.2895 - val_accuracy: 0.5387 - val_loss: 1.1952\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8792 - loss: 0.2603 - val_accuracy: 0.5441 - val_loss: 1.7616\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8692 - loss: 0.2826 - val_accuracy: 0.5333 - val_loss: 2.5615\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8928 - loss: 0.2424 - val_accuracy: 0.5477 - val_loss: 1.9315\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8987 - loss: 0.2240 - val_accuracy: 0.5459 - val_loss: 2.8515\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9123 - loss: 0.1936 - val_accuracy: 0.4955 - val_loss: 3.2774\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9075 - loss: 0.1984 - val_accuracy: 0.6180 - val_loss: 1.7035\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9167 - loss: 0.1824 - val_accuracy: 0.5423 - val_loss: 2.6277\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9320 - loss: 0.1622 - val_accuracy: 0.5297 - val_loss: 4.3326\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9238 - loss: 0.1667 - val_accuracy: 0.6072 - val_loss: 2.3068\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6942 - loss: 0.7922\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.5328 - loss: 0.8046 - val_accuracy: 0.5171 - val_loss: 0.7083\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5787 - loss: 0.6855 - val_accuracy: 0.5099 - val_loss: 0.7066\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6024 - loss: 0.6766 - val_accuracy: 0.5423 - val_loss: 0.7118\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6505 - loss: 0.6206 - val_accuracy: 0.4811 - val_loss: 1.6273\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6723 - loss: 0.5947 - val_accuracy: 0.5207 - val_loss: 0.7238\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7092 - loss: 0.5576 - val_accuracy: 0.5189 - val_loss: 1.0571\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7106 - loss: 0.5360 - val_accuracy: 0.4811 - val_loss: 3.5807\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7539 - loss: 0.4947 - val_accuracy: 0.5171 - val_loss: 1.4862\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7725 - loss: 0.4580 - val_accuracy: 0.5423 - val_loss: 1.0117\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7550 - loss: 0.4915 - val_accuracy: 0.5189 - val_loss: 3.5900\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8072 - loss: 0.4318 - val_accuracy: 0.5081 - val_loss: 1.8585\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8273 - loss: 0.3909 - val_accuracy: 0.5261 - val_loss: 1.7444\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8456 - loss: 0.3675 - val_accuracy: 0.4847 - val_loss: 2.3610\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6001 - loss: 0.6633\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.5404 - loss: 0.7296 - val_accuracy: 0.5676 - val_loss: 0.6845\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6100 - loss: 0.6451 - val_accuracy: 0.5441 - val_loss: 0.6790\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6328 - loss: 0.6281 - val_accuracy: 0.5189 - val_loss: 0.6752\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6295 - loss: 0.6162 - val_accuracy: 0.5207 - val_loss: 0.9507\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6432 - loss: 0.6095 - val_accuracy: 0.5676 - val_loss: 0.6787\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6678 - loss: 0.5773 - val_accuracy: 0.5207 - val_loss: 0.9538\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6684 - loss: 0.5914 - val_accuracy: 0.5189 - val_loss: 0.8489\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6849 - loss: 0.5754 - val_accuracy: 0.5189 - val_loss: 0.6878\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6768 - loss: 0.5650 - val_accuracy: 0.5189 - val_loss: 0.9748\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7228 - loss: 0.5303 - val_accuracy: 0.5189 - val_loss: 1.0013\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7101 - loss: 0.5352 - val_accuracy: 0.5495 - val_loss: 1.0325\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7739 - loss: 0.6861\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 0.5389 - loss: 0.7665 - val_accuracy: 0.5189 - val_loss: 0.6823\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5417 - loss: 0.6659 - val_accuracy: 0.5243 - val_loss: 0.6889\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5749 - loss: 0.6656 - val_accuracy: 0.5676 - val_loss: 0.6614\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6049 - loss: 0.6405 - val_accuracy: 0.5423 - val_loss: 0.6840\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6137 - loss: 0.6252 - val_accuracy: 0.5207 - val_loss: 0.6827\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6423 - loss: 0.6238 - val_accuracy: 0.5441 - val_loss: 0.6846\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6286 - loss: 0.6188 - val_accuracy: 0.5964 - val_loss: 0.7671\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6694 - loss: 0.5985 - val_accuracy: 0.5640 - val_loss: 0.7493\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6991 - loss: 0.5700 - val_accuracy: 0.5910 - val_loss: 0.7786\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7039 - loss: 0.5744 - val_accuracy: 0.5694 - val_loss: 1.3492\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7145 - loss: 0.5578 - val_accuracy: 0.5748 - val_loss: 0.7136\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7165 - loss: 0.5449 - val_accuracy: 0.5550 - val_loss: 0.8184\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7231 - loss: 0.5553 - val_accuracy: 0.5441 - val_loss: 0.9944\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7277 - loss: 0.5286 - val_accuracy: 0.5748 - val_loss: 0.9146\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7608 - loss: 0.4942 - val_accuracy: 0.5586 - val_loss: 0.8818\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7825 - loss: 0.4874 - val_accuracy: 0.5802 - val_loss: 0.7766\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7734 - loss: 0.4715 - val_accuracy: 0.5604 - val_loss: 0.8033\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.4495 - loss: 0.9346\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.4975 - loss: 0.8573 - val_accuracy: 0.5189 - val_loss: 0.6929\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5405 - loss: 0.6925 - val_accuracy: 0.5189 - val_loss: 0.6927\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5443 - loss: 0.6916 - val_accuracy: 0.5189 - val_loss: 0.6925\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5524 - loss: 0.6905 - val_accuracy: 0.5189 - val_loss: 0.6924\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5437 - loss: 0.6905 - val_accuracy: 0.5189 - val_loss: 0.6925\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5506 - loss: 0.6895 - val_accuracy: 0.5189 - val_loss: 0.6926\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5609 - loss: 0.6880 - val_accuracy: 0.5189 - val_loss: 0.6927\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5481 - loss: 0.6891 - val_accuracy: 0.5189 - val_loss: 0.6928\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5479 - loss: 0.6890 - val_accuracy: 0.5189 - val_loss: 0.6930\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5352 - loss: 0.6907 - val_accuracy: 0.5189 - val_loss: 0.6931\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5469 - loss: 0.6889 - val_accuracy: 0.5189 - val_loss: 0.6932\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.2161 - loss: 0.6965\n",
      "testing model 4 out of 12\n",
      "testing params: average, 5, 9, 32,0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 61ms/step - accuracy: 0.5396 - loss: 0.7004 - val_accuracy: 0.5207 - val_loss: 0.7846\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6078 - loss: 0.6650 - val_accuracy: 0.5604 - val_loss: 0.6889\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5976 - loss: 0.6565 - val_accuracy: 0.5243 - val_loss: 0.7062\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6052 - loss: 0.6464 - val_accuracy: 0.4937 - val_loss: 0.7159\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6189 - loss: 0.6311 - val_accuracy: 0.5207 - val_loss: 0.7615\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6357 - loss: 0.6186 - val_accuracy: 0.4793 - val_loss: 0.8227\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6124 - loss: 0.6494 - val_accuracy: 0.5279 - val_loss: 3.2162\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6546 - loss: 0.6173 - val_accuracy: 0.5441 - val_loss: 0.8804\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6435 - loss: 0.6190 - val_accuracy: 0.5477 - val_loss: 0.7613\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6666 - loss: 0.5959 - val_accuracy: 0.5387 - val_loss: 0.7692\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6854 - loss: 0.5900 - val_accuracy: 0.5369 - val_loss: 2.6201\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6658 - loss: 0.5938 - val_accuracy: 0.5423 - val_loss: 1.2600\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5609 - loss: 0.6922\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5316 - loss: 0.7029 - val_accuracy: 0.4973 - val_loss: 0.7135\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6022 - loss: 0.6589 - val_accuracy: 0.5369 - val_loss: 0.6938\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6188 - loss: 0.6498 - val_accuracy: 0.5279 - val_loss: 0.6916\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6285 - loss: 0.6425 - val_accuracy: 0.5261 - val_loss: 0.6905\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6267 - loss: 0.6394 - val_accuracy: 0.5387 - val_loss: 0.6956\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6628 - loss: 0.6262 - val_accuracy: 0.5441 - val_loss: 0.6741\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6476 - loss: 0.6284 - val_accuracy: 0.4811 - val_loss: 0.7708\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6207 - loss: 0.6265 - val_accuracy: 0.5225 - val_loss: 2.3256\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6576 - loss: 0.6151 - val_accuracy: 0.5279 - val_loss: 1.0630\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6508 - loss: 0.6074 - val_accuracy: 0.5640 - val_loss: 0.8489\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6807 - loss: 0.5876 - val_accuracy: 0.5477 - val_loss: 0.7194\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6774 - loss: 0.5830 - val_accuracy: 0.5802 - val_loss: 0.7050\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6760 - loss: 0.5843 - val_accuracy: 0.5532 - val_loss: 0.6984\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7006 - loss: 0.5623 - val_accuracy: 0.5207 - val_loss: 2.8903\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7037 - loss: 0.5699 - val_accuracy: 0.5423 - val_loss: 0.9198\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7240 - loss: 0.5412 - val_accuracy: 0.5928 - val_loss: 0.6822\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7025 - loss: 0.5541 - val_accuracy: 0.4793 - val_loss: 0.8114\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7168 - loss: 0.5489 - val_accuracy: 0.4811 - val_loss: 0.7992\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7364 - loss: 0.5207 - val_accuracy: 0.4793 - val_loss: 0.9137\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7417 - loss: 0.5229 - val_accuracy: 0.5207 - val_loss: 0.7439\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7467 - loss: 0.5093 - val_accuracy: 0.5189 - val_loss: 2.2512\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7509 - loss: 0.5077 - val_accuracy: 0.4847 - val_loss: 0.8528\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7699 - loss: 0.4885 - val_accuracy: 0.5640 - val_loss: 0.8776\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7836 - loss: 0.4633 - val_accuracy: 0.5369 - val_loss: 0.8632\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7837 - loss: 0.4556 - val_accuracy: 0.5946 - val_loss: 0.7780\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7942 - loss: 0.4641 - val_accuracy: 0.5153 - val_loss: 2.7841\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7931 - loss: 0.4628 - val_accuracy: 0.5243 - val_loss: 0.9118\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8290 - loss: 0.4192 - val_accuracy: 0.5099 - val_loss: 1.8983\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8098 - loss: 0.4236 - val_accuracy: 0.6216 - val_loss: 0.6812\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8162 - loss: 0.4072 - val_accuracy: 0.6126 - val_loss: 0.8482\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8186 - loss: 0.3920 - val_accuracy: 0.5207 - val_loss: 2.1580\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8302 - loss: 0.3828 - val_accuracy: 0.5225 - val_loss: 1.7948\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8703 - loss: 0.3482 - val_accuracy: 0.6270 - val_loss: 0.7833\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8607 - loss: 0.3376 - val_accuracy: 0.5153 - val_loss: 2.3510\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8590 - loss: 0.3335 - val_accuracy: 0.5838 - val_loss: 1.1358\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8895 - loss: 0.3134 - val_accuracy: 0.5441 - val_loss: 1.3357\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8661 - loss: 0.3142 - val_accuracy: 0.4847 - val_loss: 3.1578\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8943 - loss: 0.2841 - val_accuracy: 0.5730 - val_loss: 1.1323\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9111 - loss: 0.2576 - val_accuracy: 0.5135 - val_loss: 4.8502\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9223 - loss: 0.2322 - val_accuracy: 0.5297 - val_loss: 1.6548\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9235 - loss: 0.2310 - val_accuracy: 0.5207 - val_loss: 3.5872\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.9255 - loss: 0.2268 - val_accuracy: 0.5153 - val_loss: 4.7790\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.9379 - loss: 0.2075 - val_accuracy: 0.5063 - val_loss: 2.3262\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7690 - loss: 0.4993\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.5297 - loss: 0.7108 - val_accuracy: 0.5369 - val_loss: 0.6908\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6036 - loss: 0.6539 - val_accuracy: 0.5189 - val_loss: 0.7589\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6220 - loss: 0.6409 - val_accuracy: 0.5477 - val_loss: 0.6894\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6471 - loss: 0.6297 - val_accuracy: 0.5261 - val_loss: 0.6904\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6296 - loss: 0.6340 - val_accuracy: 0.5189 - val_loss: 1.5533\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6484 - loss: 0.6167 - val_accuracy: 0.5279 - val_loss: 0.7668\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7143 - loss: 0.5640 - val_accuracy: 0.5189 - val_loss: 3.1561\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6887 - loss: 0.5770 - val_accuracy: 0.5207 - val_loss: 3.1703\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6968 - loss: 0.5627 - val_accuracy: 0.5189 - val_loss: 1.0969\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7061 - loss: 0.5482 - val_accuracy: 0.5171 - val_loss: 1.5684\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7230 - loss: 0.5269 - val_accuracy: 0.5207 - val_loss: 0.9343\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7202 - loss: 0.5270 - val_accuracy: 0.5207 - val_loss: 5.6242\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7443 - loss: 0.5121 - val_accuracy: 0.5207 - val_loss: 1.5543\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6058 - loss: 0.6853\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.5193 - loss: 0.7133 - val_accuracy: 0.5730 - val_loss: 0.6841\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5793 - loss: 0.6591 - val_accuracy: 0.5315 - val_loss: 0.6966\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5875 - loss: 0.6635 - val_accuracy: 0.5099 - val_loss: 0.6892\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6170 - loss: 0.6303 - val_accuracy: 0.4811 - val_loss: 0.7048\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6282 - loss: 0.6296 - val_accuracy: 0.5189 - val_loss: 0.8810\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5475 - loss: 0.6823 - val_accuracy: 0.5189 - val_loss: 3.4009\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6340 - loss: 0.6259 - val_accuracy: 0.5351 - val_loss: 1.0004\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6632 - loss: 0.6115 - val_accuracy: 0.5243 - val_loss: 1.3959\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6445 - loss: 0.6159 - val_accuracy: 0.5171 - val_loss: 0.8050\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6632 - loss: 0.6003 - val_accuracy: 0.5694 - val_loss: 0.6970\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6491 - loss: 0.6064 - val_accuracy: 0.5622 - val_loss: 0.7042\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5037 - loss: 0.6983\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5330 - loss: 0.6987 - val_accuracy: 0.5279 - val_loss: 0.6891\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5861 - loss: 0.6649 - val_accuracy: 0.5189 - val_loss: 0.7266\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5904 - loss: 0.6603 - val_accuracy: 0.5189 - val_loss: 0.7497\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5792 - loss: 0.6548 - val_accuracy: 0.5153 - val_loss: 0.7466\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6113 - loss: 0.6433 - val_accuracy: 0.5568 - val_loss: 0.7045\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5935 - loss: 0.6498 - val_accuracy: 0.5568 - val_loss: 0.6775\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6361 - loss: 0.6268 - val_accuracy: 0.5640 - val_loss: 0.6801\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6442 - loss: 0.6211 - val_accuracy: 0.5640 - val_loss: 0.6810\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6745 - loss: 0.6070 - val_accuracy: 0.5622 - val_loss: 0.6705\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6823 - loss: 0.6011 - val_accuracy: 0.5495 - val_loss: 0.6729\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6769 - loss: 0.5979 - val_accuracy: 0.5586 - val_loss: 0.6638\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6708 - loss: 0.5947 - val_accuracy: 0.5568 - val_loss: 0.6634\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6965 - loss: 0.5814 - val_accuracy: 0.5712 - val_loss: 0.6673\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6977 - loss: 0.5776 - val_accuracy: 0.5820 - val_loss: 0.6567\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7129 - loss: 0.5591 - val_accuracy: 0.5694 - val_loss: 0.6651\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7114 - loss: 0.5563 - val_accuracy: 0.5694 - val_loss: 0.6732\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6993 - loss: 0.5492 - val_accuracy: 0.5658 - val_loss: 0.6487\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7355 - loss: 0.5324 - val_accuracy: 0.5820 - val_loss: 0.6606\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7280 - loss: 0.5265 - val_accuracy: 0.5586 - val_loss: 0.7283\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7439 - loss: 0.5247 - val_accuracy: 0.5514 - val_loss: 0.7056\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7557 - loss: 0.4972 - val_accuracy: 0.4811 - val_loss: 0.7503\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7693 - loss: 0.4845 - val_accuracy: 0.5586 - val_loss: 1.0277\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7697 - loss: 0.4747 - val_accuracy: 0.5748 - val_loss: 0.7021\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7747 - loss: 0.4735 - val_accuracy: 0.5586 - val_loss: 0.7659\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5772 - loss: 0.6686\n",
      "testing model 5 out of 12\n",
      "testing params: max, 3, 9, 32,0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 74ms/step - accuracy: 0.5319 - loss: 0.8186 - val_accuracy: 0.5207 - val_loss: 0.6930\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6441 - loss: 0.6267 - val_accuracy: 0.5207 - val_loss: 0.7156\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6718 - loss: 0.6007 - val_accuracy: 0.5207 - val_loss: 0.7763\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6975 - loss: 0.5579 - val_accuracy: 0.5207 - val_loss: 0.8193\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7552 - loss: 0.4966 - val_accuracy: 0.5207 - val_loss: 0.7806\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7695 - loss: 0.4815 - val_accuracy: 0.5117 - val_loss: 0.7257\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7979 - loss: 0.4460 - val_accuracy: 0.5189 - val_loss: 0.8851\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8201 - loss: 0.3996 - val_accuracy: 0.5261 - val_loss: 0.6910\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8565 - loss: 0.3464 - val_accuracy: 0.5297 - val_loss: 1.4499\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9208 - loss: 0.2737 - val_accuracy: 0.5207 - val_loss: 1.9493\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9276 - loss: 0.2523 - val_accuracy: 0.5748 - val_loss: 0.9948\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9591 - loss: 0.2072 - val_accuracy: 0.5261 - val_loss: 2.2447\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9677 - loss: 0.1838 - val_accuracy: 0.5820 - val_loss: 0.8869\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9645 - loss: 0.1702 - val_accuracy: 0.5261 - val_loss: 1.3723\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9738 - loss: 0.1478 - val_accuracy: 0.5459 - val_loss: 1.5781\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9878 - loss: 0.1174 - val_accuracy: 0.5568 - val_loss: 1.5911\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9961 - loss: 0.0846 - val_accuracy: 0.6595 - val_loss: 0.7065\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9942 - loss: 0.0707 - val_accuracy: 0.4775 - val_loss: 5.9433\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9969 - loss: 0.0603 - val_accuracy: 0.4955 - val_loss: 2.1985\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0540 - val_accuracy: 0.5243 - val_loss: 7.5517\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9939 - loss: 0.0560 - val_accuracy: 0.7063 - val_loss: 0.6646\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9952 - loss: 0.0605 - val_accuracy: 0.4883 - val_loss: 3.5681\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9987 - loss: 0.0311 - val_accuracy: 0.4811 - val_loss: 4.1865\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9992 - loss: 0.0284 - val_accuracy: 0.5297 - val_loss: 2.5310\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0251 - val_accuracy: 0.4919 - val_loss: 3.8502\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9978 - loss: 0.0318 - val_accuracy: 0.4793 - val_loss: 7.0272\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0189 - val_accuracy: 0.5369 - val_loss: 2.7006\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0138 - val_accuracy: 0.5279 - val_loss: 5.1250\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9997 - loss: 0.0145 - val_accuracy: 0.5423 - val_loss: 2.9119\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.4811 - val_loss: 5.5884\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0123 - val_accuracy: 0.5964 - val_loss: 1.7246\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6521 - loss: 0.7446\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.5383 - loss: 0.7722 - val_accuracy: 0.5189 - val_loss: 0.6989\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6660 - loss: 0.6276 - val_accuracy: 0.5189 - val_loss: 0.7310\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6517 - loss: 0.6107 - val_accuracy: 0.5189 - val_loss: 0.8173\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6727 - loss: 0.5932 - val_accuracy: 0.5189 - val_loss: 0.7326\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7217 - loss: 0.5540 - val_accuracy: 0.5189 - val_loss: 0.7203\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7441 - loss: 0.5209 - val_accuracy: 0.5189 - val_loss: 0.7664\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7741 - loss: 0.4833 - val_accuracy: 0.5387 - val_loss: 0.6877\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7923 - loss: 0.4568 - val_accuracy: 0.5261 - val_loss: 0.7619\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8362 - loss: 0.4211 - val_accuracy: 0.5297 - val_loss: 0.9406\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8203 - loss: 0.4111 - val_accuracy: 0.5694 - val_loss: 0.9319\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8823 - loss: 0.3431 - val_accuracy: 0.5207 - val_loss: 1.7191\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8820 - loss: 0.3232 - val_accuracy: 0.5207 - val_loss: 0.9070\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9256 - loss: 0.2671 - val_accuracy: 0.6342 - val_loss: 0.6695\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9023 - loss: 0.2776 - val_accuracy: 0.5207 - val_loss: 2.2676\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9609 - loss: 0.1916 - val_accuracy: 0.5207 - val_loss: 6.8280\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9309 - loss: 0.2336 - val_accuracy: 0.4829 - val_loss: 2.7952\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9706 - loss: 0.1627 - val_accuracy: 0.5207 - val_loss: 4.3654\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9712 - loss: 0.1497 - val_accuracy: 0.5838 - val_loss: 0.9494\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9870 - loss: 0.1086 - val_accuracy: 0.5315 - val_loss: 1.8500\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9866 - loss: 0.1061 - val_accuracy: 0.4811 - val_loss: 8.8243\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9903 - loss: 0.0914 - val_accuracy: 0.5207 - val_loss: 3.7645\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9949 - loss: 0.0699 - val_accuracy: 0.5532 - val_loss: 1.9928\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9993 - loss: 0.0533 - val_accuracy: 0.6468 - val_loss: 1.0500\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9905 - loss: 0.0643 - val_accuracy: 0.4811 - val_loss: 5.8334\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9978 - loss: 0.0474 - val_accuracy: 0.4829 - val_loss: 4.5654\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9960 - loss: 0.0604 - val_accuracy: 0.7099 - val_loss: 0.7851\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9933 - loss: 0.0569 - val_accuracy: 0.6559 - val_loss: 0.8051\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0248 - val_accuracy: 0.4811 - val_loss: 7.1488\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9881 - loss: 0.0679 - val_accuracy: 0.5514 - val_loss: 2.8280\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.5441 - val_loss: 1.8344\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9981 - loss: 0.0299 - val_accuracy: 0.5459 - val_loss: 2.6891\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.5225 - val_loss: 3.8011\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0129 - val_accuracy: 0.5676 - val_loss: 2.1271\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0099 - val_accuracy: 0.6126 - val_loss: 1.4907\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.6865 - val_loss: 1.0582\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.7568 - val_loss: 0.5783\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.4811 - val_loss: 7.1927\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.7802 - val_loss: 0.5873\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0060 - val_accuracy: 0.6955 - val_loss: 0.8388\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.4847 - val_loss: 6.2098\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0051 - val_accuracy: 0.4811 - val_loss: 7.1430\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9976 - loss: 0.0158 - val_accuracy: 0.5261 - val_loss: 3.8005\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0073 - val_accuracy: 0.7225 - val_loss: 1.0003\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0040 - val_accuracy: 0.6486 - val_loss: 1.4111\n",
      "Epoch 45/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0042 - val_accuracy: 0.4991 - val_loss: 4.3526\n",
      "Epoch 46/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.6595 - val_loss: 1.1741\n",
      "Epoch 47/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 1.0000 - loss: 0.0029 - val_accuracy: 0.5550 - val_loss: 2.5714\n",
      "Epoch 48/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.5063 - val_loss: 4.7098\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8430 - loss: 0.4129\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.5297 - loss: 0.7972 - val_accuracy: 0.5189 - val_loss: 0.7111\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6504 - loss: 0.6158 - val_accuracy: 0.5189 - val_loss: 0.7413\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6807 - loss: 0.5776 - val_accuracy: 0.5189 - val_loss: 0.9037\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7197 - loss: 0.5494 - val_accuracy: 0.5189 - val_loss: 0.9996\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7367 - loss: 0.5234 - val_accuracy: 0.5189 - val_loss: 1.0784\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7447 - loss: 0.4984 - val_accuracy: 0.5189 - val_loss: 0.7890\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8136 - loss: 0.4232 - val_accuracy: 0.5514 - val_loss: 0.6746\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8526 - loss: 0.3844 - val_accuracy: 0.5207 - val_loss: 0.8604\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8632 - loss: 0.3511 - val_accuracy: 0.5171 - val_loss: 1.0798\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9187 - loss: 0.2858 - val_accuracy: 0.5207 - val_loss: 1.0281\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8998 - loss: 0.2877 - val_accuracy: 0.5405 - val_loss: 1.2216\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9410 - loss: 0.2260 - val_accuracy: 0.5243 - val_loss: 1.4518\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9667 - loss: 0.1802 - val_accuracy: 0.5207 - val_loss: 2.3021\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9731 - loss: 0.1616 - val_accuracy: 0.4811 - val_loss: 8.9110\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9689 - loss: 0.1514 - val_accuracy: 0.6054 - val_loss: 0.7520\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9876 - loss: 0.1141 - val_accuracy: 0.5243 - val_loss: 1.8330\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9864 - loss: 0.1102 - val_accuracy: 0.5225 - val_loss: 5.0563\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9790 - loss: 0.0998 - val_accuracy: 0.5207 - val_loss: 2.8843\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9937 - loss: 0.0759 - val_accuracy: 0.5207 - val_loss: 3.6274\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9936 - loss: 0.0815 - val_accuracy: 0.5243 - val_loss: 2.3182\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.9971 - loss: 0.0546 - val_accuracy: 0.6685 - val_loss: 0.7289\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9996 - loss: 0.0368 - val_accuracy: 0.6901 - val_loss: 0.7337\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9999 - loss: 0.0333 - val_accuracy: 0.5315 - val_loss: 2.0627\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9941 - loss: 0.0472 - val_accuracy: 0.5225 - val_loss: 4.8360\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9967 - loss: 0.0451 - val_accuracy: 0.4829 - val_loss: 7.4321\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9997 - loss: 0.0261 - val_accuracy: 0.5099 - val_loss: 3.8311\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9998 - loss: 0.0194 - val_accuracy: 0.6901 - val_loss: 0.8096\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.5225 - val_loss: 6.6024\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.5207 - val_loss: 7.1030\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9995 - loss: 0.0158 - val_accuracy: 0.5874 - val_loss: 1.5264\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.7081 - val_loss: 0.7924\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0120 - val_accuracy: 0.5225 - val_loss: 12.1472\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.5027 - val_loss: 4.7198\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0088 - val_accuracy: 0.6991 - val_loss: 0.8246\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9898 - loss: 0.0527 - val_accuracy: 0.5225 - val_loss: 5.3426\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9982 - loss: 0.0257 - val_accuracy: 0.5225 - val_loss: 3.1400\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.5261 - val_loss: 3.7857\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0067 - val_accuracy: 0.6216 - val_loss: 1.6899\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0057 - val_accuracy: 0.6000 - val_loss: 1.5296\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0058 - val_accuracy: 0.6721 - val_loss: 1.2403\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.7081 - val_loss: 0.9874\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7651 - loss: 0.6202\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 75ms/step - accuracy: 0.5190 - loss: 0.7567 - val_accuracy: 0.5189 - val_loss: 0.6911\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6113 - loss: 0.6375 - val_accuracy: 0.5207 - val_loss: 0.6883\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6494 - loss: 0.6155 - val_accuracy: 0.5189 - val_loss: 0.7588\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6921 - loss: 0.5660 - val_accuracy: 0.5189 - val_loss: 0.8156\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7304 - loss: 0.5377 - val_accuracy: 0.5189 - val_loss: 0.7636\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7660 - loss: 0.5011 - val_accuracy: 0.5351 - val_loss: 0.7742\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8128 - loss: 0.4518 - val_accuracy: 0.5423 - val_loss: 0.8113\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.7980 - loss: 0.4536 - val_accuracy: 0.5568 - val_loss: 0.7113\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8313 - loss: 0.4174 - val_accuracy: 0.5333 - val_loss: 0.8676\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8519 - loss: 0.3793 - val_accuracy: 0.6324 - val_loss: 0.6318\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8860 - loss: 0.3234 - val_accuracy: 0.6432 - val_loss: 0.6428\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9056 - loss: 0.2943 - val_accuracy: 0.6396 - val_loss: 0.6290\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9236 - loss: 0.2599 - val_accuracy: 0.6505 - val_loss: 0.6470\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9282 - loss: 0.2456 - val_accuracy: 0.5243 - val_loss: 3.5520\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9583 - loss: 0.2038 - val_accuracy: 0.5730 - val_loss: 0.9502\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9722 - loss: 0.1669 - val_accuracy: 0.6378 - val_loss: 0.6989\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9790 - loss: 0.1424 - val_accuracy: 0.6577 - val_loss: 0.7533\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9828 - loss: 0.1288 - val_accuracy: 0.4955 - val_loss: 2.9482\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9877 - loss: 0.1074 - val_accuracy: 0.6450 - val_loss: 0.8378\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9935 - loss: 0.0994 - val_accuracy: 0.5477 - val_loss: 1.5038\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9941 - loss: 0.0750 - val_accuracy: 0.4919 - val_loss: 3.9066\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9968 - loss: 0.0620 - val_accuracy: 0.5261 - val_loss: 4.4331\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9977 - loss: 0.0543 - val_accuracy: 0.5532 - val_loss: 1.7134\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9959 - loss: 0.0540 - val_accuracy: 0.5261 - val_loss: 7.5271\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 1.0000 - loss: 0.0449 - val_accuracy: 0.5982 - val_loss: 1.2918\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9995 - loss: 0.0329 - val_accuracy: 0.5243 - val_loss: 2.3975\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9888 - loss: 0.0595 - val_accuracy: 0.4811 - val_loss: 5.2062\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5632 - loss: 0.9916\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 77ms/step - accuracy: 0.5113 - loss: 0.8209 - val_accuracy: 0.5189 - val_loss: 0.7002\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6460 - loss: 0.6358 - val_accuracy: 0.5189 - val_loss: 0.7512\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6881 - loss: 0.5795 - val_accuracy: 0.5189 - val_loss: 0.8302\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7142 - loss: 0.5532 - val_accuracy: 0.5189 - val_loss: 0.9117\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7449 - loss: 0.5107 - val_accuracy: 0.5189 - val_loss: 0.8540\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7896 - loss: 0.4609 - val_accuracy: 0.5189 - val_loss: 0.8253\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8157 - loss: 0.4258 - val_accuracy: 0.5189 - val_loss: 0.9825\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8486 - loss: 0.3786 - val_accuracy: 0.5838 - val_loss: 0.6610\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8826 - loss: 0.3392 - val_accuracy: 0.5369 - val_loss: 0.7343\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9070 - loss: 0.2930 - val_accuracy: 0.5279 - val_loss: 1.2956\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9230 - loss: 0.2561 - val_accuracy: 0.5261 - val_loss: 1.0326\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9287 - loss: 0.2347 - val_accuracy: 0.5730 - val_loss: 1.1539\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9811 - loss: 0.1643 - val_accuracy: 0.5694 - val_loss: 1.0128\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9800 - loss: 0.1499 - val_accuracy: 0.4883 - val_loss: 1.8161\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9769 - loss: 0.1357 - val_accuracy: 0.6216 - val_loss: 0.7268\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9847 - loss: 0.1215 - val_accuracy: 0.5964 - val_loss: 0.8898\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9802 - loss: 0.1176 - val_accuracy: 0.5856 - val_loss: 1.0725\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9976 - loss: 0.0720 - val_accuracy: 0.4901 - val_loss: 4.0253\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9930 - loss: 0.0677 - val_accuracy: 0.5423 - val_loss: 2.1192\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9986 - loss: 0.0549 - val_accuracy: 0.4955 - val_loss: 3.2449\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9975 - loss: 0.0646 - val_accuracy: 0.5838 - val_loss: 1.3432\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9997 - loss: 0.0500 - val_accuracy: 0.5243 - val_loss: 4.0367\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9993 - loss: 0.0367 - val_accuracy: 0.5009 - val_loss: 2.6490\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9996 - loss: 0.0259 - val_accuracy: 0.5225 - val_loss: 4.5578\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9979 - loss: 0.0375 - val_accuracy: 0.5225 - val_loss: 7.9992\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5695 - loss: 0.8413\n",
      "testing model 6 out of 12\n",
      "testing params: max, 5, 9, 32,0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.5504 - loss: 0.7248 - val_accuracy: 0.5207 - val_loss: 0.6966\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6664 - loss: 0.6017 - val_accuracy: 0.5207 - val_loss: 0.7280\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6835 - loss: 0.5826 - val_accuracy: 0.5207 - val_loss: 0.7394\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7518 - loss: 0.5172 - val_accuracy: 0.5207 - val_loss: 0.7449\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7905 - loss: 0.4773 - val_accuracy: 0.5207 - val_loss: 0.7542\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8154 - loss: 0.4450 - val_accuracy: 0.5207 - val_loss: 0.7711\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8647 - loss: 0.3971 - val_accuracy: 0.5207 - val_loss: 0.7537\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8732 - loss: 0.3582 - val_accuracy: 0.5189 - val_loss: 0.7742\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9187 - loss: 0.3277 - val_accuracy: 0.5405 - val_loss: 0.7753\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9185 - loss: 0.3022 - val_accuracy: 0.5550 - val_loss: 0.7571\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9399 - loss: 0.2630 - val_accuracy: 0.5279 - val_loss: 1.1166\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9578 - loss: 0.2316 - val_accuracy: 0.5802 - val_loss: 0.7465\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9754 - loss: 0.1999 - val_accuracy: 0.5297 - val_loss: 1.0823\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9835 - loss: 0.1743 - val_accuracy: 0.6180 - val_loss: 0.6800\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9834 - loss: 0.1580 - val_accuracy: 0.6090 - val_loss: 0.6979\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9914 - loss: 0.1272 - val_accuracy: 0.5658 - val_loss: 1.0431\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9934 - loss: 0.1080 - val_accuracy: 0.5495 - val_loss: 1.2055\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9948 - loss: 0.0910 - val_accuracy: 0.6108 - val_loss: 0.8305\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9984 - loss: 0.0750 - val_accuracy: 0.6324 - val_loss: 0.7486\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9984 - loss: 0.0668 - val_accuracy: 0.5243 - val_loss: 2.2752\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9974 - loss: 0.0675 - val_accuracy: 0.5351 - val_loss: 1.7229\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9981 - loss: 0.0483 - val_accuracy: 0.4847 - val_loss: 3.0345\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9975 - loss: 0.0410 - val_accuracy: 0.5423 - val_loss: 1.7265\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9997 - loss: 0.0347 - val_accuracy: 0.6486 - val_loss: 0.7120\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0287 - val_accuracy: 0.5351 - val_loss: 1.7141\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0259 - val_accuracy: 0.5207 - val_loss: 1.8035\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9989 - loss: 0.0258 - val_accuracy: 0.6541 - val_loss: 0.7421\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9999 - loss: 0.0212 - val_accuracy: 0.5099 - val_loss: 2.4285\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0182 - val_accuracy: 0.5928 - val_loss: 1.1218\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.6144 - val_loss: 1.0093\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.6378 - val_loss: 0.9182\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.5207 - val_loss: 2.1934\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9986 - loss: 0.0218 - val_accuracy: 0.6306 - val_loss: 0.9783\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.6486 - val_loss: 0.8283\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.5946 - val_loss: 1.1642\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9997 - loss: 0.0085 - val_accuracy: 0.5640 - val_loss: 1.7026\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.6703 - val_loss: 0.7394\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0065 - val_accuracy: 0.5261 - val_loss: 3.9319\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.6342 - val_loss: 1.0778\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0062 - val_accuracy: 0.5820 - val_loss: 1.4814\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0046 - val_accuracy: 0.6252 - val_loss: 1.0853\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0044 - val_accuracy: 0.5874 - val_loss: 1.5491\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0045 - val_accuracy: 0.5261 - val_loss: 3.6652\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0036 - val_accuracy: 0.5784 - val_loss: 1.5569\n",
      "Epoch 45/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0035 - val_accuracy: 0.6324 - val_loss: 1.0385\n",
      "Epoch 46/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9998 - loss: 0.0069 - val_accuracy: 0.5297 - val_loss: 2.4666\n",
      "Epoch 47/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9691 - loss: 0.0922 - val_accuracy: 0.5207 - val_loss: 5.4830\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7148 - loss: 0.6951\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.5629 - loss: 0.9519 - val_accuracy: 0.5189 - val_loss: 1.0415\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6301 - loss: 0.6397 - val_accuracy: 0.5189 - val_loss: 1.0723\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6558 - loss: 0.6127 - val_accuracy: 0.5189 - val_loss: 0.9576\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6938 - loss: 0.5748 - val_accuracy: 0.5189 - val_loss: 0.9390\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7244 - loss: 0.5546 - val_accuracy: 0.5189 - val_loss: 1.0307\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7611 - loss: 0.5260 - val_accuracy: 0.5189 - val_loss: 1.0260\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7705 - loss: 0.5011 - val_accuracy: 0.5189 - val_loss: 0.7736\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8203 - loss: 0.4657 - val_accuracy: 0.5189 - val_loss: 1.0850\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8751 - loss: 0.4229 - val_accuracy: 0.5622 - val_loss: 0.7372\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8521 - loss: 0.4025 - val_accuracy: 0.5387 - val_loss: 0.7438\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8914 - loss: 0.3622 - val_accuracy: 0.6414 - val_loss: 0.6151\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9279 - loss: 0.3184 - val_accuracy: 0.5261 - val_loss: 1.1687\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9531 - loss: 0.2728 - val_accuracy: 0.5910 - val_loss: 0.8331\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9638 - loss: 0.2453 - val_accuracy: 0.5189 - val_loss: 2.1731\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9690 - loss: 0.2207 - val_accuracy: 0.5369 - val_loss: 0.9649\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9869 - loss: 0.1762 - val_accuracy: 0.5856 - val_loss: 0.8441\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9866 - loss: 0.1597 - val_accuracy: 0.4955 - val_loss: 1.6378\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9881 - loss: 0.1419 - val_accuracy: 0.5910 - val_loss: 0.7824\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9962 - loss: 0.1075 - val_accuracy: 0.6360 - val_loss: 0.7434\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9944 - loss: 0.0963 - val_accuracy: 0.4793 - val_loss: 2.2171\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9990 - loss: 0.0737 - val_accuracy: 0.5423 - val_loss: 1.1913\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5826 - loss: 0.6867\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.5611 - loss: 0.8205 - val_accuracy: 0.5189 - val_loss: 0.7111\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6593 - loss: 0.6110 - val_accuracy: 0.5189 - val_loss: 0.7494\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6798 - loss: 0.5862 - val_accuracy: 0.5189 - val_loss: 0.7538\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7138 - loss: 0.5554 - val_accuracy: 0.5189 - val_loss: 0.7838\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7549 - loss: 0.5116 - val_accuracy: 0.5189 - val_loss: 0.7766\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7773 - loss: 0.4860 - val_accuracy: 0.5189 - val_loss: 0.8147\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8174 - loss: 0.4513 - val_accuracy: 0.5189 - val_loss: 0.8065\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8464 - loss: 0.4327 - val_accuracy: 0.5189 - val_loss: 0.8838\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8664 - loss: 0.3961 - val_accuracy: 0.5766 - val_loss: 0.6855\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8791 - loss: 0.3801 - val_accuracy: 0.5351 - val_loss: 1.2000\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8861 - loss: 0.3527 - val_accuracy: 0.5405 - val_loss: 0.9669\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9098 - loss: 0.3181 - val_accuracy: 0.5910 - val_loss: 0.6742\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9423 - loss: 0.2830 - val_accuracy: 0.5225 - val_loss: 1.2122\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9538 - loss: 0.2591 - val_accuracy: 0.5820 - val_loss: 0.7141\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9591 - loss: 0.2342 - val_accuracy: 0.6216 - val_loss: 0.7533\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9814 - loss: 0.1884 - val_accuracy: 0.6054 - val_loss: 0.8429\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9875 - loss: 0.1622 - val_accuracy: 0.6595 - val_loss: 0.7052\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9929 - loss: 0.1533 - val_accuracy: 0.6126 - val_loss: 0.9258\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9900 - loss: 0.1257 - val_accuracy: 0.5243 - val_loss: 1.9160\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9962 - loss: 0.1082 - val_accuracy: 0.5243 - val_loss: 3.1242\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9915 - loss: 0.1021 - val_accuracy: 0.5982 - val_loss: 1.0936\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9969 - loss: 0.0834 - val_accuracy: 0.4919 - val_loss: 2.3224\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9991 - loss: 0.0690 - val_accuracy: 0.5207 - val_loss: 2.0011\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9970 - loss: 0.0709 - val_accuracy: 0.5622 - val_loss: 1.3124\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9993 - loss: 0.0464 - val_accuracy: 0.5658 - val_loss: 1.0553\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9966 - loss: 0.0510 - val_accuracy: 0.5982 - val_loss: 0.9389\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9995 - loss: 0.0362 - val_accuracy: 0.5640 - val_loss: 1.4185\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5660 - loss: 0.8580\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.5217 - loss: 0.7652 - val_accuracy: 0.5189 - val_loss: 0.6928\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6512 - loss: 0.6233 - val_accuracy: 0.5189 - val_loss: 0.7152\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7042 - loss: 0.5703 - val_accuracy: 0.5189 - val_loss: 0.7840\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7472 - loss: 0.5250 - val_accuracy: 0.5189 - val_loss: 0.7692\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7527 - loss: 0.5112 - val_accuracy: 0.5189 - val_loss: 0.7979\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8036 - loss: 0.4754 - val_accuracy: 0.5189 - val_loss: 0.8164\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8335 - loss: 0.4377 - val_accuracy: 0.5189 - val_loss: 0.9261\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8373 - loss: 0.4192 - val_accuracy: 0.5261 - val_loss: 0.7388\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8732 - loss: 0.3897 - val_accuracy: 0.5189 - val_loss: 1.2755\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8820 - loss: 0.3544 - val_accuracy: 0.5802 - val_loss: 0.6962\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9187 - loss: 0.3208 - val_accuracy: 0.5225 - val_loss: 1.0012\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9380 - loss: 0.2964 - val_accuracy: 0.6450 - val_loss: 0.6302\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9483 - loss: 0.2646 - val_accuracy: 0.5189 - val_loss: 2.0993\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9465 - loss: 0.2558 - val_accuracy: 0.6180 - val_loss: 0.6947\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9620 - loss: 0.2221 - val_accuracy: 0.5784 - val_loss: 0.8021\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9744 - loss: 0.1948 - val_accuracy: 0.6252 - val_loss: 0.6949\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9803 - loss: 0.1743 - val_accuracy: 0.4775 - val_loss: 2.4461\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9878 - loss: 0.1486 - val_accuracy: 0.5568 - val_loss: 1.0903\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9901 - loss: 0.1255 - val_accuracy: 0.5279 - val_loss: 1.4001\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9890 - loss: 0.1093 - val_accuracy: 0.5441 - val_loss: 1.1290\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9927 - loss: 0.1050 - val_accuracy: 0.4811 - val_loss: 3.6650\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9916 - loss: 0.1024 - val_accuracy: 0.4811 - val_loss: 3.1550\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5163 - loss: 0.7613\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.5710 - loss: 0.7145 - val_accuracy: 0.5189 - val_loss: 0.7102\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6567 - loss: 0.6107 - val_accuracy: 0.5189 - val_loss: 0.7396\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7250 - loss: 0.5665 - val_accuracy: 0.5189 - val_loss: 0.6986\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7392 - loss: 0.5306 - val_accuracy: 0.5189 - val_loss: 0.7020\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7597 - loss: 0.5059 - val_accuracy: 0.5189 - val_loss: 0.6973\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8102 - loss: 0.4661 - val_accuracy: 0.5153 - val_loss: 0.7319\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8441 - loss: 0.4120 - val_accuracy: 0.5189 - val_loss: 0.8541\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8772 - loss: 0.3862 - val_accuracy: 0.5171 - val_loss: 0.9272\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9020 - loss: 0.3529 - val_accuracy: 0.5802 - val_loss: 0.6671\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9271 - loss: 0.3181 - val_accuracy: 0.5802 - val_loss: 0.7154\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9386 - loss: 0.2857 - val_accuracy: 0.5730 - val_loss: 0.7181\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9454 - loss: 0.2552 - val_accuracy: 0.6198 - val_loss: 0.6463\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9576 - loss: 0.2269 - val_accuracy: 0.5820 - val_loss: 0.7649\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9845 - loss: 0.1735 - val_accuracy: 0.5586 - val_loss: 1.0667\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9871 - loss: 0.1607 - val_accuracy: 0.5369 - val_loss: 1.2068\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9870 - loss: 0.1431 - val_accuracy: 0.5189 - val_loss: 1.6607\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9919 - loss: 0.1188 - val_accuracy: 0.6342 - val_loss: 0.7436\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9969 - loss: 0.0952 - val_accuracy: 0.5027 - val_loss: 2.0167\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9932 - loss: 0.0917 - val_accuracy: 0.5351 - val_loss: 1.4615\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9987 - loss: 0.0718 - val_accuracy: 0.5928 - val_loss: 0.8750\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9992 - loss: 0.0560 - val_accuracy: 0.6288 - val_loss: 0.7276\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9991 - loss: 0.0575 - val_accuracy: 0.6252 - val_loss: 0.7363\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9972 - loss: 0.0451 - val_accuracy: 0.5532 - val_loss: 1.3166\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0393 - val_accuracy: 0.5009 - val_loss: 1.9563\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9993 - loss: 0.0328 - val_accuracy: 0.5784 - val_loss: 1.3328\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0268 - val_accuracy: 0.4829 - val_loss: 3.1201\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 1.0000 - loss: 0.0227 - val_accuracy: 0.5730 - val_loss: 1.2083\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6788 - loss: 0.6110\n",
      "testing model 7 out of 12\n",
      "testing params: average, 3, 9, 32,0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - accuracy: 0.5283 - loss: 0.7225 - val_accuracy: 0.4739 - val_loss: 0.6968\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5994 - loss: 0.6456 - val_accuracy: 0.5243 - val_loss: 0.7037\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6669 - loss: 0.5943 - val_accuracy: 0.5009 - val_loss: 0.7057\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7128 - loss: 0.5613 - val_accuracy: 0.5207 - val_loss: 0.9646\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7262 - loss: 0.5301 - val_accuracy: 0.5207 - val_loss: 0.8203\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7897 - loss: 0.4683 - val_accuracy: 0.5387 - val_loss: 0.7316\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8064 - loss: 0.4479 - val_accuracy: 0.5207 - val_loss: 0.9057\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8241 - loss: 0.4172 - val_accuracy: 0.5604 - val_loss: 0.7512\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8634 - loss: 0.3638 - val_accuracy: 0.4793 - val_loss: 2.8242\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8828 - loss: 0.3350 - val_accuracy: 0.5514 - val_loss: 0.8811\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8762 - loss: 0.3284 - val_accuracy: 0.5712 - val_loss: 0.9823\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9129 - loss: 0.2823 - val_accuracy: 0.4793 - val_loss: 8.3918\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9079 - loss: 0.2761 - val_accuracy: 0.4721 - val_loss: 18.4454\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9267 - loss: 0.2500 - val_accuracy: 0.5261 - val_loss: 2.6443\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9481 - loss: 0.2185 - val_accuracy: 0.5207 - val_loss: 4.6546\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9498 - loss: 0.2084 - val_accuracy: 0.6468 - val_loss: 0.6865\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9730 - loss: 0.1678 - val_accuracy: 0.4721 - val_loss: 10.6561\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9751 - loss: 0.1683 - val_accuracy: 0.5712 - val_loss: 1.0776\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9759 - loss: 0.1460 - val_accuracy: 0.6739 - val_loss: 0.7303\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9802 - loss: 0.1351 - val_accuracy: 0.4937 - val_loss: 3.3282\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9846 - loss: 0.1192 - val_accuracy: 0.6523 - val_loss: 0.7767\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9901 - loss: 0.1122 - val_accuracy: 0.5369 - val_loss: 1.9218\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9893 - loss: 0.0979 - val_accuracy: 0.6288 - val_loss: 0.9042\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9968 - loss: 0.0839 - val_accuracy: 0.6667 - val_loss: 0.7388\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9961 - loss: 0.0786 - val_accuracy: 0.5910 - val_loss: 1.2442\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9960 - loss: 0.0754 - val_accuracy: 0.6072 - val_loss: 1.1185\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9971 - loss: 0.0623 - val_accuracy: 0.5279 - val_loss: 2.0142\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9955 - loss: 0.0692 - val_accuracy: 0.4793 - val_loss: 7.7013\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9998 - loss: 0.0570 - val_accuracy: 0.5982 - val_loss: 1.5568\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7698 - loss: 0.4946\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - accuracy: 0.5506 - loss: 0.7054 - val_accuracy: 0.5189 - val_loss: 0.6920\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.6222 - loss: 0.6368 - val_accuracy: 0.5189 - val_loss: 0.7080\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6837 - loss: 0.5813 - val_accuracy: 0.5189 - val_loss: 0.7172\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6835 - loss: 0.5789 - val_accuracy: 0.5189 - val_loss: 0.7483\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7515 - loss: 0.5222 - val_accuracy: 0.5189 - val_loss: 0.7733\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7587 - loss: 0.4911 - val_accuracy: 0.5189 - val_loss: 0.9244\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7925 - loss: 0.4603 - val_accuracy: 0.5153 - val_loss: 0.8314\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8174 - loss: 0.4361 - val_accuracy: 0.4811 - val_loss: 3.7779\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8409 - loss: 0.4018 - val_accuracy: 0.6072 - val_loss: 0.6554\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8572 - loss: 0.3780 - val_accuracy: 0.5261 - val_loss: 0.7376\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8718 - loss: 0.3462 - val_accuracy: 0.4793 - val_loss: 6.6808\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8959 - loss: 0.3267 - val_accuracy: 0.5586 - val_loss: 0.8872\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9156 - loss: 0.2865 - val_accuracy: 0.5640 - val_loss: 1.0589\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9139 - loss: 0.2838 - val_accuracy: 0.5676 - val_loss: 1.0150\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9401 - loss: 0.2483 - val_accuracy: 0.6324 - val_loss: 0.6486\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9627 - loss: 0.2147 - val_accuracy: 0.5910 - val_loss: 0.9014\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9560 - loss: 0.2125 - val_accuracy: 0.5694 - val_loss: 1.0956\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9694 - loss: 0.1831 - val_accuracy: 0.5766 - val_loss: 0.9417\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9708 - loss: 0.1777 - val_accuracy: 0.6468 - val_loss: 0.7040\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9762 - loss: 0.1539 - val_accuracy: 0.6577 - val_loss: 0.6880\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9698 - loss: 0.1489 - val_accuracy: 0.5297 - val_loss: 2.1304\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9822 - loss: 0.1294 - val_accuracy: 0.5207 - val_loss: 2.0293\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9963 - loss: 0.1101 - val_accuracy: 0.5351 - val_loss: 2.1280\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9934 - loss: 0.1054 - val_accuracy: 0.6270 - val_loss: 0.7460\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9955 - loss: 0.0900 - val_accuracy: 0.5586 - val_loss: 1.3228\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9938 - loss: 0.0877 - val_accuracy: 0.6162 - val_loss: 1.1260\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9974 - loss: 0.0721 - val_accuracy: 0.6505 - val_loss: 1.0918\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9982 - loss: 0.0659 - val_accuracy: 0.5676 - val_loss: 1.2712\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9978 - loss: 0.0625 - val_accuracy: 0.6252 - val_loss: 0.8820\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9969 - loss: 0.0637 - val_accuracy: 0.5243 - val_loss: 2.3857\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7016 - loss: 0.6647\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - accuracy: 0.5088 - loss: 0.7355 - val_accuracy: 0.5405 - val_loss: 0.6915\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6193 - loss: 0.6430 - val_accuracy: 0.5189 - val_loss: 0.6968\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6615 - loss: 0.6108 - val_accuracy: 0.5189 - val_loss: 0.8475\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7128 - loss: 0.5515 - val_accuracy: 0.5063 - val_loss: 0.7105\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7479 - loss: 0.5174 - val_accuracy: 0.5351 - val_loss: 0.6917\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7743 - loss: 0.4827 - val_accuracy: 0.5171 - val_loss: 0.9908\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8017 - loss: 0.4419 - val_accuracy: 0.5874 - val_loss: 0.6936\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8055 - loss: 0.4417 - val_accuracy: 0.4937 - val_loss: 2.2629\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8513 - loss: 0.3896 - val_accuracy: 0.6162 - val_loss: 0.6758\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8632 - loss: 0.3653 - val_accuracy: 0.5333 - val_loss: 0.9394\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8487 - loss: 0.3563 - val_accuracy: 0.5351 - val_loss: 1.1196\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8709 - loss: 0.3377 - val_accuracy: 0.4883 - val_loss: 3.7729\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9035 - loss: 0.3013 - val_accuracy: 0.5207 - val_loss: 1.8041\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9190 - loss: 0.2727 - val_accuracy: 0.6198 - val_loss: 0.7151\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9164 - loss: 0.2709 - val_accuracy: 0.5171 - val_loss: 1.4770\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9330 - loss: 0.2380 - val_accuracy: 0.6054 - val_loss: 0.7658\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9562 - loss: 0.2104 - val_accuracy: 0.5730 - val_loss: 1.3630\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9703 - loss: 0.1923 - val_accuracy: 0.5225 - val_loss: 1.7645\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9635 - loss: 0.1828 - val_accuracy: 0.6360 - val_loss: 0.9207\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9758 - loss: 0.1636 - val_accuracy: 0.4991 - val_loss: 4.1164\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9787 - loss: 0.1592 - val_accuracy: 0.5369 - val_loss: 1.3538\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9894 - loss: 0.1361 - val_accuracy: 0.5315 - val_loss: 2.8502\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9786 - loss: 0.1305 - val_accuracy: 0.6468 - val_loss: 0.7314\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9862 - loss: 0.1166 - val_accuracy: 0.4919 - val_loss: 4.3802\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9813 - loss: 0.1214 - val_accuracy: 0.5676 - val_loss: 1.0504\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9966 - loss: 0.0987 - val_accuracy: 0.5189 - val_loss: 2.9406\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9974 - loss: 0.0853 - val_accuracy: 0.5243 - val_loss: 2.1338\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9934 - loss: 0.0811 - val_accuracy: 0.5189 - val_loss: 4.3235\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9959 - loss: 0.0807 - val_accuracy: 0.4829 - val_loss: 8.6246\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9949 - loss: 0.0737 - val_accuracy: 0.5622 - val_loss: 1.3416\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9975 - loss: 0.0623 - val_accuracy: 0.5207 - val_loss: 3.4935\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9979 - loss: 0.0557 - val_accuracy: 0.4865 - val_loss: 6.3848\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.9986 - loss: 0.0526 - val_accuracy: 0.5459 - val_loss: 1.6347\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5420 - loss: 1.0001\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.5161 - loss: 0.7093 - val_accuracy: 0.5153 - val_loss: 0.6913\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6101 - loss: 0.6466 - val_accuracy: 0.5189 - val_loss: 0.6964\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6739 - loss: 0.5883 - val_accuracy: 0.5171 - val_loss: 0.7014\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7293 - loss: 0.5462 - val_accuracy: 0.5297 - val_loss: 0.7027\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7558 - loss: 0.5115 - val_accuracy: 0.5189 - val_loss: 1.3046\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7839 - loss: 0.4729 - val_accuracy: 0.5189 - val_loss: 0.9777\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8105 - loss: 0.4272 - val_accuracy: 0.5622 - val_loss: 0.8082\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8518 - loss: 0.3887 - val_accuracy: 0.5441 - val_loss: 1.1431\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8908 - loss: 0.3359 - val_accuracy: 0.6468 - val_loss: 0.6289\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9056 - loss: 0.3049 - val_accuracy: 0.5189 - val_loss: 1.6269\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9183 - loss: 0.2772 - val_accuracy: 0.5820 - val_loss: 0.8237\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9413 - loss: 0.2410 - val_accuracy: 0.4847 - val_loss: 6.8496\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9473 - loss: 0.2383 - val_accuracy: 0.5189 - val_loss: 11.4778\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9569 - loss: 0.2086 - val_accuracy: 0.4739 - val_loss: 5.0178\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9760 - loss: 0.1888 - val_accuracy: 0.5405 - val_loss: 1.4633\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9759 - loss: 0.1691 - val_accuracy: 0.4757 - val_loss: 13.5371\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9771 - loss: 0.1508 - val_accuracy: 0.5369 - val_loss: 2.2568\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9894 - loss: 0.1328 - val_accuracy: 0.5423 - val_loss: 2.3202\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9898 - loss: 0.1172 - val_accuracy: 0.5856 - val_loss: 0.9395\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5952 - loss: 0.7089\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 70ms/step - accuracy: 0.5608 - loss: 0.7119 - val_accuracy: 0.5081 - val_loss: 0.6910\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6457 - loss: 0.6223 - val_accuracy: 0.5225 - val_loss: 0.6873\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7089 - loss: 0.5671 - val_accuracy: 0.5171 - val_loss: 0.7055\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7128 - loss: 0.5453 - val_accuracy: 0.5189 - val_loss: 0.7314\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7527 - loss: 0.5027 - val_accuracy: 0.5099 - val_loss: 0.7154\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7999 - loss: 0.4488 - val_accuracy: 0.5297 - val_loss: 0.7329\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8314 - loss: 0.4138 - val_accuracy: 0.5261 - val_loss: 0.8803\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8442 - loss: 0.3955 - val_accuracy: 0.5441 - val_loss: 0.7550\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8565 - loss: 0.3637 - val_accuracy: 0.5045 - val_loss: 1.3204\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9116 - loss: 0.3090 - val_accuracy: 0.5640 - val_loss: 0.7710\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9211 - loss: 0.2999 - val_accuracy: 0.5315 - val_loss: 0.9210\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9403 - loss: 0.2588 - val_accuracy: 0.4937 - val_loss: 1.8244\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9443 - loss: 0.2493 - val_accuracy: 0.5910 - val_loss: 0.8160\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9580 - loss: 0.2238 - val_accuracy: 0.5081 - val_loss: 2.0110\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9627 - loss: 0.2065 - val_accuracy: 0.5225 - val_loss: 1.8427\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9688 - loss: 0.1815 - val_accuracy: 0.5243 - val_loss: 1.6516\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9763 - loss: 0.1689 - val_accuracy: 0.5297 - val_loss: 1.6325\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9825 - loss: 0.1521 - val_accuracy: 0.5261 - val_loss: 2.3150\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9854 - loss: 0.1396 - val_accuracy: 0.4811 - val_loss: 5.4984\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9682 - loss: 0.1460 - val_accuracy: 0.5027 - val_loss: 2.4608\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9854 - loss: 0.1192 - val_accuracy: 0.4901 - val_loss: 2.9776\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9924 - loss: 0.1031 - val_accuracy: 0.5207 - val_loss: 2.3734\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9918 - loss: 0.0959 - val_accuracy: 0.5369 - val_loss: 1.7938\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7545 - loss: 0.5213\n",
      "testing model 8 out of 12\n",
      "testing params: average, 5, 9, 32,0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.5505 - loss: 0.6882 - val_accuracy: 0.5207 - val_loss: 0.6923\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6086 - loss: 0.6558 - val_accuracy: 0.5207 - val_loss: 0.7257\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6339 - loss: 0.6351 - val_accuracy: 0.5207 - val_loss: 0.7665\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6702 - loss: 0.6160 - val_accuracy: 0.5207 - val_loss: 0.7970\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6392 - loss: 0.6276 - val_accuracy: 0.4721 - val_loss: 1.1129\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6611 - loss: 0.6220 - val_accuracy: 0.5207 - val_loss: 0.8072\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6683 - loss: 0.6111 - val_accuracy: 0.5153 - val_loss: 0.7385\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6476 - loss: 0.6141 - val_accuracy: 0.5207 - val_loss: 0.8902\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6857 - loss: 0.5875 - val_accuracy: 0.4739 - val_loss: 2.1920\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6848 - loss: 0.5874 - val_accuracy: 0.5694 - val_loss: 0.6945\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7141 - loss: 0.5715 - val_accuracy: 0.4793 - val_loss: 3.3273\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6857 - loss: 0.5703 - val_accuracy: 0.4793 - val_loss: 1.5951\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7203 - loss: 0.5495 - val_accuracy: 0.6090 - val_loss: 0.6751\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7070 - loss: 0.5509 - val_accuracy: 0.5694 - val_loss: 0.6745\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7341 - loss: 0.5350 - val_accuracy: 0.4829 - val_loss: 0.7988\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7250 - loss: 0.5365 - val_accuracy: 0.5225 - val_loss: 2.5189\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7503 - loss: 0.5157 - val_accuracy: 0.6234 - val_loss: 0.6529\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7364 - loss: 0.5130 - val_accuracy: 0.6180 - val_loss: 0.6811\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7453 - loss: 0.5109 - val_accuracy: 0.5495 - val_loss: 0.6880\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7584 - loss: 0.4994 - val_accuracy: 0.5495 - val_loss: 0.7924\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7503 - loss: 0.5034 - val_accuracy: 0.5730 - val_loss: 0.8412\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7603 - loss: 0.4952 - val_accuracy: 0.4721 - val_loss: 4.4306\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7806 - loss: 0.4714 - val_accuracy: 0.5243 - val_loss: 1.3094\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7730 - loss: 0.4791 - val_accuracy: 0.5405 - val_loss: 2.1275\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7845 - loss: 0.4661 - val_accuracy: 0.5495 - val_loss: 1.2640\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7859 - loss: 0.4471 - val_accuracy: 0.5784 - val_loss: 0.7853\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7751 - loss: 0.4654 - val_accuracy: 0.6721 - val_loss: 0.6350\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7840 - loss: 0.4502 - val_accuracy: 0.4703 - val_loss: 2.7902\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7981 - loss: 0.4568 - val_accuracy: 0.4793 - val_loss: 7.0718\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8109 - loss: 0.4281 - val_accuracy: 0.5676 - val_loss: 0.8640\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8033 - loss: 0.4312 - val_accuracy: 0.4757 - val_loss: 3.3706\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8218 - loss: 0.4132 - val_accuracy: 0.5604 - val_loss: 0.8767\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8260 - loss: 0.4115 - val_accuracy: 0.5369 - val_loss: 1.2121\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8102 - loss: 0.4176 - val_accuracy: 0.5333 - val_loss: 1.2115\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8256 - loss: 0.4062 - val_accuracy: 0.5676 - val_loss: 0.9473\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8189 - loss: 0.3926 - val_accuracy: 0.5423 - val_loss: 1.3143\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8554 - loss: 0.3686 - val_accuracy: 0.6108 - val_loss: 0.7019\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7402 - loss: 0.5431\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.5457 - loss: 0.6912 - val_accuracy: 0.5189 - val_loss: 0.7031\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5901 - loss: 0.6608 - val_accuracy: 0.5243 - val_loss: 0.6999\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6091 - loss: 0.6481 - val_accuracy: 0.5189 - val_loss: 0.7079\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6291 - val_accuracy: 0.5189 - val_loss: 0.7791\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6597 - loss: 0.6073 - val_accuracy: 0.5207 - val_loss: 0.7049\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6934 - loss: 0.5987 - val_accuracy: 0.5189 - val_loss: 0.7862\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6968 - loss: 0.5876 - val_accuracy: 0.4811 - val_loss: 2.2169\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6936 - loss: 0.5894 - val_accuracy: 0.5225 - val_loss: 0.7223\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6900 - loss: 0.5815 - val_accuracy: 0.5333 - val_loss: 0.9790\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7121 - loss: 0.5709 - val_accuracy: 0.5189 - val_loss: 1.0670\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7140 - loss: 0.5586 - val_accuracy: 0.5189 - val_loss: 1.0268\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7258 - loss: 0.5573 - val_accuracy: 0.5946 - val_loss: 0.7729\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7182 - loss: 0.5412 - val_accuracy: 0.5207 - val_loss: 1.5032\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7325 - loss: 0.5463 - val_accuracy: 0.4955 - val_loss: 1.9960\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7220 - loss: 0.5420 - val_accuracy: 0.5117 - val_loss: 0.9851\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7350 - loss: 0.5245 - val_accuracy: 0.4811 - val_loss: 3.1192\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7672 - loss: 0.4993 - val_accuracy: 0.4829 - val_loss: 2.6439\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7488 - loss: 0.5049 - val_accuracy: 0.5225 - val_loss: 1.6140\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7395 - loss: 0.5090 - val_accuracy: 0.6108 - val_loss: 0.6576\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7566 - loss: 0.4951 - val_accuracy: 0.5099 - val_loss: 1.1677\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7575 - loss: 0.4860 - val_accuracy: 0.5802 - val_loss: 0.7299\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7866 - loss: 0.4669 - val_accuracy: 0.5315 - val_loss: 1.0438\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7683 - loss: 0.4692 - val_accuracy: 0.6667 - val_loss: 0.6225\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7787 - loss: 0.4675 - val_accuracy: 0.5532 - val_loss: 0.9259\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7996 - loss: 0.4610 - val_accuracy: 0.4847 - val_loss: 2.0015\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7874 - loss: 0.4513 - val_accuracy: 0.4829 - val_loss: 2.5086\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7971 - loss: 0.4492 - val_accuracy: 0.5622 - val_loss: 0.8468\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8085 - loss: 0.4347 - val_accuracy: 0.5189 - val_loss: 1.8104\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8129 - loss: 0.4329 - val_accuracy: 0.5225 - val_loss: 2.1228\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8179 - loss: 0.4146 - val_accuracy: 0.5189 - val_loss: 5.3279\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8073 - loss: 0.4292 - val_accuracy: 0.4811 - val_loss: 5.2495\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8291 - loss: 0.4016 - val_accuracy: 0.5207 - val_loss: 2.1543\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8393 - loss: 0.3966 - val_accuracy: 0.5207 - val_loss: 2.5433\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6423 - loss: 0.6608\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.5316 - loss: 0.6944 - val_accuracy: 0.5243 - val_loss: 0.6920\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6361 - loss: 0.6435 - val_accuracy: 0.5189 - val_loss: 0.7010\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6614 - loss: 0.6213 - val_accuracy: 0.5189 - val_loss: 0.7152\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6984 - loss: 0.6043 - val_accuracy: 0.5171 - val_loss: 0.7012\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6770 - loss: 0.5980 - val_accuracy: 0.5189 - val_loss: 0.7506\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6783 - loss: 0.5917 - val_accuracy: 0.5171 - val_loss: 0.7370\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6939 - loss: 0.5852 - val_accuracy: 0.5514 - val_loss: 0.7228\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7018 - loss: 0.5742 - val_accuracy: 0.5189 - val_loss: 0.8759\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6887 - loss: 0.5667 - val_accuracy: 0.5225 - val_loss: 0.7373\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7081 - loss: 0.5549 - val_accuracy: 0.5369 - val_loss: 0.7497\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7287 - loss: 0.5447 - val_accuracy: 0.5207 - val_loss: 1.5377\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7334 - loss: 0.5451 - val_accuracy: 0.4811 - val_loss: 1.9813\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7329 - loss: 0.5458 - val_accuracy: 0.5189 - val_loss: 0.8095\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7453 - loss: 0.5237 - val_accuracy: 0.5207 - val_loss: 1.0713\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7427 - loss: 0.5261 - val_accuracy: 0.4829 - val_loss: 2.4285\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7612 - loss: 0.5041 - val_accuracy: 0.6450 - val_loss: 0.6802\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7518 - loss: 0.5113 - val_accuracy: 0.5189 - val_loss: 1.3370\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7596 - loss: 0.5060 - val_accuracy: 0.4829 - val_loss: 2.0302\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7821 - loss: 0.4811 - val_accuracy: 0.5189 - val_loss: 2.0158\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7652 - loss: 0.4909 - val_accuracy: 0.4847 - val_loss: 2.8642\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7828 - loss: 0.4756 - val_accuracy: 0.5207 - val_loss: 1.6873\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7821 - loss: 0.4764 - val_accuracy: 0.4757 - val_loss: 4.8166\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7832 - loss: 0.4666 - val_accuracy: 0.6036 - val_loss: 0.6889\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8118 - loss: 0.4473 - val_accuracy: 0.5261 - val_loss: 1.1969\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7951 - loss: 0.4489 - val_accuracy: 0.5189 - val_loss: 2.4060\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7892 - loss: 0.4506 - val_accuracy: 0.5171 - val_loss: 1.6649\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7725 - loss: 0.4873\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.4852 - loss: 0.7423 - val_accuracy: 0.5117 - val_loss: 0.6928\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6018 - loss: 0.6653 - val_accuracy: 0.5225 - val_loss: 0.6907\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6410 - loss: 0.6411 - val_accuracy: 0.5189 - val_loss: 0.6941\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6549 - loss: 0.6188 - val_accuracy: 0.5189 - val_loss: 0.8022\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6654 - loss: 0.6121 - val_accuracy: 0.5189 - val_loss: 0.7418\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6873 - loss: 0.5974 - val_accuracy: 0.5189 - val_loss: 0.8068\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6761 - loss: 0.6007 - val_accuracy: 0.5189 - val_loss: 0.7939\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7043 - loss: 0.5817 - val_accuracy: 0.5622 - val_loss: 0.6837\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6825 - loss: 0.5906 - val_accuracy: 0.4739 - val_loss: 1.2851\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7217 - loss: 0.5667 - val_accuracy: 0.4883 - val_loss: 1.1941\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7101 - loss: 0.5542 - val_accuracy: 0.4883 - val_loss: 2.0271\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7163 - loss: 0.5519 - val_accuracy: 0.4793 - val_loss: 2.0979\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7147 - loss: 0.5419 - val_accuracy: 0.5189 - val_loss: 0.7243\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7404 - loss: 0.5365 - val_accuracy: 0.6036 - val_loss: 0.6848\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7386 - loss: 0.5207 - val_accuracy: 0.5423 - val_loss: 0.8132\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7671 - loss: 0.5049 - val_accuracy: 0.5189 - val_loss: 1.7667\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7319 - loss: 0.5239 - val_accuracy: 0.5387 - val_loss: 1.0071\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7428 - loss: 0.5225 - val_accuracy: 0.4883 - val_loss: 1.7985\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7611 - loss: 0.5107 - val_accuracy: 0.5189 - val_loss: 1.5575\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7386 - loss: 0.5035 - val_accuracy: 0.4901 - val_loss: 2.2891\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7483 - loss: 0.4888 - val_accuracy: 0.5189 - val_loss: 1.1575\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7647 - loss: 0.4772 - val_accuracy: 0.5243 - val_loss: 1.5028\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7849 - loss: 0.4702 - val_accuracy: 0.5568 - val_loss: 0.7316\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7715 - loss: 0.4718 - val_accuracy: 0.6252 - val_loss: 0.6682\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7666 - loss: 0.4664 - val_accuracy: 0.6216 - val_loss: 0.6523\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8098 - loss: 0.4504 - val_accuracy: 0.5856 - val_loss: 0.7807\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8154 - loss: 0.4292 - val_accuracy: 0.6072 - val_loss: 0.7269\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8105 - loss: 0.4390 - val_accuracy: 0.4919 - val_loss: 2.0097\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8149 - loss: 0.4276 - val_accuracy: 0.4883 - val_loss: 1.8848\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8173 - loss: 0.4278 - val_accuracy: 0.5586 - val_loss: 0.7116\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8120 - loss: 0.4151 - val_accuracy: 0.5189 - val_loss: 1.6572\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.8295 - loss: 0.4077 - val_accuracy: 0.5045 - val_loss: 1.4077\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.8316 - loss: 0.3956 - val_accuracy: 0.5550 - val_loss: 0.7320\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.8318 - loss: 0.4001 - val_accuracy: 0.5225 - val_loss: 1.6610\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7628 - loss: 0.5379\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.5409 - loss: 0.7008 - val_accuracy: 0.5189 - val_loss: 0.6925\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5844 - loss: 0.6603 - val_accuracy: 0.5189 - val_loss: 0.6942\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6163 - loss: 0.6368 - val_accuracy: 0.5189 - val_loss: 0.7012\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6665 - loss: 0.6078 - val_accuracy: 0.5171 - val_loss: 0.7050\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6300 - loss: 0.6179 - val_accuracy: 0.5189 - val_loss: 0.7246\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6702 - loss: 0.6043 - val_accuracy: 0.5189 - val_loss: 0.7581\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6752 - loss: 0.5883 - val_accuracy: 0.4865 - val_loss: 0.8933\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7014 - loss: 0.5800 - val_accuracy: 0.5207 - val_loss: 0.8569\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6942 - loss: 0.5693 - val_accuracy: 0.5892 - val_loss: 0.6641\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7160 - loss: 0.5579 - val_accuracy: 0.5225 - val_loss: 1.1174\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7146 - loss: 0.5590 - val_accuracy: 0.5189 - val_loss: 1.0637\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7423 - loss: 0.5260 - val_accuracy: 0.5189 - val_loss: 2.8184\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7441 - loss: 0.5236 - val_accuracy: 0.4811 - val_loss: 3.8341\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7311 - loss: 0.5316 - val_accuracy: 0.4811 - val_loss: 2.2458\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7416 - loss: 0.5228 - val_accuracy: 0.5171 - val_loss: 0.9092\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7397 - loss: 0.5163 - val_accuracy: 0.4865 - val_loss: 1.7227\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7134 - loss: 0.5278 - val_accuracy: 0.5063 - val_loss: 1.0541\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7632 - loss: 0.4995 - val_accuracy: 0.5189 - val_loss: 1.7656\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7758 - loss: 0.4829 - val_accuracy: 0.5189 - val_loss: 1.5885\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6909 - loss: 0.5946\n",
      "testing model 9 out of 12\n",
      "testing params: max, 3, 9, 32,1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.4759 - loss: 0.8296 - val_accuracy: 0.5207 - val_loss: 0.6967\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6007 - loss: 0.6784 - val_accuracy: 0.5207 - val_loss: 0.7604\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6468 - loss: 0.6328 - val_accuracy: 0.5207 - val_loss: 0.8357\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6661 - loss: 0.6104 - val_accuracy: 0.5207 - val_loss: 0.8643\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6749 - loss: 0.5984 - val_accuracy: 0.5207 - val_loss: 0.8660\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6894 - loss: 0.5781 - val_accuracy: 0.5207 - val_loss: 0.8870\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7056 - loss: 0.5522 - val_accuracy: 0.5207 - val_loss: 0.8513\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7283 - loss: 0.5414 - val_accuracy: 0.5207 - val_loss: 0.8900\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7692 - loss: 0.5209 - val_accuracy: 0.5225 - val_loss: 0.8217\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7539 - loss: 0.5148 - val_accuracy: 0.6216 - val_loss: 0.6518\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7819 - loss: 0.4961 - val_accuracy: 0.6018 - val_loss: 0.6578\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7978 - loss: 0.4690 - val_accuracy: 0.6378 - val_loss: 0.6530\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7824 - loss: 0.4818 - val_accuracy: 0.5550 - val_loss: 0.7792\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7861 - loss: 0.4594 - val_accuracy: 0.5946 - val_loss: 0.6933\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8265 - loss: 0.4478 - val_accuracy: 0.6306 - val_loss: 0.6489\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8198 - loss: 0.4417 - val_accuracy: 0.6018 - val_loss: 0.6811\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8443 - loss: 0.4227 - val_accuracy: 0.5712 - val_loss: 0.8032\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8600 - loss: 0.4113 - val_accuracy: 0.5261 - val_loss: 0.9854\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8555 - loss: 0.4010 - val_accuracy: 0.6108 - val_loss: 0.6588\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8709 - loss: 0.3902 - val_accuracy: 0.6378 - val_loss: 0.6528\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8739 - loss: 0.3869 - val_accuracy: 0.6252 - val_loss: 0.6534\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8960 - loss: 0.3647 - val_accuracy: 0.5477 - val_loss: 0.8900\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6674 - loss: 0.6112\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.5409 - loss: 0.7411 - val_accuracy: 0.5189 - val_loss: 0.7381\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.5852 - loss: 0.6804 - val_accuracy: 0.5189 - val_loss: 0.7881\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6049 - loss: 0.6659 - val_accuracy: 0.5189 - val_loss: 0.8136\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6449 - loss: 0.6326 - val_accuracy: 0.5189 - val_loss: 0.8289\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6584 - loss: 0.6136 - val_accuracy: 0.5189 - val_loss: 0.8345\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6905 - loss: 0.5948 - val_accuracy: 0.5189 - val_loss: 0.8271\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6966 - loss: 0.5764 - val_accuracy: 0.5207 - val_loss: 0.8156\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7046 - loss: 0.5652 - val_accuracy: 0.5261 - val_loss: 0.8074\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.7268 - loss: 0.5563 - val_accuracy: 0.5333 - val_loss: 0.8237\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.7387 - loss: 0.5263 - val_accuracy: 0.5820 - val_loss: 0.6825\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.7553 - loss: 0.5109 - val_accuracy: 0.5910 - val_loss: 0.6682\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7860 - loss: 0.4972 - val_accuracy: 0.6018 - val_loss: 0.7045\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7965 - loss: 0.4858 - val_accuracy: 0.5874 - val_loss: 0.7578\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7933 - loss: 0.4867 - val_accuracy: 0.5838 - val_loss: 0.6675\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8162 - loss: 0.4622 - val_accuracy: 0.5946 - val_loss: 0.6765\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8348 - loss: 0.4462 - val_accuracy: 0.6000 - val_loss: 0.7016\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8309 - loss: 0.4389 - val_accuracy: 0.5946 - val_loss: 0.6710\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8463 - loss: 0.4235 - val_accuracy: 0.5892 - val_loss: 0.6718\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8457 - loss: 0.4169 - val_accuracy: 0.6054 - val_loss: 0.7213\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8645 - loss: 0.4036 - val_accuracy: 0.5730 - val_loss: 0.6904\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8630 - loss: 0.4047 - val_accuracy: 0.6162 - val_loss: 0.7119\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8754 - loss: 0.3801 - val_accuracy: 0.5910 - val_loss: 0.6686\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8817 - loss: 0.3748 - val_accuracy: 0.5604 - val_loss: 0.7462\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9016 - loss: 0.3552 - val_accuracy: 0.5892 - val_loss: 0.8987\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8934 - loss: 0.3505 - val_accuracy: 0.6378 - val_loss: 0.7122\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9075 - loss: 0.3444 - val_accuracy: 0.5910 - val_loss: 0.6772\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9088 - loss: 0.3368 - val_accuracy: 0.6234 - val_loss: 0.7182\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9116 - loss: 0.3284 - val_accuracy: 0.5910 - val_loss: 0.7032\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9291 - loss: 0.3154 - val_accuracy: 0.5820 - val_loss: 0.7153\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9352 - loss: 0.3051 - val_accuracy: 0.5586 - val_loss: 0.7912\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9370 - loss: 0.2981 - val_accuracy: 0.5748 - val_loss: 0.8063\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9498 - loss: 0.2888 - val_accuracy: 0.6216 - val_loss: 0.6950\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9410 - loss: 0.2929 - val_accuracy: 0.5982 - val_loss: 0.6878\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9516 - loss: 0.2839 - val_accuracy: 0.6216 - val_loss: 0.7101\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9448 - loss: 0.2759 - val_accuracy: 0.6036 - val_loss: 0.6842\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7351 - loss: 0.5564\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.4937 - loss: 0.9136 - val_accuracy: 0.5189 - val_loss: 0.6924\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.5805 - loss: 0.6986 - val_accuracy: 0.5189 - val_loss: 0.6967\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6050 - loss: 0.6518 - val_accuracy: 0.5189 - val_loss: 0.7197\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6414 - loss: 0.6335 - val_accuracy: 0.5189 - val_loss: 0.7798\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6664 - loss: 0.5976 - val_accuracy: 0.5189 - val_loss: 0.8338\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7158 - loss: 0.5667 - val_accuracy: 0.5189 - val_loss: 0.8694\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.7014 - loss: 0.5661 - val_accuracy: 0.5189 - val_loss: 0.8980\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7301 - loss: 0.5453 - val_accuracy: 0.5189 - val_loss: 0.9211\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7514 - loss: 0.5218 - val_accuracy: 0.5243 - val_loss: 0.8868\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7595 - loss: 0.5056 - val_accuracy: 0.5387 - val_loss: 0.8653\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7697 - loss: 0.4948 - val_accuracy: 0.5514 - val_loss: 0.8341\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7938 - loss: 0.4748 - val_accuracy: 0.6090 - val_loss: 0.6626\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7940 - loss: 0.4771 - val_accuracy: 0.6018 - val_loss: 0.6720\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8186 - loss: 0.4627 - val_accuracy: 0.6000 - val_loss: 0.6612\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8204 - loss: 0.4500 - val_accuracy: 0.6432 - val_loss: 0.6691\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8211 - loss: 0.4380 - val_accuracy: 0.5964 - val_loss: 0.6806\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8337 - loss: 0.4225 - val_accuracy: 0.6036 - val_loss: 0.6908\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8449 - loss: 0.4106 - val_accuracy: 0.6541 - val_loss: 0.6623\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8497 - loss: 0.4080 - val_accuracy: 0.5910 - val_loss: 0.8346\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8663 - loss: 0.3913 - val_accuracy: 0.6126 - val_loss: 0.6696\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8870 - loss: 0.3643 - val_accuracy: 0.5892 - val_loss: 0.7606\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8959 - loss: 0.3516 - val_accuracy: 0.5892 - val_loss: 0.8747\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8993 - loss: 0.3515 - val_accuracy: 0.5892 - val_loss: 0.7415\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8883 - loss: 0.3431 - val_accuracy: 0.6414 - val_loss: 0.6537\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9171 - loss: 0.3225 - val_accuracy: 0.6234 - val_loss: 0.7598\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9258 - loss: 0.3206 - val_accuracy: 0.5982 - val_loss: 0.7246\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9235 - loss: 0.3102 - val_accuracy: 0.6486 - val_loss: 0.6576\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9396 - loss: 0.2932 - val_accuracy: 0.6342 - val_loss: 0.6673\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6704 - loss: 0.6127\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.5388 - loss: 0.7945 - val_accuracy: 0.5189 - val_loss: 0.7208\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.5979 - loss: 0.6818 - val_accuracy: 0.5189 - val_loss: 0.8403\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6351 - loss: 0.6498 - val_accuracy: 0.5189 - val_loss: 1.0115\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6810 - loss: 0.6011 - val_accuracy: 0.5189 - val_loss: 1.0900\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7003 - loss: 0.5787 - val_accuracy: 0.5189 - val_loss: 1.0704\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7211 - loss: 0.5593 - val_accuracy: 0.5189 - val_loss: 1.0996\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7390 - loss: 0.5336 - val_accuracy: 0.5189 - val_loss: 1.0086\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7523 - loss: 0.5160 - val_accuracy: 0.5207 - val_loss: 1.0176\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.7867 - loss: 0.4928 - val_accuracy: 0.5369 - val_loss: 0.7993\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.7721 - loss: 0.4895 - val_accuracy: 0.5640 - val_loss: 0.7326\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7787 - loss: 0.4689 - val_accuracy: 0.5604 - val_loss: 0.8149\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7925 - loss: 0.4670 - val_accuracy: 0.6108 - val_loss: 0.6776\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8084 - loss: 0.4579 - val_accuracy: 0.6162 - val_loss: 0.6703\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8270 - loss: 0.4171 - val_accuracy: 0.6144 - val_loss: 0.6735\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8386 - loss: 0.4169 - val_accuracy: 0.5766 - val_loss: 0.8565\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8271 - loss: 0.4247 - val_accuracy: 0.6234 - val_loss: 0.6945\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8587 - loss: 0.3934 - val_accuracy: 0.6126 - val_loss: 0.7036\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8679 - loss: 0.3803 - val_accuracy: 0.5982 - val_loss: 0.7197\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8780 - loss: 0.3694 - val_accuracy: 0.6270 - val_loss: 0.6831\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8857 - loss: 0.3595 - val_accuracy: 0.6072 - val_loss: 0.6880\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8835 - loss: 0.3473 - val_accuracy: 0.6054 - val_loss: 0.7075\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9012 - loss: 0.3345 - val_accuracy: 0.5333 - val_loss: 1.2428\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9084 - loss: 0.3231 - val_accuracy: 0.6072 - val_loss: 0.7547\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9199 - loss: 0.3110 - val_accuracy: 0.5658 - val_loss: 0.8783\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9010 - loss: 0.3188 - val_accuracy: 0.6162 - val_loss: 0.6872\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9277 - loss: 0.2912 - val_accuracy: 0.5928 - val_loss: 0.8245\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9364 - loss: 0.2850 - val_accuracy: 0.6324 - val_loss: 0.6943\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9403 - loss: 0.2719 - val_accuracy: 0.6216 - val_loss: 0.7117\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9391 - loss: 0.2637 - val_accuracy: 0.6000 - val_loss: 0.7893\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9624 - loss: 0.2430 - val_accuracy: 0.6108 - val_loss: 0.8119\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9571 - loss: 0.2438 - val_accuracy: 0.6072 - val_loss: 0.7462\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9692 - loss: 0.2373 - val_accuracy: 0.6342 - val_loss: 0.7038\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9590 - loss: 0.2316 - val_accuracy: 0.5964 - val_loss: 0.8456\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9721 - loss: 0.2189 - val_accuracy: 0.6324 - val_loss: 0.6881\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9761 - loss: 0.2057 - val_accuracy: 0.6342 - val_loss: 0.6762\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9784 - loss: 0.2069 - val_accuracy: 0.6252 - val_loss: 0.6875\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9805 - loss: 0.1969 - val_accuracy: 0.6342 - val_loss: 0.6964\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9745 - loss: 0.1952 - val_accuracy: 0.5568 - val_loss: 0.9525\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9783 - loss: 0.1936 - val_accuracy: 0.6162 - val_loss: 0.7935\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9778 - loss: 0.1853 - val_accuracy: 0.6486 - val_loss: 0.7105\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9896 - loss: 0.1695 - val_accuracy: 0.5946 - val_loss: 0.9229\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9884 - loss: 0.1698 - val_accuracy: 0.6036 - val_loss: 0.8815\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9833 - loss: 0.1746 - val_accuracy: 0.6378 - val_loss: 0.7328\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9897 - loss: 0.1562 - val_accuracy: 0.6162 - val_loss: 0.7667\n",
      "Epoch 45/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9907 - loss: 0.1551 - val_accuracy: 0.6252 - val_loss: 0.8090\n",
      "Epoch 46/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9873 - loss: 0.1485 - val_accuracy: 0.6090 - val_loss: 0.8117\n",
      "Epoch 47/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9914 - loss: 0.1440 - val_accuracy: 0.6396 - val_loss: 0.6820\n",
      "Epoch 48/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9907 - loss: 0.1302 - val_accuracy: 0.5604 - val_loss: 1.1496\n",
      "Epoch 49/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9949 - loss: 0.1363 - val_accuracy: 0.6450 - val_loss: 0.7701\n",
      "Epoch 50/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9958 - loss: 0.1229 - val_accuracy: 0.5495 - val_loss: 1.1650\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7235 - loss: 0.5578\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 76ms/step - accuracy: 0.4962 - loss: 0.7773 - val_accuracy: 0.5189 - val_loss: 0.6919\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6011 - loss: 0.6628 - val_accuracy: 0.5189 - val_loss: 0.7184\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6167 - loss: 0.6391 - val_accuracy: 0.5189 - val_loss: 0.7686\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.6713 - loss: 0.6181 - val_accuracy: 0.5189 - val_loss: 0.7844\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.6877 - loss: 0.5950 - val_accuracy: 0.5189 - val_loss: 0.7946\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.6996 - loss: 0.5748 - val_accuracy: 0.5189 - val_loss: 0.8368\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7256 - loss: 0.5566 - val_accuracy: 0.5189 - val_loss: 0.8882\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7311 - loss: 0.5496 - val_accuracy: 0.5189 - val_loss: 0.8605\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7402 - loss: 0.5335 - val_accuracy: 0.5261 - val_loss: 0.7933\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7561 - loss: 0.5107 - val_accuracy: 0.5477 - val_loss: 0.7030\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7866 - loss: 0.4920 - val_accuracy: 0.5622 - val_loss: 0.6992\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.7772 - loss: 0.4917 - val_accuracy: 0.6144 - val_loss: 0.6588\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8099 - loss: 0.4602 - val_accuracy: 0.6018 - val_loss: 0.6760\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8152 - loss: 0.4505 - val_accuracy: 0.6162 - val_loss: 0.6599\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8200 - loss: 0.4452 - val_accuracy: 0.6270 - val_loss: 0.6553\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8385 - loss: 0.4232 - val_accuracy: 0.6378 - val_loss: 0.6540\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8485 - loss: 0.4155 - val_accuracy: 0.6072 - val_loss: 0.6696\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.8580 - loss: 0.4022 - val_accuracy: 0.6306 - val_loss: 0.6577\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.8796 - loss: 0.3795 - val_accuracy: 0.6396 - val_loss: 0.6555\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8793 - loss: 0.3828 - val_accuracy: 0.6378 - val_loss: 0.6572\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9093 - loss: 0.3475 - val_accuracy: 0.6396 - val_loss: 0.6508\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9026 - loss: 0.3583 - val_accuracy: 0.5856 - val_loss: 0.7152\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.8964 - loss: 0.3397 - val_accuracy: 0.6198 - val_loss: 0.6707\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9032 - loss: 0.3368 - val_accuracy: 0.5892 - val_loss: 0.7052\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9277 - loss: 0.3154 - val_accuracy: 0.6306 - val_loss: 0.6584\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9282 - loss: 0.3050 - val_accuracy: 0.6450 - val_loss: 0.6652\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9440 - loss: 0.2981 - val_accuracy: 0.6036 - val_loss: 0.7198\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9406 - loss: 0.2886 - val_accuracy: 0.6414 - val_loss: 0.6570\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9502 - loss: 0.2761 - val_accuracy: 0.6306 - val_loss: 0.6737\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9479 - loss: 0.2697 - val_accuracy: 0.6180 - val_loss: 0.6658\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9545 - loss: 0.2616 - val_accuracy: 0.6396 - val_loss: 0.6509\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9440 - loss: 0.2556 - val_accuracy: 0.5658 - val_loss: 0.8619\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9693 - loss: 0.2364 - val_accuracy: 0.6090 - val_loss: 0.7173\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9698 - loss: 0.2294 - val_accuracy: 0.5892 - val_loss: 0.8288\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - accuracy: 0.9734 - loss: 0.2224 - val_accuracy: 0.6432 - val_loss: 0.6703\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 0.9839 - loss: 0.2194 - val_accuracy: 0.6342 - val_loss: 0.6783\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5405 - loss: 0.7327\n",
      "testing model 10 out of 12\n",
      "testing params: max, 5, 9, 32,1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 60ms/step - accuracy: 0.4578 - loss: 0.8477 - val_accuracy: 0.4793 - val_loss: 0.7079\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5863 - loss: 0.6757 - val_accuracy: 0.4793 - val_loss: 0.6999\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6335 - loss: 0.6438 - val_accuracy: 0.5261 - val_loss: 0.6890\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6330 - loss: 0.6217 - val_accuracy: 0.5207 - val_loss: 0.7016\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6504 - loss: 0.6078 - val_accuracy: 0.5207 - val_loss: 0.7236\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6902 - loss: 0.5845 - val_accuracy: 0.5207 - val_loss: 0.7685\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6786 - loss: 0.5860 - val_accuracy: 0.5207 - val_loss: 0.8182\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6997 - loss: 0.5659 - val_accuracy: 0.5207 - val_loss: 0.8752\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7062 - loss: 0.5539 - val_accuracy: 0.5207 - val_loss: 0.8095\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7250 - loss: 0.5472 - val_accuracy: 0.5441 - val_loss: 0.7774\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7392 - loss: 0.5299 - val_accuracy: 0.5568 - val_loss: 0.6992\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7447 - loss: 0.5309 - val_accuracy: 0.5568 - val_loss: 0.6957\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7599 - loss: 0.5189 - val_accuracy: 0.5874 - val_loss: 0.6858\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7599 - loss: 0.5108 - val_accuracy: 0.5730 - val_loss: 0.6942\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7715 - loss: 0.5072 - val_accuracy: 0.5784 - val_loss: 0.7020\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7725 - loss: 0.5036 - val_accuracy: 0.5964 - val_loss: 0.6817\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7992 - loss: 0.4882 - val_accuracy: 0.5982 - val_loss: 0.6900\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7990 - loss: 0.4818 - val_accuracy: 0.6144 - val_loss: 0.6843\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8073 - loss: 0.4681 - val_accuracy: 0.5730 - val_loss: 0.7143\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8298 - loss: 0.4626 - val_accuracy: 0.5802 - val_loss: 0.7041\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8187 - loss: 0.4626 - val_accuracy: 0.5658 - val_loss: 0.7189\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8156 - loss: 0.4533 - val_accuracy: 0.5910 - val_loss: 0.6815\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8343 - loss: 0.4430 - val_accuracy: 0.6000 - val_loss: 0.6831\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8565 - loss: 0.4301 - val_accuracy: 0.5946 - val_loss: 0.6838\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8395 - loss: 0.4317 - val_accuracy: 0.5802 - val_loss: 0.7065\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8579 - loss: 0.4212 - val_accuracy: 0.5874 - val_loss: 0.6932\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8636 - loss: 0.4103 - val_accuracy: 0.5910 - val_loss: 0.6802\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8702 - loss: 0.4052 - val_accuracy: 0.5784 - val_loss: 0.7457\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.6844 - loss: 0.5876\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.4524 - loss: 1.8772 - val_accuracy: 0.5189 - val_loss: 0.6925\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4447 - loss: 1.1442 - val_accuracy: 0.5261 - val_loss: 0.6917\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.4644 - loss: 0.8532 - val_accuracy: 0.5189 - val_loss: 0.6938\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5210 - loss: 0.7331 - val_accuracy: 0.5081 - val_loss: 0.6973\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.5533 - loss: 0.6955 - val_accuracy: 0.4919 - val_loss: 0.7123\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5941 - loss: 0.6655 - val_accuracy: 0.5099 - val_loss: 0.7477\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6275 - loss: 0.6509 - val_accuracy: 0.5225 - val_loss: 0.7923\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6488 - loss: 0.6355 - val_accuracy: 0.5207 - val_loss: 0.8365\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6601 - loss: 0.6224 - val_accuracy: 0.5459 - val_loss: 0.7539\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6583 - loss: 0.6097 - val_accuracy: 0.5369 - val_loss: 0.8098\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6752 - loss: 0.6111 - val_accuracy: 0.5982 - val_loss: 0.6761\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6849 - loss: 0.5999 - val_accuracy: 0.6180 - val_loss: 0.6580\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6792 - loss: 0.5948 - val_accuracy: 0.6468 - val_loss: 0.6303\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6787 - loss: 0.5938 - val_accuracy: 0.6342 - val_loss: 0.6428\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7144 - loss: 0.5780 - val_accuracy: 0.6216 - val_loss: 0.6609\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7152 - loss: 0.5644 - val_accuracy: 0.6126 - val_loss: 0.6604\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7208 - loss: 0.5645 - val_accuracy: 0.6378 - val_loss: 0.6223\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7399 - loss: 0.5552 - val_accuracy: 0.6324 - val_loss: 0.6410\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7510 - loss: 0.5467 - val_accuracy: 0.6468 - val_loss: 0.6204\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7332 - loss: 0.5519 - val_accuracy: 0.6360 - val_loss: 0.6460\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7551 - loss: 0.5411 - val_accuracy: 0.6288 - val_loss: 0.6617\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7579 - loss: 0.5269 - val_accuracy: 0.5820 - val_loss: 0.7296\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7630 - loss: 0.5259 - val_accuracy: 0.6468 - val_loss: 0.6269\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5841 - loss: 0.6657\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 59ms/step - accuracy: 0.5420 - loss: 0.7094 - val_accuracy: 0.5189 - val_loss: 0.6927\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6030 - loss: 0.6597 - val_accuracy: 0.5189 - val_loss: 0.7017\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6203 - loss: 0.6353 - val_accuracy: 0.5189 - val_loss: 0.7236\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6573 - loss: 0.6209 - val_accuracy: 0.5189 - val_loss: 0.7482\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6777 - loss: 0.5971 - val_accuracy: 0.5189 - val_loss: 0.7866\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6909 - loss: 0.5798 - val_accuracy: 0.5189 - val_loss: 0.8518\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6912 - loss: 0.5853 - val_accuracy: 0.5189 - val_loss: 0.9258\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7111 - loss: 0.5801 - val_accuracy: 0.5189 - val_loss: 0.9287\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6960 - loss: 0.5762 - val_accuracy: 0.5225 - val_loss: 0.8607\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5485 - val_accuracy: 0.5982 - val_loss: 0.6685\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7367 - loss: 0.5406 - val_accuracy: 0.5766 - val_loss: 0.7257\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7458 - loss: 0.5361 - val_accuracy: 0.5892 - val_loss: 0.7191\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7571 - loss: 0.5293 - val_accuracy: 0.5946 - val_loss: 0.6592\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7659 - loss: 0.5229 - val_accuracy: 0.6198 - val_loss: 0.6440\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7743 - loss: 0.5031 - val_accuracy: 0.6126 - val_loss: 0.6436\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7660 - loss: 0.5094 - val_accuracy: 0.6144 - val_loss: 0.6438\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7898 - loss: 0.4981 - val_accuracy: 0.6288 - val_loss: 0.6504\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7937 - loss: 0.4824 - val_accuracy: 0.6234 - val_loss: 0.6472\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8008 - loss: 0.4867 - val_accuracy: 0.6234 - val_loss: 0.6422\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8075 - loss: 0.4828 - val_accuracy: 0.6126 - val_loss: 0.6711\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8140 - loss: 0.4663 - val_accuracy: 0.5946 - val_loss: 0.7096\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8081 - loss: 0.4677 - val_accuracy: 0.5622 - val_loss: 0.7985\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8222 - loss: 0.4534 - val_accuracy: 0.6342 - val_loss: 0.6375\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8409 - loss: 0.4523 - val_accuracy: 0.6252 - val_loss: 0.6464\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8340 - loss: 0.4466 - val_accuracy: 0.6324 - val_loss: 0.6426\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8476 - loss: 0.4371 - val_accuracy: 0.6324 - val_loss: 0.6484\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8625 - loss: 0.4228 - val_accuracy: 0.6306 - val_loss: 0.6423\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8538 - loss: 0.4243 - val_accuracy: 0.6162 - val_loss: 0.6470\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8641 - loss: 0.4224 - val_accuracy: 0.5802 - val_loss: 0.7641\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8675 - loss: 0.4139 - val_accuracy: 0.6324 - val_loss: 0.6310\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8762 - loss: 0.4060 - val_accuracy: 0.6414 - val_loss: 0.6334\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8740 - loss: 0.4043 - val_accuracy: 0.6360 - val_loss: 0.6657\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8856 - loss: 0.3926 - val_accuracy: 0.5946 - val_loss: 0.7310\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8868 - loss: 0.3950 - val_accuracy: 0.6468 - val_loss: 0.6306\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8936 - loss: 0.3835 - val_accuracy: 0.6288 - val_loss: 0.6359\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8941 - loss: 0.3790 - val_accuracy: 0.6396 - val_loss: 0.6319\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8940 - loss: 0.3773 - val_accuracy: 0.6523 - val_loss: 0.6295\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9116 - loss: 0.3639 - val_accuracy: 0.6144 - val_loss: 0.6368\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9095 - loss: 0.3599 - val_accuracy: 0.6018 - val_loss: 0.6972\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9170 - loss: 0.3497 - val_accuracy: 0.6216 - val_loss: 0.6512\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9195 - loss: 0.3471 - val_accuracy: 0.6523 - val_loss: 0.6514\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9243 - loss: 0.3413 - val_accuracy: 0.6000 - val_loss: 0.7024\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9329 - loss: 0.3360 - val_accuracy: 0.6216 - val_loss: 0.7007\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9271 - loss: 0.3355 - val_accuracy: 0.6108 - val_loss: 0.7045\n",
      "Epoch 45/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9248 - loss: 0.3290 - val_accuracy: 0.6342 - val_loss: 0.6328\n",
      "Epoch 46/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9381 - loss: 0.3243 - val_accuracy: 0.6450 - val_loss: 0.6352\n",
      "Epoch 47/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9351 - loss: 0.3227 - val_accuracy: 0.6072 - val_loss: 0.6995\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6377 - loss: 0.6391\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.5287 - loss: 0.7277 - val_accuracy: 0.5189 - val_loss: 0.7184\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6257 - loss: 0.6539 - val_accuracy: 0.5189 - val_loss: 0.7797\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6549 - loss: 0.6237 - val_accuracy: 0.5189 - val_loss: 0.8182\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6426 - loss: 0.6133 - val_accuracy: 0.5189 - val_loss: 0.8290\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6522 - loss: 0.6085 - val_accuracy: 0.5189 - val_loss: 0.8368\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6668 - loss: 0.5944 - val_accuracy: 0.5189 - val_loss: 0.8763\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.7132 - loss: 0.5682 - val_accuracy: 0.5189 - val_loss: 0.9085\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7155 - loss: 0.5605 - val_accuracy: 0.5189 - val_loss: 0.9073\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7096 - loss: 0.5662 - val_accuracy: 0.5243 - val_loss: 0.8245\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7294 - loss: 0.5557 - val_accuracy: 0.5550 - val_loss: 0.7337\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7391 - loss: 0.5421 - val_accuracy: 0.5604 - val_loss: 0.7620\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7611 - loss: 0.5204 - val_accuracy: 0.5730 - val_loss: 0.7092\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7576 - loss: 0.5116 - val_accuracy: 0.6090 - val_loss: 0.6628\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7724 - loss: 0.5012 - val_accuracy: 0.6144 - val_loss: 0.6665\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7881 - loss: 0.4957 - val_accuracy: 0.6090 - val_loss: 0.6649\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7871 - loss: 0.4963 - val_accuracy: 0.6072 - val_loss: 0.6621\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8038 - loss: 0.4821 - val_accuracy: 0.6036 - val_loss: 0.6632\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7979 - loss: 0.4798 - val_accuracy: 0.5964 - val_loss: 0.6688\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8145 - loss: 0.4566 - val_accuracy: 0.6072 - val_loss: 0.6716\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8266 - loss: 0.4571 - val_accuracy: 0.6072 - val_loss: 0.6683\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.8316 - loss: 0.4514 - val_accuracy: 0.5910 - val_loss: 0.7417\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8341 - loss: 0.4456 - val_accuracy: 0.6108 - val_loss: 0.6862\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8347 - loss: 0.4461 - val_accuracy: 0.6018 - val_loss: 0.6625\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8539 - loss: 0.4354 - val_accuracy: 0.6072 - val_loss: 0.6657\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5305 - loss: 0.7358\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.4385 - loss: 1.1652 - val_accuracy: 0.4793 - val_loss: 0.6964\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5056 - loss: 0.7493 - val_accuracy: 0.4937 - val_loss: 0.6979\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.5851 - loss: 0.6802 - val_accuracy: 0.4793 - val_loss: 0.6953\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6169 - loss: 0.6525 - val_accuracy: 0.5171 - val_loss: 0.7147\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.6303 - loss: 0.6371 - val_accuracy: 0.5189 - val_loss: 0.7835\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6314 - loss: 0.6330 - val_accuracy: 0.5189 - val_loss: 0.8522\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.6669 - loss: 0.6172 - val_accuracy: 0.5189 - val_loss: 0.9409\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6612 - loss: 0.6033 - val_accuracy: 0.5189 - val_loss: 0.9174\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6922 - loss: 0.5861 - val_accuracy: 0.5189 - val_loss: 0.9334\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6832 - loss: 0.5835 - val_accuracy: 0.5495 - val_loss: 0.7557\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.6926 - loss: 0.5867 - val_accuracy: 0.5315 - val_loss: 0.8364\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7164 - loss: 0.5639 - val_accuracy: 0.5658 - val_loss: 0.7284\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7237 - loss: 0.5648 - val_accuracy: 0.5712 - val_loss: 0.7439\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7293 - loss: 0.5510 - val_accuracy: 0.6018 - val_loss: 0.6787\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7375 - loss: 0.5513 - val_accuracy: 0.5874 - val_loss: 0.6622\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7495 - loss: 0.5396 - val_accuracy: 0.6036 - val_loss: 0.6966\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7431 - loss: 0.5279 - val_accuracy: 0.6000 - val_loss: 0.6680\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7477 - loss: 0.5234 - val_accuracy: 0.5838 - val_loss: 0.6827\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7854 - loss: 0.5055 - val_accuracy: 0.5946 - val_loss: 0.6729\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7691 - loss: 0.5100 - val_accuracy: 0.5892 - val_loss: 0.6665\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.7927 - loss: 0.5040 - val_accuracy: 0.5892 - val_loss: 0.6672\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8012 - loss: 0.4909 - val_accuracy: 0.5928 - val_loss: 0.6613\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.7964 - loss: 0.4901 - val_accuracy: 0.5892 - val_loss: 0.6683\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8169 - loss: 0.4796 - val_accuracy: 0.6054 - val_loss: 0.6817\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8024 - loss: 0.4768 - val_accuracy: 0.5604 - val_loss: 0.7555\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8309 - loss: 0.4642 - val_accuracy: 0.6018 - val_loss: 0.6613\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8280 - loss: 0.4618 - val_accuracy: 0.5946 - val_loss: 0.6598\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8369 - loss: 0.4463 - val_accuracy: 0.6054 - val_loss: 0.6608\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8434 - loss: 0.4492 - val_accuracy: 0.6018 - val_loss: 0.6676\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8295 - loss: 0.4503 - val_accuracy: 0.5730 - val_loss: 0.7005\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8651 - loss: 0.4243 - val_accuracy: 0.6072 - val_loss: 0.6633\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8493 - loss: 0.4342 - val_accuracy: 0.6054 - val_loss: 0.6619\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8634 - loss: 0.4122 - val_accuracy: 0.6018 - val_loss: 0.6617\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8722 - loss: 0.4180 - val_accuracy: 0.5982 - val_loss: 0.6637\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8869 - loss: 0.4018 - val_accuracy: 0.5964 - val_loss: 0.6614\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8892 - loss: 0.3945 - val_accuracy: 0.6162 - val_loss: 0.6600\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8766 - loss: 0.3952 - val_accuracy: 0.6090 - val_loss: 0.6642\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.8858 - loss: 0.3881 - val_accuracy: 0.6090 - val_loss: 0.6942\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8907 - loss: 0.3800 - val_accuracy: 0.6144 - val_loss: 0.6565\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.8900 - loss: 0.3704 - val_accuracy: 0.6108 - val_loss: 0.6641\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9146 - loss: 0.3660 - val_accuracy: 0.6126 - val_loss: 0.6716\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9122 - loss: 0.3608 - val_accuracy: 0.6288 - val_loss: 0.6787\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9041 - loss: 0.3656 - val_accuracy: 0.6126 - val_loss: 0.6617\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9287 - loss: 0.3378 - val_accuracy: 0.6414 - val_loss: 0.6528\n",
      "Epoch 45/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9297 - loss: 0.3344 - val_accuracy: 0.6252 - val_loss: 0.6798\n",
      "Epoch 46/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9306 - loss: 0.3276 - val_accuracy: 0.5495 - val_loss: 0.8915\n",
      "Epoch 47/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9255 - loss: 0.3256 - val_accuracy: 0.5532 - val_loss: 0.8270\n",
      "Epoch 48/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9381 - loss: 0.3177 - val_accuracy: 0.6072 - val_loss: 0.6817\n",
      "Epoch 49/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9454 - loss: 0.3092 - val_accuracy: 0.6252 - val_loss: 0.6593\n",
      "Epoch 50/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9510 - loss: 0.2995 - val_accuracy: 0.6234 - val_loss: 0.6769\n",
      "Epoch 51/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9495 - loss: 0.3008 - val_accuracy: 0.6450 - val_loss: 0.6513\n",
      "Epoch 52/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9564 - loss: 0.2946 - val_accuracy: 0.6000 - val_loss: 0.7045\n",
      "Epoch 53/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9544 - loss: 0.2843 - val_accuracy: 0.6360 - val_loss: 0.6609\n",
      "Epoch 54/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.9664 - loss: 0.2783 - val_accuracy: 0.6288 - val_loss: 0.6607\n",
      "Epoch 55/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9556 - loss: 0.2800 - val_accuracy: 0.6126 - val_loss: 0.6704\n",
      "Epoch 56/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9681 - loss: 0.2659 - val_accuracy: 0.6378 - val_loss: 0.6604\n",
      "Epoch 57/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9621 - loss: 0.2609 - val_accuracy: 0.6270 - val_loss: 0.6603\n",
      "Epoch 58/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - accuracy: 0.9608 - loss: 0.2616 - val_accuracy: 0.5964 - val_loss: 0.7372\n",
      "Epoch 59/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9616 - loss: 0.2572 - val_accuracy: 0.6432 - val_loss: 0.6567\n",
      "Epoch 60/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9606 - loss: 0.2498 - val_accuracy: 0.6252 - val_loss: 0.6828\n",
      "Epoch 61/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - accuracy: 0.9702 - loss: 0.2475 - val_accuracy: 0.5964 - val_loss: 0.7429\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5793 - loss: 0.6919\n",
      "testing model 11 out of 12\n",
      "testing params: average, 3, 9, 32,1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.5362 - loss: 0.7161 - val_accuracy: 0.4793 - val_loss: 0.7027\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.5776 - loss: 0.6799 - val_accuracy: 0.4865 - val_loss: 0.6982\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6174 - loss: 0.6529 - val_accuracy: 0.5135 - val_loss: 0.6940\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6698 - loss: 0.6292 - val_accuracy: 0.5189 - val_loss: 0.7084\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6633 - loss: 0.6179 - val_accuracy: 0.5261 - val_loss: 0.7334\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6845 - loss: 0.5950 - val_accuracy: 0.5261 - val_loss: 0.7119\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6899 - loss: 0.5879 - val_accuracy: 0.5207 - val_loss: 0.7915\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7057 - loss: 0.5755 - val_accuracy: 0.5279 - val_loss: 0.7377\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7022 - loss: 0.5682 - val_accuracy: 0.5243 - val_loss: 0.7827\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7304 - loss: 0.5397 - val_accuracy: 0.5441 - val_loss: 0.7361\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7557 - loss: 0.5313 - val_accuracy: 0.5766 - val_loss: 0.6626\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7553 - loss: 0.5217 - val_accuracy: 0.5441 - val_loss: 0.7712\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7655 - loss: 0.5083 - val_accuracy: 0.5297 - val_loss: 0.8161\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7562 - loss: 0.5089 - val_accuracy: 0.5748 - val_loss: 0.6591\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7836 - loss: 0.5007 - val_accuracy: 0.5676 - val_loss: 0.7127\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7901 - loss: 0.4893 - val_accuracy: 0.5477 - val_loss: 0.8813\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8000 - loss: 0.4790 - val_accuracy: 0.5838 - val_loss: 0.6661\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8190 - loss: 0.4513 - val_accuracy: 0.5928 - val_loss: 0.6567\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8189 - loss: 0.4606 - val_accuracy: 0.6090 - val_loss: 0.7047\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8232 - loss: 0.4547 - val_accuracy: 0.5820 - val_loss: 0.6650\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8195 - loss: 0.4406 - val_accuracy: 0.5802 - val_loss: 0.6642\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8405 - loss: 0.4334 - val_accuracy: 0.5532 - val_loss: 0.7083\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8438 - loss: 0.4292 - val_accuracy: 0.5640 - val_loss: 0.7126\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8592 - loss: 0.4151 - val_accuracy: 0.5297 - val_loss: 1.1626\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8551 - loss: 0.4142 - val_accuracy: 0.6541 - val_loss: 0.6559\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8608 - loss: 0.4010 - val_accuracy: 0.5423 - val_loss: 0.8752\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8588 - loss: 0.3968 - val_accuracy: 0.6613 - val_loss: 0.6574\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8789 - loss: 0.3761 - val_accuracy: 0.5658 - val_loss: 0.8246\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8771 - loss: 0.3769 - val_accuracy: 0.5730 - val_loss: 0.8005\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8779 - loss: 0.3747 - val_accuracy: 0.5532 - val_loss: 0.8933\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8853 - loss: 0.3651 - val_accuracy: 0.5243 - val_loss: 1.1624\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8761 - loss: 0.3702 - val_accuracy: 0.5820 - val_loss: 0.7270\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8873 - loss: 0.3574 - val_accuracy: 0.6559 - val_loss: 0.6116\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8945 - loss: 0.3497 - val_accuracy: 0.6775 - val_loss: 0.6187\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.9008 - loss: 0.3410 - val_accuracy: 0.5658 - val_loss: 0.8271\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9040 - loss: 0.3444 - val_accuracy: 0.5856 - val_loss: 0.7233\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9084 - loss: 0.3331 - val_accuracy: 0.6378 - val_loss: 0.7155\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9080 - loss: 0.3287 - val_accuracy: 0.5928 - val_loss: 0.6715\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8949 - loss: 0.3261 - val_accuracy: 0.5676 - val_loss: 0.8429\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9140 - loss: 0.3249 - val_accuracy: 0.6144 - val_loss: 0.6551\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9122 - loss: 0.3132 - val_accuracy: 0.5225 - val_loss: 1.4176\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9115 - loss: 0.3073 - val_accuracy: 0.5658 - val_loss: 0.8514\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9332 - loss: 0.2939 - val_accuracy: 0.6018 - val_loss: 0.9005\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9204 - loss: 0.2942 - val_accuracy: 0.6234 - val_loss: 0.6345\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7089 - loss: 0.5863\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.5349 - loss: 0.7193 - val_accuracy: 0.4811 - val_loss: 0.6962\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.5717 - loss: 0.6766 - val_accuracy: 0.4847 - val_loss: 0.6953\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6108 - loss: 0.6566 - val_accuracy: 0.5423 - val_loss: 0.6911\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6135 - loss: 0.6410 - val_accuracy: 0.5423 - val_loss: 0.6874\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6386 - loss: 0.6250 - val_accuracy: 0.5387 - val_loss: 0.6854\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6430 - loss: 0.6218 - val_accuracy: 0.5297 - val_loss: 0.6877\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6684 - loss: 0.6043 - val_accuracy: 0.5477 - val_loss: 0.6820\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6989 - loss: 0.5892 - val_accuracy: 0.5604 - val_loss: 0.6824\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6989 - loss: 0.5828 - val_accuracy: 0.5495 - val_loss: 0.7053\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7237 - loss: 0.5697 - val_accuracy: 0.5441 - val_loss: 0.6801\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7425 - loss: 0.5533 - val_accuracy: 0.6018 - val_loss: 0.6659\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7533 - loss: 0.5471 - val_accuracy: 0.5802 - val_loss: 0.6674\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7553 - loss: 0.5400 - val_accuracy: 0.5838 - val_loss: 0.6619\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7783 - loss: 0.5249 - val_accuracy: 0.5964 - val_loss: 0.6612\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7556 - loss: 0.5259 - val_accuracy: 0.5640 - val_loss: 0.7133\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7863 - loss: 0.5123 - val_accuracy: 0.5730 - val_loss: 0.7794\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7872 - loss: 0.5043 - val_accuracy: 0.5874 - val_loss: 0.7116\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7926 - loss: 0.4928 - val_accuracy: 0.5748 - val_loss: 0.6879\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8130 - loss: 0.4852 - val_accuracy: 0.6054 - val_loss: 0.6615\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7969 - loss: 0.4825 - val_accuracy: 0.5946 - val_loss: 0.7198\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8128 - loss: 0.4680 - val_accuracy: 0.5928 - val_loss: 0.7461\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8365 - loss: 0.4568 - val_accuracy: 0.6306 - val_loss: 0.6430\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8086 - loss: 0.4678 - val_accuracy: 0.5550 - val_loss: 0.8167\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8177 - loss: 0.4551 - val_accuracy: 0.6216 - val_loss: 0.6513\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8297 - loss: 0.4449 - val_accuracy: 0.5838 - val_loss: 0.7802\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8319 - loss: 0.4411 - val_accuracy: 0.6450 - val_loss: 0.6362\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8382 - loss: 0.4344 - val_accuracy: 0.6306 - val_loss: 0.6409\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8303 - loss: 0.4259 - val_accuracy: 0.6595 - val_loss: 0.6241\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8511 - loss: 0.4242 - val_accuracy: 0.6144 - val_loss: 0.7026\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8449 - loss: 0.4270 - val_accuracy: 0.6613 - val_loss: 0.6245\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8499 - loss: 0.4189 - val_accuracy: 0.6703 - val_loss: 0.6285\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8664 - loss: 0.4072 - val_accuracy: 0.5622 - val_loss: 0.9954\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8655 - loss: 0.3992 - val_accuracy: 0.4901 - val_loss: 2.1283\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8643 - loss: 0.3936 - val_accuracy: 0.5856 - val_loss: 0.7323\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8664 - loss: 0.4010 - val_accuracy: 0.6198 - val_loss: 0.7163\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8591 - loss: 0.3939 - val_accuracy: 0.6162 - val_loss: 0.6653\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8638 - loss: 0.3840 - val_accuracy: 0.6432 - val_loss: 0.6913\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8790 - loss: 0.3724 - val_accuracy: 0.6541 - val_loss: 0.6385\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8799 - loss: 0.3758 - val_accuracy: 0.6559 - val_loss: 0.6293\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8996 - loss: 0.3606 - val_accuracy: 0.6486 - val_loss: 0.6300\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8953 - loss: 0.3542 - val_accuracy: 0.6523 - val_loss: 0.6251\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6386 - loss: 0.6541\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.5296 - loss: 0.7253 - val_accuracy: 0.5189 - val_loss: 0.6915\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5585 - loss: 0.6869 - val_accuracy: 0.5189 - val_loss: 0.6902\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.6008 - loss: 0.6617 - val_accuracy: 0.5189 - val_loss: 0.6922\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6130 - loss: 0.6433 - val_accuracy: 0.5207 - val_loss: 0.6895\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6224 - loss: 0.6329 - val_accuracy: 0.5315 - val_loss: 0.6872\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6614 - loss: 0.6183 - val_accuracy: 0.5423 - val_loss: 0.6868\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6799 - loss: 0.5988 - val_accuracy: 0.5315 - val_loss: 0.7005\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6965 - loss: 0.5910 - val_accuracy: 0.5477 - val_loss: 0.6906\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7290 - loss: 0.5625 - val_accuracy: 0.5514 - val_loss: 0.7056\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7164 - loss: 0.5608 - val_accuracy: 0.5910 - val_loss: 0.6593\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7276 - loss: 0.5514 - val_accuracy: 0.6018 - val_loss: 0.6630\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7576 - loss: 0.5332 - val_accuracy: 0.5514 - val_loss: 0.7313\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7503 - loss: 0.5259 - val_accuracy: 0.6054 - val_loss: 0.6588\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7595 - loss: 0.5265 - val_accuracy: 0.5423 - val_loss: 0.7655\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7726 - loss: 0.5078 - val_accuracy: 0.5766 - val_loss: 0.6904\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7806 - loss: 0.4974 - val_accuracy: 0.6162 - val_loss: 0.6713\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7742 - loss: 0.4964 - val_accuracy: 0.6180 - val_loss: 0.6475\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7704 - loss: 0.4914 - val_accuracy: 0.5946 - val_loss: 0.6863\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8094 - loss: 0.4685 - val_accuracy: 0.6198 - val_loss: 0.6545\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7927 - loss: 0.4723 - val_accuracy: 0.5568 - val_loss: 0.7624\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8265 - loss: 0.4485 - val_accuracy: 0.6144 - val_loss: 0.6826\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8080 - loss: 0.4480 - val_accuracy: 0.5586 - val_loss: 0.7492\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8474 - loss: 0.4325 - val_accuracy: 0.5495 - val_loss: 0.7898\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8284 - loss: 0.4381 - val_accuracy: 0.6523 - val_loss: 0.6407\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8320 - loss: 0.4233 - val_accuracy: 0.6360 - val_loss: 0.6735\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8532 - loss: 0.4035 - val_accuracy: 0.6342 - val_loss: 0.6345\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8492 - loss: 0.4044 - val_accuracy: 0.5820 - val_loss: 0.9345\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8512 - loss: 0.3969 - val_accuracy: 0.6378 - val_loss: 0.6664\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8395 - loss: 0.4013 - val_accuracy: 0.6306 - val_loss: 0.6520\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8808 - loss: 0.3803 - val_accuracy: 0.5820 - val_loss: 0.7563\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8782 - loss: 0.3748 - val_accuracy: 0.6234 - val_loss: 0.7400\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8754 - loss: 0.3698 - val_accuracy: 0.6288 - val_loss: 0.7209\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8895 - loss: 0.3524 - val_accuracy: 0.6306 - val_loss: 0.6464\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8970 - loss: 0.3519 - val_accuracy: 0.6757 - val_loss: 0.6191\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8896 - loss: 0.3482 - val_accuracy: 0.6631 - val_loss: 0.6561\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8787 - loss: 0.3603 - val_accuracy: 0.5495 - val_loss: 0.8588\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8943 - loss: 0.3355 - val_accuracy: 0.5694 - val_loss: 0.8133\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9054 - loss: 0.3328 - val_accuracy: 0.6252 - val_loss: 0.6749\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8966 - loss: 0.3340 - val_accuracy: 0.5910 - val_loss: 0.9207\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9073 - loss: 0.3271 - val_accuracy: 0.6721 - val_loss: 0.6247\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9039 - loss: 0.3250 - val_accuracy: 0.5405 - val_loss: 0.9667\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9044 - loss: 0.3175 - val_accuracy: 0.6739 - val_loss: 0.6441\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9149 - loss: 0.3134 - val_accuracy: 0.6378 - val_loss: 0.7508\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9205 - loss: 0.2997 - val_accuracy: 0.6739 - val_loss: 0.6351\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6383 - loss: 0.6542\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.4829 - loss: 0.7403 - val_accuracy: 0.5189 - val_loss: 0.6918\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5562 - loss: 0.6864 - val_accuracy: 0.5189 - val_loss: 0.6933\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.5971 - loss: 0.6614 - val_accuracy: 0.5189 - val_loss: 0.6986\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6189 - loss: 0.6483 - val_accuracy: 0.5189 - val_loss: 0.7105\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6642 - loss: 0.6197 - val_accuracy: 0.5207 - val_loss: 0.7268\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6646 - loss: 0.6151 - val_accuracy: 0.5225 - val_loss: 0.7333\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6879 - loss: 0.6018 - val_accuracy: 0.5189 - val_loss: 0.7399\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7075 - loss: 0.5975 - val_accuracy: 0.5207 - val_loss: 0.7678\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7086 - loss: 0.5738 - val_accuracy: 0.5874 - val_loss: 0.6805\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7402 - loss: 0.5534 - val_accuracy: 0.5532 - val_loss: 0.7182\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7299 - loss: 0.5564 - val_accuracy: 0.5820 - val_loss: 0.6728\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7549 - loss: 0.5349 - val_accuracy: 0.5892 - val_loss: 0.6668\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7608 - loss: 0.5347 - val_accuracy: 0.5892 - val_loss: 0.6851\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7672 - loss: 0.5131 - val_accuracy: 0.5694 - val_loss: 0.6911\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7671 - loss: 0.5160 - val_accuracy: 0.6054 - val_loss: 0.6848\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7757 - loss: 0.5076 - val_accuracy: 0.5712 - val_loss: 0.6926\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.7719 - loss: 0.5043 - val_accuracy: 0.6036 - val_loss: 0.6452\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8070 - loss: 0.4860 - val_accuracy: 0.6036 - val_loss: 0.6919\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7910 - loss: 0.4886 - val_accuracy: 0.6126 - val_loss: 0.6631\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8020 - loss: 0.4781 - val_accuracy: 0.6216 - val_loss: 0.6617\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8247 - loss: 0.4573 - val_accuracy: 0.5964 - val_loss: 0.6558\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8123 - loss: 0.4655 - val_accuracy: 0.6090 - val_loss: 0.6426\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8400 - loss: 0.4407 - val_accuracy: 0.5784 - val_loss: 0.7101\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8483 - loss: 0.4313 - val_accuracy: 0.5658 - val_loss: 0.7497\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.8330 - loss: 0.4393 - val_accuracy: 0.6180 - val_loss: 0.6786\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8517 - loss: 0.4174 - val_accuracy: 0.5658 - val_loss: 0.7583\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8699 - loss: 0.4114 - val_accuracy: 0.5730 - val_loss: 0.7267\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8555 - loss: 0.4157 - val_accuracy: 0.6090 - val_loss: 0.6621\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8597 - loss: 0.4057 - val_accuracy: 0.5964 - val_loss: 0.6729\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8784 - loss: 0.3934 - val_accuracy: 0.6468 - val_loss: 0.6329\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8645 - loss: 0.3874 - val_accuracy: 0.5658 - val_loss: 0.7847\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8890 - loss: 0.3829 - val_accuracy: 0.6432 - val_loss: 0.6393\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8774 - loss: 0.3716 - val_accuracy: 0.5712 - val_loss: 0.7731\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8728 - loss: 0.3707 - val_accuracy: 0.5982 - val_loss: 0.6768\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8951 - loss: 0.3614 - val_accuracy: 0.5892 - val_loss: 0.7115\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8855 - loss: 0.3592 - val_accuracy: 0.5946 - val_loss: 0.7232\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8902 - loss: 0.3571 - val_accuracy: 0.5676 - val_loss: 0.8427\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9029 - loss: 0.3394 - val_accuracy: 0.6288 - val_loss: 0.7215\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8980 - loss: 0.3312 - val_accuracy: 0.6252 - val_loss: 0.6890\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8956 - loss: 0.3382 - val_accuracy: 0.5640 - val_loss: 0.8123\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.7123 - loss: 0.5494\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.5240 - loss: 0.7026 - val_accuracy: 0.5189 - val_loss: 0.6945\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.5656 - loss: 0.6710 - val_accuracy: 0.5189 - val_loss: 0.7109\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6062 - loss: 0.6497 - val_accuracy: 0.5189 - val_loss: 0.7181\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6249 - loss: 0.6414 - val_accuracy: 0.5189 - val_loss: 0.7085\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6411 - loss: 0.6287 - val_accuracy: 0.5261 - val_loss: 0.7046\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6753 - loss: 0.6101 - val_accuracy: 0.5405 - val_loss: 0.6842\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.6614 - loss: 0.6076 - val_accuracy: 0.5297 - val_loss: 0.6877\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.6881 - loss: 0.6024 - val_accuracy: 0.5658 - val_loss: 0.6730\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7004 - loss: 0.5895 - val_accuracy: 0.5928 - val_loss: 0.6623\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7262 - loss: 0.5771 - val_accuracy: 0.5640 - val_loss: 0.6691\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7195 - loss: 0.5645 - val_accuracy: 0.6000 - val_loss: 0.6548\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7306 - loss: 0.5589 - val_accuracy: 0.5946 - val_loss: 0.6518\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7386 - loss: 0.5487 - val_accuracy: 0.6000 - val_loss: 0.6796\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7557 - loss: 0.5363 - val_accuracy: 0.5333 - val_loss: 0.8557\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7538 - loss: 0.5293 - val_accuracy: 0.5892 - val_loss: 0.6508\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7773 - loss: 0.5160 - val_accuracy: 0.5802 - val_loss: 0.7013\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.7645 - loss: 0.5128 - val_accuracy: 0.5910 - val_loss: 0.7283\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7717 - loss: 0.5062 - val_accuracy: 0.5568 - val_loss: 0.7453\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.8077 - loss: 0.4894 - val_accuracy: 0.6162 - val_loss: 0.6731\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8034 - loss: 0.4832 - val_accuracy: 0.5658 - val_loss: 0.6672\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7952 - loss: 0.4796 - val_accuracy: 0.5568 - val_loss: 0.8068\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8067 - loss: 0.4713 - val_accuracy: 0.6000 - val_loss: 0.6564\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8089 - loss: 0.4700 - val_accuracy: 0.6018 - val_loss: 0.7104\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8082 - loss: 0.4644 - val_accuracy: 0.5514 - val_loss: 0.8231\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8338 - loss: 0.4504 - val_accuracy: 0.5225 - val_loss: 1.0546\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8282 - loss: 0.4502 - val_accuracy: 0.5838 - val_loss: 0.7586\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8455 - loss: 0.4425 - val_accuracy: 0.5820 - val_loss: 0.6917\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8380 - loss: 0.4373 - val_accuracy: 0.6090 - val_loss: 0.6555\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.8422 - loss: 0.4287 - val_accuracy: 0.6396 - val_loss: 0.6351\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8364 - loss: 0.4275 - val_accuracy: 0.5982 - val_loss: 0.6650\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8546 - loss: 0.4148 - val_accuracy: 0.6018 - val_loss: 0.7430\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8673 - loss: 0.4038 - val_accuracy: 0.5676 - val_loss: 0.7838\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8444 - loss: 0.4098 - val_accuracy: 0.6324 - val_loss: 0.6527\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8695 - loss: 0.4034 - val_accuracy: 0.5694 - val_loss: 0.7678\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8636 - loss: 0.3954 - val_accuracy: 0.5874 - val_loss: 0.7908\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8715 - loss: 0.3935 - val_accuracy: 0.5568 - val_loss: 0.8515\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8637 - loss: 0.3862 - val_accuracy: 0.5730 - val_loss: 0.7840\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8727 - loss: 0.3815 - val_accuracy: 0.5676 - val_loss: 0.7795\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8844 - loss: 0.3730 - val_accuracy: 0.5225 - val_loss: 1.3151\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6861 - loss: 0.5830\n",
      "testing model 12 out of 12\n",
      "testing params: average, 5, 9, 32,1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.4740 - loss: 0.7099 - val_accuracy: 0.5207 - val_loss: 0.6922\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5485 - loss: 0.6829 - val_accuracy: 0.5207 - val_loss: 0.6935\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.5713 - loss: 0.6739 - val_accuracy: 0.5207 - val_loss: 0.6964\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5985 - loss: 0.6651 - val_accuracy: 0.5207 - val_loss: 0.7009\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6109 - loss: 0.6551 - val_accuracy: 0.5207 - val_loss: 0.7029\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6484 - loss: 0.6434 - val_accuracy: 0.5207 - val_loss: 0.7070\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6421 - loss: 0.6447 - val_accuracy: 0.5207 - val_loss: 0.7070\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6357 - loss: 0.6436 - val_accuracy: 0.5261 - val_loss: 0.6883\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6400 - loss: 0.6347 - val_accuracy: 0.5189 - val_loss: 0.7077\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6659 - loss: 0.6300 - val_accuracy: 0.5207 - val_loss: 0.7162\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.6399 - loss: 0.6356 - val_accuracy: 0.6000 - val_loss: 0.6730\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6581 - loss: 0.6267 - val_accuracy: 0.5550 - val_loss: 0.6774\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6608 - loss: 0.6231 - val_accuracy: 0.5586 - val_loss: 0.6893\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6769 - loss: 0.6128 - val_accuracy: 0.6180 - val_loss: 0.6615\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6622 - loss: 0.6236 - val_accuracy: 0.5874 - val_loss: 0.6784\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6812 - loss: 0.6044 - val_accuracy: 0.6054 - val_loss: 0.6644\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6757 - loss: 0.6049 - val_accuracy: 0.5009 - val_loss: 0.8829\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6742 - loss: 0.6033 - val_accuracy: 0.5459 - val_loss: 0.6936\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6864 - loss: 0.6010 - val_accuracy: 0.5423 - val_loss: 0.7311\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6661 - loss: 0.6050 - val_accuracy: 0.6306 - val_loss: 0.6497\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6929 - loss: 0.5968 - val_accuracy: 0.5333 - val_loss: 0.7208\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6900 - loss: 0.5956 - val_accuracy: 0.6126 - val_loss: 0.6472\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6999 - loss: 0.5935 - val_accuracy: 0.6198 - val_loss: 0.6554\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6952 - loss: 0.5913 - val_accuracy: 0.5369 - val_loss: 0.7247\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7003 - loss: 0.5846 - val_accuracy: 0.5568 - val_loss: 0.6984\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7130 - loss: 0.5816 - val_accuracy: 0.6378 - val_loss: 0.6501\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7072 - loss: 0.5791 - val_accuracy: 0.5694 - val_loss: 0.6628\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6931 - loss: 0.5834 - val_accuracy: 0.5586 - val_loss: 0.6709\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7158 - loss: 0.5806 - val_accuracy: 0.5207 - val_loss: 0.8591\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7015 - loss: 0.5770 - val_accuracy: 0.5207 - val_loss: 0.8138\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7203 - loss: 0.5652 - val_accuracy: 0.5243 - val_loss: 0.7225\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7114 - loss: 0.5704 - val_accuracy: 0.5946 - val_loss: 0.6842\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7193 - loss: 0.5650 - val_accuracy: 0.6144 - val_loss: 0.6477\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7071 - loss: 0.5702 - val_accuracy: 0.5838 - val_loss: 0.6538\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7225 - loss: 0.5605 - val_accuracy: 0.5982 - val_loss: 0.6873\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7219 - loss: 0.5538 - val_accuracy: 0.4703 - val_loss: 1.5319\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7300 - loss: 0.5771\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 58ms/step - accuracy: 0.4570 - loss: 0.7763 - val_accuracy: 0.4811 - val_loss: 0.6947\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.4861 - loss: 0.7211 - val_accuracy: 0.4811 - val_loss: 0.6949\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5040 - loss: 0.7004 - val_accuracy: 0.5369 - val_loss: 0.6917\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5314 - loss: 0.6882 - val_accuracy: 0.5153 - val_loss: 0.6901\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5689 - loss: 0.6804 - val_accuracy: 0.5189 - val_loss: 0.6900\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5963 - loss: 0.6680 - val_accuracy: 0.5189 - val_loss: 0.6873\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6100 - loss: 0.6639 - val_accuracy: 0.5261 - val_loss: 0.6834\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6184 - loss: 0.6545 - val_accuracy: 0.5189 - val_loss: 0.6976\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6369 - loss: 0.6493 - val_accuracy: 0.5207 - val_loss: 0.6873\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6646 - loss: 0.6393 - val_accuracy: 0.5712 - val_loss: 0.6666\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6572 - loss: 0.6353 - val_accuracy: 0.5550 - val_loss: 0.6749\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6515 - loss: 0.6360 - val_accuracy: 0.4865 - val_loss: 0.9126\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6477 - loss: 0.6333 - val_accuracy: 0.6523 - val_loss: 0.6520\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6731 - loss: 0.6218 - val_accuracy: 0.6180 - val_loss: 0.6714\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6619 - loss: 0.6254 - val_accuracy: 0.4955 - val_loss: 0.9652\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6831 - loss: 0.6187 - val_accuracy: 0.5189 - val_loss: 0.7627\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6536 - loss: 0.6241 - val_accuracy: 0.4919 - val_loss: 1.0294\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6720 - loss: 0.6136 - val_accuracy: 0.6162 - val_loss: 0.6649\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6910 - loss: 0.5977 - val_accuracy: 0.6036 - val_loss: 0.6433\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6987 - loss: 0.6026 - val_accuracy: 0.6649 - val_loss: 0.6235\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6880 - loss: 0.6025 - val_accuracy: 0.5856 - val_loss: 0.6463\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6980 - loss: 0.5968 - val_accuracy: 0.5802 - val_loss: 0.6551\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6894 - loss: 0.5993 - val_accuracy: 0.5225 - val_loss: 0.7341\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6865 - loss: 0.5974 - val_accuracy: 0.5045 - val_loss: 1.0813\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6906 - loss: 0.5998 - val_accuracy: 0.6541 - val_loss: 0.6241\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6954 - loss: 0.5924 - val_accuracy: 0.6090 - val_loss: 0.6382\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7099 - loss: 0.5828 - val_accuracy: 0.6613 - val_loss: 0.6171\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7140 - loss: 0.5783 - val_accuracy: 0.6360 - val_loss: 0.6507\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7057 - loss: 0.5818 - val_accuracy: 0.5441 - val_loss: 0.7070\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7042 - loss: 0.5791 - val_accuracy: 0.6198 - val_loss: 0.6645\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7384 - loss: 0.5681\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 55ms/step - accuracy: 0.5471 - loss: 0.6892 - val_accuracy: 0.5189 - val_loss: 0.6919\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.5806 - loss: 0.6760 - val_accuracy: 0.5189 - val_loss: 0.6974\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6075 - loss: 0.6636 - val_accuracy: 0.5189 - val_loss: 0.7058\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5829 - loss: 0.6683 - val_accuracy: 0.5189 - val_loss: 0.7055\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5989 - loss: 0.6614 - val_accuracy: 0.5189 - val_loss: 0.7090\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6235 - loss: 0.6551 - val_accuracy: 0.5189 - val_loss: 0.7124\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6203 - loss: 0.6492 - val_accuracy: 0.5189 - val_loss: 0.7080\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6274 - loss: 0.6473 - val_accuracy: 0.5189 - val_loss: 0.6960\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6526 - loss: 0.6414 - val_accuracy: 0.5694 - val_loss: 0.6740\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6434 - loss: 0.6356 - val_accuracy: 0.5297 - val_loss: 0.6890\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6543 - loss: 0.6310 - val_accuracy: 0.5207 - val_loss: 0.7187\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6815 - loss: 0.6226 - val_accuracy: 0.6360 - val_loss: 0.6463\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6545 - loss: 0.6266 - val_accuracy: 0.6306 - val_loss: 0.6526\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6719 - loss: 0.6200 - val_accuracy: 0.5658 - val_loss: 0.6581\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6760 - loss: 0.6181 - val_accuracy: 0.5351 - val_loss: 0.6888\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6677 - loss: 0.6163 - val_accuracy: 0.5622 - val_loss: 0.6707\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6708 - loss: 0.6117 - val_accuracy: 0.6486 - val_loss: 0.6312\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6719 - loss: 0.6117 - val_accuracy: 0.6108 - val_loss: 0.6428\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6836 - loss: 0.6056 - val_accuracy: 0.6252 - val_loss: 0.6517\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6936 - loss: 0.5953 - val_accuracy: 0.5820 - val_loss: 0.6564\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6849 - loss: 0.5918 - val_accuracy: 0.5459 - val_loss: 0.6932\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6692 - loss: 0.6045 - val_accuracy: 0.5459 - val_loss: 0.7517\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7043 - loss: 0.5857 - val_accuracy: 0.5207 - val_loss: 0.7958\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6825 - loss: 0.5991 - val_accuracy: 0.5640 - val_loss: 0.7300\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6786 - loss: 0.5872 - val_accuracy: 0.5405 - val_loss: 0.7226\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6790 - loss: 0.5903 - val_accuracy: 0.6486 - val_loss: 0.6087\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6991 - loss: 0.5779 - val_accuracy: 0.6523 - val_loss: 0.6307\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7031 - loss: 0.5776 - val_accuracy: 0.6595 - val_loss: 0.6075\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7109 - loss: 0.5659 - val_accuracy: 0.6739 - val_loss: 0.6150\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6926 - loss: 0.5805 - val_accuracy: 0.6577 - val_loss: 0.6113\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6916 - loss: 0.5855 - val_accuracy: 0.5928 - val_loss: 0.6413\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7163 - loss: 0.5718 - val_accuracy: 0.6252 - val_loss: 0.6449\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7080 - loss: 0.5734 - val_accuracy: 0.5369 - val_loss: 0.7807\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7138 - loss: 0.5664 - val_accuracy: 0.5874 - val_loss: 0.6649\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7181 - loss: 0.5593 - val_accuracy: 0.5928 - val_loss: 0.6354\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7126 - loss: 0.5700 - val_accuracy: 0.6468 - val_loss: 0.6304\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7056 - loss: 0.5737 - val_accuracy: 0.4937 - val_loss: 1.3463\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5626 - val_accuracy: 0.6288 - val_loss: 0.6585\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7087 - loss: 0.5662 - val_accuracy: 0.4955 - val_loss: 1.1299\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.5669 - loss: 0.6677\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 54ms/step - accuracy: 0.4902 - loss: 0.7161 - val_accuracy: 0.4811 - val_loss: 0.6955\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5382 - loss: 0.6900 - val_accuracy: 0.4811 - val_loss: 0.6980\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.5636 - loss: 0.6775 - val_accuracy: 0.4829 - val_loss: 0.6976\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5695 - loss: 0.6713 - val_accuracy: 0.5315 - val_loss: 0.6903\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.5964 - loss: 0.6626 - val_accuracy: 0.5225 - val_loss: 0.6886\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6197 - loss: 0.6542 - val_accuracy: 0.5369 - val_loss: 0.6880\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6297 - loss: 0.6438 - val_accuracy: 0.5351 - val_loss: 0.6835\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6490 - loss: 0.6403 - val_accuracy: 0.5550 - val_loss: 0.6782\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6482 - loss: 0.6333 - val_accuracy: 0.5532 - val_loss: 0.6707\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6443 - loss: 0.6319 - val_accuracy: 0.4775 - val_loss: 0.8139\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6461 - loss: 0.6368 - val_accuracy: 0.6198 - val_loss: 0.6443\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6585 - loss: 0.6222 - val_accuracy: 0.6054 - val_loss: 0.6587\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6618 - loss: 0.6088 - val_accuracy: 0.6342 - val_loss: 0.6359\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6595 - loss: 0.6158 - val_accuracy: 0.4793 - val_loss: 0.9372\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6672 - loss: 0.6096 - val_accuracy: 0.4739 - val_loss: 0.9920\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6587 - loss: 0.6096 - val_accuracy: 0.5676 - val_loss: 0.6761\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6763 - loss: 0.6075 - val_accuracy: 0.5604 - val_loss: 0.6894\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6510 - loss: 0.6147 - val_accuracy: 0.5622 - val_loss: 0.6811\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6528 - loss: 0.6066 - val_accuracy: 0.4775 - val_loss: 1.1002\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6714 - loss: 0.5992 - val_accuracy: 0.6090 - val_loss: 0.6607\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6684 - loss: 0.5953 - val_accuracy: 0.5910 - val_loss: 0.6808\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6806 - loss: 0.5879 - val_accuracy: 0.6162 - val_loss: 0.6465\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6755 - loss: 0.5898 - val_accuracy: 0.5532 - val_loss: 0.7227\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.6007 - loss: 0.6663\n",
      "Epoch 1/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.5405 - loss: 0.6950 - val_accuracy: 0.5189 - val_loss: 0.6927\n",
      "Epoch 2/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5734 - loss: 0.6733 - val_accuracy: 0.5189 - val_loss: 0.6948\n",
      "Epoch 3/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5786 - loss: 0.6697 - val_accuracy: 0.5189 - val_loss: 0.7005\n",
      "Epoch 4/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.5985 - loss: 0.6612 - val_accuracy: 0.5189 - val_loss: 0.7090\n",
      "Epoch 5/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6193 - loss: 0.6503 - val_accuracy: 0.5189 - val_loss: 0.7172\n",
      "Epoch 6/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6189 - loss: 0.6464 - val_accuracy: 0.5189 - val_loss: 0.7234\n",
      "Epoch 7/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6261 - loss: 0.6371 - val_accuracy: 0.5189 - val_loss: 0.7321\n",
      "Epoch 8/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6336 - loss: 0.6293 - val_accuracy: 0.5189 - val_loss: 0.7094\n",
      "Epoch 9/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6542 - loss: 0.6239 - val_accuracy: 0.5189 - val_loss: 0.7056\n",
      "Epoch 10/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6674 - loss: 0.6113 - val_accuracy: 0.5514 - val_loss: 0.6707\n",
      "Epoch 11/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6562 - loss: 0.6195 - val_accuracy: 0.4847 - val_loss: 1.0720\n",
      "Epoch 12/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.6578 - loss: 0.6181 - val_accuracy: 0.6144 - val_loss: 0.6695\n",
      "Epoch 13/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6526 - loss: 0.6178 - val_accuracy: 0.6234 - val_loss: 0.6525\n",
      "Epoch 14/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6543 - loss: 0.6181 - val_accuracy: 0.6162 - val_loss: 0.6669\n",
      "Epoch 15/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6823 - loss: 0.5959 - val_accuracy: 0.5856 - val_loss: 0.7157\n",
      "Epoch 16/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6716 - loss: 0.6093 - val_accuracy: 0.6198 - val_loss: 0.6405\n",
      "Epoch 17/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6935 - loss: 0.5918 - val_accuracy: 0.5207 - val_loss: 0.7961\n",
      "Epoch 18/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6816 - loss: 0.5907 - val_accuracy: 0.5892 - val_loss: 0.7099\n",
      "Epoch 19/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6825 - loss: 0.5993 - val_accuracy: 0.4883 - val_loss: 1.1960\n",
      "Epoch 20/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6871 - loss: 0.6037 - val_accuracy: 0.6396 - val_loss: 0.6315\n",
      "Epoch 21/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7008 - loss: 0.5900 - val_accuracy: 0.6324 - val_loss: 0.6278\n",
      "Epoch 22/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7030 - loss: 0.5812 - val_accuracy: 0.5964 - val_loss: 0.6548\n",
      "Epoch 23/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.6868 - loss: 0.5890 - val_accuracy: 0.6162 - val_loss: 0.6919\n",
      "Epoch 24/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7091 - loss: 0.5809 - val_accuracy: 0.6288 - val_loss: 0.6262\n",
      "Epoch 25/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7027 - loss: 0.5819 - val_accuracy: 0.6523 - val_loss: 0.6305\n",
      "Epoch 26/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.6864 - loss: 0.5877 - val_accuracy: 0.6414 - val_loss: 0.6224\n",
      "Epoch 27/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7140 - loss: 0.5777 - val_accuracy: 0.6306 - val_loss: 0.6260\n",
      "Epoch 28/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7112 - loss: 0.5716 - val_accuracy: 0.5928 - val_loss: 0.6529\n",
      "Epoch 29/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.7037 - loss: 0.5766 - val_accuracy: 0.5189 - val_loss: 0.9574\n",
      "Epoch 30/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7118 - loss: 0.5754 - val_accuracy: 0.6523 - val_loss: 0.6316\n",
      "Epoch 31/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7235 - loss: 0.5602 - val_accuracy: 0.5027 - val_loss: 1.0744\n",
      "Epoch 32/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7440 - loss: 0.5521 - val_accuracy: 0.5856 - val_loss: 0.6534\n",
      "Epoch 33/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7380 - loss: 0.5593 - val_accuracy: 0.5514 - val_loss: 0.7244\n",
      "Epoch 34/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7162 - loss: 0.5620 - val_accuracy: 0.6541 - val_loss: 0.6234\n",
      "Epoch 35/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7265 - loss: 0.5493 - val_accuracy: 0.5586 - val_loss: 0.6959\n",
      "Epoch 36/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7267 - loss: 0.5546 - val_accuracy: 0.5802 - val_loss: 0.6547\n",
      "Epoch 37/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7373 - loss: 0.5453 - val_accuracy: 0.5297 - val_loss: 0.7573\n",
      "Epoch 38/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7314 - loss: 0.5510 - val_accuracy: 0.6000 - val_loss: 0.6379\n",
      "Epoch 39/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - accuracy: 0.7372 - loss: 0.5439 - val_accuracy: 0.5189 - val_loss: 1.3154\n",
      "Epoch 40/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7438 - loss: 0.5385 - val_accuracy: 0.6216 - val_loss: 0.6496\n",
      "Epoch 41/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7204 - loss: 0.5450 - val_accuracy: 0.5189 - val_loss: 1.1217\n",
      "Epoch 42/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7370 - loss: 0.5348 - val_accuracy: 0.5189 - val_loss: 0.9691\n",
      "Epoch 43/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7267 - loss: 0.5429 - val_accuracy: 0.5477 - val_loss: 0.7146\n",
      "Epoch 44/270\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - accuracy: 0.7352 - loss: 0.5392 - val_accuracy: 0.5405 - val_loss: 0.7073\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7618 - loss: 0.5262\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, AveragePooling2D, MaxPooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from sklearn.model_selection import GridSearch\n",
    "\n",
    "# Configure cross-validation and early stopping\n",
    "n_splits = 5\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'k_dim': [3,9],\n",
    "    'conv_dim': [16,32],\n",
    "    'pool_dim': [3, 5],\n",
    "    'pooling_type': ['max', 'average'],  \n",
    "    'learning_rate': [1e-4, 1e-5],\n",
    "}\n",
    "\n",
    "# Perform cross-validation with early stopping\n",
    "best_params = None\n",
    "best_score = 0\n",
    "test_scores = {}\n",
    "i = 1\n",
    "\n",
    "for k_dim in param_grid['k_dim']:\n",
    "    for conv_dim in param_grid['conv_dim']:\n",
    "        for learning_rate in param_grid['learning_rate']:\n",
    "            for pooling_type in param_grid['pooling_type']:\n",
    "                for pool_dim in param_grid['pool_dim']:\n",
    "                    total_models = len(param_grid['pooling_type'])*len(param_grid['pool_dim'])*len(param_grid['k_dim'])*len(param_grid['conv_dim'])*len(param_grid['learning_rate'])\n",
    "                    print(f\"testing model {i} out of {total_models}\")\n",
    "                    print(f'testing params: {pooling_type}, {pool_dim}, {k_dim}, {conv_dim},{learning_rate}')\n",
    "                    i += 1\n",
    "\n",
    "                    num_folds = 1\n",
    "                    best_rounds = []\n",
    "                    for train_index, test_index in kf.split(inputs, targets):\n",
    "                        with tf.device(\"/CPU:0\") :\n",
    "                            X_train_fold, X_test_fold = inputs[train_index], inputs[test_index]\n",
    "                            y_train_fold, y_test_fold = targets[train_index], targets[test_index]\n",
    "\n",
    "                        with tf.device(\"/CPU:0\") :\n",
    "                            #X_train, X_test, y_train, y_test = train_test_split(train_index, test_index, test_size=0.2)\n",
    "                            X_train_fold, X_val, y_train_fold, y_val = train_test_split(X_train_fold, y_train_fold, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "                        with tf.device(\"/CPU:0\") :\n",
    "                            batchsize = 32\n",
    "                            train_dataset = tf.data.Dataset.from_tensor_slices((X_train_fold, y_train_fold)).shuffle(200).batch(batchsize)\n",
    "                            val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(batchsize)\n",
    "\n",
    "\n",
    "                        early_stopping = EarlyStopping(\n",
    "                        monitor=\"val_accuracy\", \n",
    "                        patience=10,  # Stop if no improvement for 5 epochs\n",
    "                        mode=\"max\", \n",
    "                        restore_best_weights=True  # Automatically restores the best model weights\n",
    "                        )\n",
    "\n",
    "                        # Prepare the model\n",
    "                        #k_dim=3\n",
    "                        #conv_dim=16\n",
    "                        #learning_rate=1e-4 \n",
    "                        drop_rate=0\n",
    "                        ff_dim=32\n",
    "                        \n",
    "                        model = Sequential([\n",
    "                            Conv2D(conv_dim, kernel_size=(k_dim, k_dim), activation='relu', input_shape=(512, 512, 1)),\n",
    "                            BatchNormalization(),\n",
    "                            ReLU(),\n",
    "                            MaxPooling2D(pool_size=(pool_dim, pool_dim)) if pooling_type == 'max' else AveragePooling2D(pool_size=(pool_dim, pool_dim)),\n",
    "                            Dropout(drop_rate),\n",
    "                            Conv2D(conv_dim, kernel_size=(k_dim, k_dim), padding='valid'),\n",
    "                            BatchNormalization(),\n",
    "                            ReLU(),\n",
    "                            MaxPooling2D(pool_size=(pool_dim, pool_dim)) if pooling_type == 'max' else AveragePooling2D(pool_size=(pool_dim, pool_dim)),\n",
    "                            Dropout(drop_rate),\n",
    "                            Conv2D(conv_dim, kernel_size=(k_dim, k_dim), padding='valid'),\n",
    "                            BatchNormalization(),\n",
    "                            ReLU(),\n",
    "                            MaxPooling2D(pool_size=(pool_dim, pool_dim)) if pooling_type == 'max' else AveragePooling2D(pool_size=(pool_dim, pool_dim)),\n",
    "                            Dropout(drop_rate),\n",
    "                            Flatten(),\n",
    "                            Dense(ff_dim, activation='relu'),\n",
    "                            Dropout(drop_rate),\n",
    "                            Dense(1, activation='sigmoid')\n",
    "                        ])\n",
    "                        model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                                    loss='binary_crossentropy',\n",
    "                                    metrics=['accuracy'])\n",
    "\n",
    "                        # Fit model on train fold and use validation for early stopping\n",
    "                        model.fit(X_train_fold, y_train_fold, epochs = 270, validation_data=val_dataset,callbacks=[early_stopping])\n",
    "\n",
    "                        # Predict on test set\n",
    "                        #y_pred_test = model.predict(X_test_fold)\n",
    "                        test_loss, test_acc = model.evaluate(X_test_fold, y_test_fold)\n",
    "                        test_scores[f'fold:{num_folds}, pooling_type: {pooling_type}, pool_dim: {pool_dim}, k_dim: {k_dim}, conv_dim: {conv_dim}, learning_rate: {learning_rate}'] = {\"loss\":test_loss, \"accuracy\":test_acc}\n",
    "                        \n",
    "                        num_folds += 1\n",
    "\n",
    "        # Compute average score across all folds\n",
    "        #average_score = np.mean(test_scores)\n",
    "        \n",
    "        #if average_score > best_score:\n",
    "            #best_score = average_score\n",
    "            #best_params = {'learning_rate': learning_rate, 'pool_dim': pool_dim}\n",
    "\n",
    "#print(f\"Best Parameters: {best_params}\")\n",
    "#print(f\"Best CV Average Accuracy: {best_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169b0fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fold:1, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.7603837251663208,\n",
       "  'accuracy': 0.5504322648048401},\n",
       " 'fold:2, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.9335079789161682,\n",
       "  'accuracy': 0.64985591173172},\n",
       " 'fold:3, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6924248933792114,\n",
       "  'accuracy': 0.5411255359649658},\n",
       " 'fold:4, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.7347667217254639,\n",
       "  'accuracy': 0.6233766078948975},\n",
       " 'fold:5, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.7261780500411987,\n",
       "  'accuracy': 0.5440115332603455},\n",
       " 'fold:1, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6921393871307373,\n",
       "  'accuracy': 0.5547550320625305},\n",
       " 'fold:2, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.7125189304351807,\n",
       "  'accuracy': 0.6354466676712036},\n",
       " 'fold:3, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6557337641716003,\n",
       "  'accuracy': 0.6176046133041382},\n",
       " 'fold:4, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.9280881881713867,\n",
       "  'accuracy': 0.5613275766372681},\n",
       " 'fold:5, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6655669212341309,\n",
       "  'accuracy': 0.5974025726318359},\n",
       " 'fold:1, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.9173616766929626,\n",
       "  'accuracy': 0.6325648427009583},\n",
       " 'fold:2, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.7117121815681458,\n",
       "  'accuracy': 0.5129683017730713},\n",
       " 'fold:3, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6887571811676025,\n",
       "  'accuracy': 0.5007215142250061},\n",
       " 'fold:4, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.7532536387443542,\n",
       "  'accuracy': 0.5685425400733948},\n",
       " 'fold:5, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6926850080490112,\n",
       "  'accuracy': 0.5411255359649658},\n",
       " 'fold:1, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6830115914344788,\n",
       "  'accuracy': 0.5677233338356018},\n",
       " 'fold:2, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.7314074635505676,\n",
       "  'accuracy': 0.6268011331558228},\n",
       " 'fold:3, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6917557120323181,\n",
       "  'accuracy': 0.5194805264472961},\n",
       " 'fold:4, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6860822439193726,\n",
       "  'accuracy': 0.5266955494880676},\n",
       " 'fold:5, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001': {'loss': 0.6751853227615356,\n",
       "  'accuracy': 0.5656565427780151},\n",
       " 'fold:1, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.6890273094177246,\n",
       "  'accuracy': 0.681556224822998},\n",
       " 'fold:2, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.5592296123504639,\n",
       "  'accuracy': 0.7881844639778137},\n",
       " 'fold:3, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.8573769330978394,\n",
       "  'accuracy': 0.6940836906433105},\n",
       " 'fold:4, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.7597237825393677,\n",
       "  'accuracy': 0.6435786485671997},\n",
       " 'fold:5, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.7089056968688965,\n",
       "  'accuracy': 0.6392496228218079},\n",
       " 'fold:1, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.664371907711029,\n",
       "  'accuracy': 0.7247838377952576},\n",
       " 'fold:2, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.6105037331581116,\n",
       "  'accuracy': 0.6541786789894104},\n",
       " 'fold:3, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.7233209609985352,\n",
       "  'accuracy': 0.6334776282310486},\n",
       " 'fold:4, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.6518352627754211,\n",
       "  'accuracy': 0.62193363904953},\n",
       " 'fold:5, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.7678213119506836,\n",
       "  'accuracy': 0.6190476417541504},\n",
       " 'fold:1, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.75260329246521,\n",
       "  'accuracy': 0.64985591173172},\n",
       " 'fold:2, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.6889753937721252,\n",
       "  'accuracy': 0.6945244669914246},\n",
       " 'fold:3, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.7964785695075989,\n",
       "  'accuracy': 0.6248196363449097},\n",
       " 'fold:4, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.666740357875824,\n",
       "  'accuracy': 0.6161616444587708},\n",
       " 'fold:5, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.8791249394416809,\n",
       "  'accuracy': 0.5757575631141663},\n",
       " 'fold:1, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.6034401059150696,\n",
       "  'accuracy': 0.6844380497932434},\n",
       " 'fold:2, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.5877361297607422,\n",
       "  'accuracy': 0.681556224822998},\n",
       " 'fold:3, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.7101410031318665,\n",
       "  'accuracy': 0.5916305780410767},\n",
       " 'fold:4, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.7032422423362732,\n",
       "  'accuracy': 0.6262626051902771},\n",
       " 'fold:5, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001': {'loss': 0.6590855121612549,\n",
       "  'accuracy': 0.588744580745697},\n",
       " 'fold:1, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6504047513008118,\n",
       "  'accuracy': 0.6282420754432678},\n",
       " 'fold:2, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6916393637657166,\n",
       "  'accuracy': 0.6426513195037842},\n",
       " 'fold:3, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.7188220024108887,\n",
       "  'accuracy': 0.5945165753364563},\n",
       " 'fold:4, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.7696695923805237,\n",
       "  'accuracy': 0.6089466214179993},\n",
       " 'fold:5, pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.659368097782135,\n",
       "  'accuracy': 0.6161616444587708},\n",
       " 'fold:1, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6282691359519958,\n",
       "  'accuracy': 0.6613832712173462},\n",
       " 'fold:2, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6482641696929932,\n",
       "  'accuracy': 0.6123919486999512},\n",
       " 'fold:3, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6401457786560059,\n",
       "  'accuracy': 0.630591630935669},\n",
       " 'fold:4, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6743382811546326,\n",
       "  'accuracy': 0.5901876091957092},\n",
       " 'fold:5, pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6130292415618896,\n",
       "  'accuracy': 0.6580086350440979},\n",
       " 'fold:1, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6026511788368225,\n",
       "  'accuracy': 0.6959654092788696},\n",
       " 'fold:2, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.5860449075698853,\n",
       "  'accuracy': 0.6786743402481079},\n",
       " 'fold:3, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6506237387657166,\n",
       "  'accuracy': 0.630591630935669},\n",
       " 'fold:4, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6721553206443787,\n",
       "  'accuracy': 0.6176046133041382},\n",
       " 'fold:5, pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6610036492347717,\n",
       "  'accuracy': 0.6161616444587708},\n",
       " 'fold:1, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6292195320129395,\n",
       "  'accuracy': 0.64985591173172},\n",
       " 'fold:2, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6262649297714233,\n",
       "  'accuracy': 0.6484149694442749},\n",
       " 'fold:3, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.641272783279419,\n",
       "  'accuracy': 0.6204906105995178},\n",
       " 'fold:4, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.6562520861625671,\n",
       "  'accuracy': 0.6147186160087585},\n",
       " 'fold:5, pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05': {'loss': 0.605099618434906,\n",
       "  'accuracy': 0.6652236580848694}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa4e8282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fold:1, pooling_type: max, pool_dim: 3, k_dim: 3, conv_dim: 16, learning_rate: 0.001</th>\n",
       "      <td>0.665986</td>\n",
       "      <td>0.629683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold:2, pooling_type: max, pool_dim: 3, k_dim: 3, conv_dim: 16, learning_rate: 0.001</th>\n",
       "      <td>0.692688</td>\n",
       "      <td>0.541787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold:3, pooling_type: max, pool_dim: 3, k_dim: 3, conv_dim: 16, learning_rate: 0.001</th>\n",
       "      <td>0.822476</td>\n",
       "      <td>0.624820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold:4, pooling_type: max, pool_dim: 3, k_dim: 3, conv_dim: 16, learning_rate: 0.001</th>\n",
       "      <td>0.692710</td>\n",
       "      <td>0.541126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold:5, pooling_type: max, pool_dim: 3, k_dim: 3, conv_dim: 16, learning_rate: 0.001</th>\n",
       "      <td>0.692670</td>\n",
       "      <td>0.541126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        loss  accuracy\n",
       "params                                                                \n",
       "fold:1, pooling_type: max, pool_dim: 3, k_dim: ...  0.665986  0.629683\n",
       "fold:2, pooling_type: max, pool_dim: 3, k_dim: ...  0.692688  0.541787\n",
       "fold:3, pooling_type: max, pool_dim: 3, k_dim: ...  0.822476  0.624820\n",
       "fold:4, pooling_type: max, pool_dim: 3, k_dim: ...  0.692710  0.541126\n",
       "fold:5, pooling_type: max, pool_dim: 3, k_dim: ...  0.692670  0.541126"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_results_df(test_scores):\n",
    "    # Initialize a dictionary to aggregate results\n",
    "    aggregated_results = {}\n",
    "\n",
    "    for key, metrics in test_scores.items():\n",
    "        # Parse the key to extract the hyperparameter combination (remove fold info)\n",
    "        params = key\n",
    "        \n",
    "        # Initialize an entry in the results dictionary if not already present\n",
    "        if params not in aggregated_results:\n",
    "            aggregated_results[params] = {'loss': [], 'accuracy': []}\n",
    "        \n",
    "        # Append loss and accuracy for this fold\n",
    "        aggregated_results[params]['loss'].append(metrics['loss'])\n",
    "        aggregated_results[params]['accuracy'].append(metrics['accuracy'])\n",
    "\n",
    "    # Create a DataFrame to store averaged results\n",
    "    results_list = []\n",
    "    for params, metrics in aggregated_results.items():\n",
    "        loss = metrics['loss'][0]\n",
    "        accuracy = metrics['accuracy'][0]\n",
    "        results_list.append({'params': params, 'loss': loss, 'accuracy': accuracy})\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results_list).set_index('params')\n",
    "    return results_df\n",
    "\n",
    "raw_result_df = make_results_df(test_scores) \n",
    "raw_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9e9034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee582ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_result_df.to_csv(\"2024-12-03_gridsearch_raw_results_height.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82564281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_average_scores_df(test_scores):\n",
    "    # Initialize a dictionary to aggregate results\n",
    "    aggregated_results = {}\n",
    "\n",
    "    for key, metrics in test_scores.items():\n",
    "        # Parse the key to extract the hyperparameter combination (remove fold info)\n",
    "        params = ', '.join([part for part in key.split(', ') if not part.startswith('fold')])\n",
    "        \n",
    "        # Initialize an entry in the results dictionary if not already present\n",
    "        if params not in aggregated_results:\n",
    "            aggregated_results[params] = {'loss': [], 'accuracy': []}\n",
    "        \n",
    "        # Append loss and accuracy for this fold\n",
    "        aggregated_results[params]['loss'].append(metrics['loss'])\n",
    "        aggregated_results[params]['accuracy'].append(metrics['accuracy'])\n",
    "\n",
    "    # Create a DataFrame to store averaged results\n",
    "    results_list = []\n",
    "    for params, metrics in aggregated_results.items():\n",
    "        avg_loss = sum(metrics['loss']) / len(metrics['loss'])\n",
    "        avg_accuracy = sum(metrics['accuracy']) / len(metrics['accuracy'])\n",
    "        results_list.append({'params': params, 'average_loss': avg_loss, 'average_accuracy': avg_accuracy})\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results_list).set_index('params')\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48fa2985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average_loss</th>\n",
       "      <th>average_accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001</th>\n",
       "      <td>0.769452</td>\n",
       "      <td>0.581760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001</th>\n",
       "      <td>0.730809</td>\n",
       "      <td>0.593307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.001</th>\n",
       "      <td>0.752754</td>\n",
       "      <td>0.551185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.001</th>\n",
       "      <td>0.693488</td>\n",
       "      <td>0.561271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001</th>\n",
       "      <td>0.714853</td>\n",
       "      <td>0.689331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001</th>\n",
       "      <td>0.683571</td>\n",
       "      <td>0.650684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 0.0001</th>\n",
       "      <td>0.756785</td>\n",
       "      <td>0.632224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 0.0001</th>\n",
       "      <td>0.652729</td>\n",
       "      <td>0.634526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: max, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05</th>\n",
       "      <td>0.697981</td>\n",
       "      <td>0.618104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: max, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05</th>\n",
       "      <td>0.640809</td>\n",
       "      <td>0.630513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: average, pool_dim: 3, k_dim: 9, conv_dim: 32, learning_rate: 1e-05</th>\n",
       "      <td>0.634496</td>\n",
       "      <td>0.647800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pooling_type: average, pool_dim: 5, k_dim: 9, conv_dim: 32, learning_rate: 1e-05</th>\n",
       "      <td>0.631622</td>\n",
       "      <td>0.639741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    average_loss  \\\n",
       "params                                                             \n",
       "pooling_type: max, pool_dim: 3, k_dim: 9, conv_...      0.769452   \n",
       "pooling_type: max, pool_dim: 5, k_dim: 9, conv_...      0.730809   \n",
       "pooling_type: average, pool_dim: 3, k_dim: 9, c...      0.752754   \n",
       "pooling_type: average, pool_dim: 5, k_dim: 9, c...      0.693488   \n",
       "pooling_type: max, pool_dim: 3, k_dim: 9, conv_...      0.714853   \n",
       "pooling_type: max, pool_dim: 5, k_dim: 9, conv_...      0.683571   \n",
       "pooling_type: average, pool_dim: 3, k_dim: 9, c...      0.756785   \n",
       "pooling_type: average, pool_dim: 5, k_dim: 9, c...      0.652729   \n",
       "pooling_type: max, pool_dim: 3, k_dim: 9, conv_...      0.697981   \n",
       "pooling_type: max, pool_dim: 5, k_dim: 9, conv_...      0.640809   \n",
       "pooling_type: average, pool_dim: 3, k_dim: 9, c...      0.634496   \n",
       "pooling_type: average, pool_dim: 5, k_dim: 9, c...      0.631622   \n",
       "\n",
       "                                                    average_accuracy  \n",
       "params                                                                \n",
       "pooling_type: max, pool_dim: 3, k_dim: 9, conv_...          0.581760  \n",
       "pooling_type: max, pool_dim: 5, k_dim: 9, conv_...          0.593307  \n",
       "pooling_type: average, pool_dim: 3, k_dim: 9, c...          0.551185  \n",
       "pooling_type: average, pool_dim: 5, k_dim: 9, c...          0.561271  \n",
       "pooling_type: max, pool_dim: 3, k_dim: 9, conv_...          0.689331  \n",
       "pooling_type: max, pool_dim: 5, k_dim: 9, conv_...          0.650684  \n",
       "pooling_type: average, pool_dim: 3, k_dim: 9, c...          0.632224  \n",
       "pooling_type: average, pool_dim: 5, k_dim: 9, c...          0.634526  \n",
       "pooling_type: max, pool_dim: 3, k_dim: 9, conv_...          0.618104  \n",
       "pooling_type: max, pool_dim: 5, k_dim: 9, conv_...          0.630513  \n",
       "pooling_type: average, pool_dim: 3, k_dim: 9, c...          0.647800  \n",
       "pooling_type: average, pool_dim: 5, k_dim: 9, c...          0.639741  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "averaged_results = calculate_average_scores_df(test_scores)\n",
    "averaged_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc324802",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_results.to_csv(\"2024-12-03_gridsearch_averaged_results_height.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde8b6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: pooling_type: average, pool_dim: 5, k_dim: 3, conv_dim: 32, learning_rate: 0.0001\n",
      "Best Loss: 0.5036\n",
      "Best Accuracy: 0.7335\n"
     ]
    }
   ],
   "source": [
    "def find_best_hyperparameters_df(results_df):\n",
    "    # Find the row with the highest average_accuracy\n",
    "    best_row = results_df.loc[results_df['average_accuracy'].idxmax()]\n",
    "    \n",
    "    # Extract the best parameters, loss, and accuracy\n",
    "    best_params = best_row.name  # The index contains the parameter combination\n",
    "    best_loss = best_row['average_loss']\n",
    "    best_accuracy = best_row['average_accuracy']\n",
    "    \n",
    "    return best_params, best_loss, best_accuracy\n",
    "\n",
    "best_params, best_loss, best_accuracy = find_best_hyperparameters_df(averaged_results)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Loss: {best_loss:.4f}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00b88f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hyperparameters(averaged_results):\n",
    "    # Initialize variables to track the best hyperparameters\n",
    "    best_params = None\n",
    "    best_accuracy = 0\n",
    "    best_loss = None\n",
    "\n",
    "    # Iterate over the averaged results\n",
    "    for params, metrics in averaged_results.items():\n",
    "        if metrics['average_accuracy'] > best_accuracy:\n",
    "            best_accuracy = metrics['average_accuracy']\n",
    "            best_loss = metrics['average_loss']\n",
    "            best_params = params\n",
    "\n",
    "    return best_params, best_loss, best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a47c6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: pooling_type: max, pool_dim: 5\n",
      "Best Loss: 0.6461\n",
      "Best Accuracy: 0.5852\n"
     ]
    }
   ],
   "source": [
    "best_params, best_loss, best_accuracy = find_best_hyperparameters(averaged_results)\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Loss: {best_loss:.4f}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1266b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84b7f67",
   "metadata": {},
   "source": [
    "### GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "734a687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU, AveragePooling2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "# Define the model function\n",
    "def build_model(pool_dim):\n",
    "    k_dim=3\n",
    "    conv_dim=16\n",
    "    learning_rate=1e-4 \n",
    "    drop_rate=0\n",
    "    ff_dim=32\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(conv_dim, kernel_size=(k_dim, k_dim), activation='relu', input_shape=(512, 512, 2)),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        AveragePooling2D(pool_size=(pool_dim, pool_dim)),\n",
    "        Dropout(drop_rate),\n",
    "        Conv2D(conv_dim, kernel_size=(k_dim, k_dim), padding='valid'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        AveragePooling2D(pool_size=(pool_dim, pool_dim)),\n",
    "        Dropout(drop_rate),\n",
    "        Conv2D(conv_dim, kernel_size=(k_dim, k_dim), padding='valid'),\n",
    "        BatchNormalization(),\n",
    "        ReLU(),\n",
    "        AveragePooling2D(pool_size=(pool_dim, pool_dim)),\n",
    "        Dropout(drop_rate),\n",
    "        Flatten(),\n",
    "        Dense(ff_dim, activation='relu'),\n",
    "        Dropout(drop_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "   # 'k_dim': [3, 9, 15, 27],\n",
    "   # 'conv_dim': [16, 32, 48],\n",
    "    'pool_dim': [3, 5],\n",
    "   # 'learning_rate': [1e-2, 1e-3, 1e-4, 1e-5],\n",
    "    'epochs': [50]\n",
    "}\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "  filepath='checkpoint.model3.keras',\n",
    "  monitor='val_loss',\n",
    "  mode='min',\n",
    "  save_best_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_accuracy\", \n",
    "    patience=5,  # Stop if no improvement for 5 epochs\n",
    "    mode=\"max\", \n",
    "    restore_best_weights=True  # Automatically restores the best model weights\n",
    ")\n",
    "\n",
    "# Wrap the model\n",
    "model = KerasClassifier(build_fn=build_model, batch_size=batchsize, pool_dim = None, verbose=1)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2,verbose=3, n_jobs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a928a5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, \n",
    "                        y_train, \n",
    "                        validation_data = val_dataset,\n",
    "                        callbacks=[early_stopping]\n",
    "                        )\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee243d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc125c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.get_params().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ee8ff694",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'k_dim': [3, 9, 15, 27],\n",
    "    'conv_dim': [16],\n",
    "    'pool_dim': [3, 5],\n",
    "    'learning_rate': [1e-2,1e-3,1e-4,1e-5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a0e1ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Wrap the model\n",
    "model = KerasClassifier(build_fn=build_model, verbose=0)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a43b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e011dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results = grid.fit(inputs,targets,\n",
    "                  #validation_data=val_dataset, \n",
    "                  epochs=50)\n",
    "                  #callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e7992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_dim = 16\n",
    "ff_dim = 32\n",
    "k_dim = 9\n",
    "pool_dim = 5\n",
    "drop_rate = 0.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Conv2D(conv_dim, kernel_size = (k_dim, k_dim), activation='relu', input_shape=(512, 512, 2)),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.ReLU(),\n",
    "  tf.keras.layers.AveragePooling2D(pool_dim,pool_dim),\n",
    "  tf.keras.layers.Dropout(drop_rate),\n",
    "  tf.keras.layers.Conv2D(conv_dim, kernel_size = (k_dim, k_dim), padding ='valid'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.ReLU(),\n",
    "  tf.keras.layers.AveragePooling2D(pool_dim,pool_dim),\n",
    "  tf.keras.layers.Dropout(drop_rate),\n",
    "  tf.keras.layers.Conv2D(conv_dim, kernel_size = (k_dim, k_dim), padding ='valid'),\n",
    "  tf.keras.layers.BatchNormalization(),\n",
    "  tf.keras.layers.ReLU(),\n",
    "  tf.keras.layers.AveragePooling2D(pool_dim,pool_dim),\n",
    "  tf.keras.layers.Dropout(drop_rate),\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(ff_dim, activation='relu'),\n",
    "  tf.keras.layers.Dropout(drop_rate),\n",
    "  tf.keras.layers.Dense(1, activation='sigmoid')  \n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32069887",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(optimizer=Adam(learning_rate=1e-4),\n",
    "#model.compile(optimizer=Adam(learning_rate=1e-2),\n",
    "#model.compile(optimizer=Adam(learning_rate=1e-5),\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy',  \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798f45a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(\n",
    "  filepath='checkpoint.modelG6.keras',\n",
    "  monitor='val_loss',\n",
    "  mode='min',\n",
    "  save_best_only=True)\n",
    "\n",
    "optim = model.fit(train_dataset,\n",
    "                  validation_data=val_dataset, \n",
    "                  epochs=50, \n",
    "                  callbacks=[model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3452ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "optim.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc6db465",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc_arr = np.array(optim.history['accuracy'])\n",
    "val_acc_arr = optim.history['val_accuracy']\n",
    "val_loss_arr = optim.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22749ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = []\n",
    "for i in range(100):\n",
    "    if train_acc_arr[i] > 0.98:\n",
    "        epochs.append(i)\n",
    "\n",
    "first_epoch_exceed_98 = epochs[0]\n",
    "first_epoch_exceed_98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ff173-6bd5-467c-a91b-c8ece934f27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(optim.history['accuracy'])\n",
    "plt.plot(optim.history['val_accuracy'])\n",
    "plt.legend(['train', 'validation'], loc='lower right')\n",
    "plt.title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4aebbd-9b27-42a2-b22b-5ea9d1c4e671",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(optim.history['loss'])\n",
    "plt.plot(optim.history['val_loss'])\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.title('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c556e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quarter_stats(val_loss, val_acc):\n",
    "    x = np.arange(25)\n",
    "    val_acc_diff = np.gradient(val_acc)\n",
    "    val_loss_diff = np.gradient(val_loss)\n",
    "    slope, _ = np.polyfit(x, val_loss, 1)\n",
    "    return {\n",
    "        \"min_loss\": np.min(val_loss),\n",
    "        \"max_loss\": np.max(val_loss),\n",
    "        \"min_acc\": np.min(val_acc),\n",
    "        \"max_acc\": np.max(val_acc),\n",
    "        \"std_loss\" : np.std(val_loss),\n",
    "        \"r_loss\": np.corrcoef(x, val_loss)[0, 1],\n",
    "        \"slope_loss\": slope,\n",
    "        \"avg_loss_gradient\": np.mean(val_loss_diff),\n",
    "        \"avg_acc_gradient\": np.mean(val_acc_diff),\n",
    "    }\n",
    "\n",
    "# Calculate statistics for each quarter\n",
    "quarter_1 = calculate_quarter_stats(val_loss_arr[:25], val_acc_arr[:25])\n",
    "quarter_2 = calculate_quarter_stats(val_loss_arr[25:50], val_acc_arr[25:50])\n",
    "quarter_3 = calculate_quarter_stats(val_loss_arr[50:75], val_acc_arr[50:75])\n",
    "quarter_4 = calculate_quarter_stats(val_loss_arr[75:], val_acc_arr[75:])\n",
    "\n",
    "# Store results in a DataFrame\n",
    "data = pd.DataFrame([quarter_1, quarter_2, quarter_3, quarter_4], \n",
    "                    index=[\"Q1\", \"Q2\", \"Q3\", \"Q4\"])\n",
    "\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eecd8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2ecafd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_diff1 = np.gradient(val_acc_arr)\n",
    "val_loss_diff1 = np.gradient(val_loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_diff1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b654d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(val_acc_diff1 > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb51a9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_acc_diff1)\n",
    "plt.axhline(y=0,color='r')\n",
    "plt.title(\"Accuracy Gradient\")\n",
    "plt.ylabel(\"Differences in accuracy between epochs\")\n",
    "plt.ylim(-.2,.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90173927",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_diff1)\n",
    "plt.axhline(y=0,color='r')\n",
    "plt.title(\"Loss Gradient\")\n",
    "plt.ylabel(\"Differences in loss between epochs\")\n",
    "plt.ylim(-60,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ac6ce3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(25)\n",
    "# 1st quarter\n",
    "val_loss1 = val_loss_arr[:25]\n",
    "val_acc1 = val_acc_arr[:25]\n",
    "quarter_1 = {\n",
    "\"min_loss\": np.min(val_loss1),\n",
    "\"min_acc\" : np.min(val_acc1),\n",
    "\"max_loss\" : np.max(val_loss1),\n",
    "\"max_acc\" : np.max(val_acc1),\n",
    "\"r_loss\" : np.corrcoef(x,val_loss1)[0,1],\n",
    "\"r_squared_loss\" : np.corrcoef(x,val_loss1)[0,1]**2\n",
    "}\n",
    "\n",
    "# 2nd quarter\n",
    "val_loss2 = val_loss_arr[25:50]\n",
    "val_acc2 = val_acc_arr[25:50]\n",
    "quarter_2 = {\n",
    "\"min_loss\" : np.min(val_loss2),\n",
    "\"min_acc\" : np.min(val_acc2),\n",
    "\"max_loss\" : np.max(val_loss2),\n",
    "\"max_acc\" : np.max(val_acc2),\n",
    "\"r_loss\" : np.corrcoef(x,val_loss2)[0,1],\n",
    "\"r_squared_loss\" : np.corrcoef(x,val_loss2)[0,1]**2\n",
    "}\n",
    "\n",
    "# 3rd quarter\n",
    "val_loss3 = val_loss_arr[50:75]\n",
    "val_acc3 = val_acc_arr[50:75]\n",
    "quarter_3 = {\n",
    "\"min_loss\":np.min(val_loss3),\n",
    "\"min_acc\":np.min(val_acc3),\n",
    "\"max_loss\" : np.max(val_loss3),\n",
    "\"max_acc\" : np.max(val_acc3),\n",
    "\"r_loss\" : np.corrcoef(x,val_loss3)[0,1],\n",
    "\"r_squared_loss\" : np.corrcoef(x,val_loss3)[0,1]**2\n",
    "}\n",
    "\n",
    "# 4th quarter\n",
    "val_loss4 = val_loss_arr[75:]\n",
    "val_acc4 = val_acc_arr[75:]\n",
    "quarter_4 = {\n",
    "\"min_loss\" : np.min(val_loss4),\n",
    "\"min_acc\" : np.min(val_acc4),\n",
    "\"max_loss\" : np.max(val_loss4),\n",
    "\"max_acc\" : np.max(val_acc4),\n",
    "\"r_loss\" : np.corrcoef(x,val_loss4)[0,1],\n",
    "\"r_squared_loss\" : np.corrcoef(x,val_loss4)[0,1]**2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbb27f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "quarter_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "27f87da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = np.arange(50)\n",
    "r = np.corrcoef(x,optim.history['val_loss'])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719b1570",
   "metadata": {},
   "outputs": [],
   "source": [
    "r**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c819042",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424f42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(val_acc_arr[2:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f55d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(val_loss_arr[2:24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e81f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(val_loss_arr[2:24]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734e5ba5-7163-4bb0-ab7a-2c6a94340d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(optim.history['val_accuracy']).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cca68f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(50)\n",
    "r = np.corrcoef(x,optim.history['val_loss'])[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3a325104",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc_diff1 = np.gradient(val_acc_arr)\n",
    "val_loss_diff1 = np.gradient(val_loss_arr)\n",
    "\n",
    "val_acc_diff2 = np.gradient(val_acc_diff1)\n",
    "val_loss_diff2 = np.gradient(val_loss_diff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4cf604f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_acc_diff1)\n",
    "plt.axhline(y=0,color='r')\n",
    "#plt.plot(val_acc_diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91004c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val_loss_diff1)\n",
    "plt.axhline(y=0,color='r')\n",
    "plt.ylim(-3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150381e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe the rate of change needs to roughly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8353884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# want to measure the rate of change \n",
    "plt.hist(val_loss_diff1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcb288d6-4c71-4d03-a8b7-7a7e3d523c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "best_model = load_model('checkpoint.modelG6.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01d84a9-73d6-4129-8acb-b605e14ebebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5b8c9-2650-4fa2-acd0-e62d26930911",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Test loss:{0}, Test accuracy: {1}'.format(test_loss,test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c6069a-36aa-4e8a-ac05-51c9d9c5c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values from the testing dataset\n",
    "Y_pred_probs = best_model.predict(X_test)\n",
    "Y_pred = np.array(Y_pred_probs>=.5)\n",
    "# compute the confusion matrix\n",
    "#confusion_mtx = tf.math.confusion_matrix(Y_true, Y_pred) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1214ef0-f6ca-4882-8ea7-8a69a9881c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(Y_pred_probs.flatten())\n",
    "plt.title('Probability distribution of Predictions')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7862201e-ae5d-4aa2-9adf-00226c212c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_test)\n",
    "plt.title('Probability distribution of True values')\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ec003f-efd9-46e5-a20a-b79d958e34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "041bcccf-e5ac-4858-a278-ed9efee44f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = Y_pred.astype(float).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4db01-4804-45a3-800d-073bc7c36193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, Y_pred) \n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bc92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d757d41-6a14-4fc5-9b6a-cc54f0ca21af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TP=152\n",
    "TN=175\n",
    "FP=13\n",
    "FN=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ee234d-29fb-40f3-b31f-42c47bfcd5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = TP/(TP+FN)\n",
    "precision = TP/(TP+FP)\n",
    "\n",
    "print(recall,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871263b3-e031-4560-9dd4-846c0ea76a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498bcb2a-bfa1-4a39-a8cb-d8bdb50277f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
